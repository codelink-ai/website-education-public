[{"categories":["devops"],"contents":" We will share the five application scenarios for Nginx: HTTP server, static server, reverse proxy server, load balancer, and separation of static and dynamic contents.\nI. HTTP server Nginx itself is also a static resource server. When there are only static resources, you can use Nginx to be a server, if a website is only a static page, then it can be deployed in this way.\n1. first in the document root directory Docroot (/usr/local/var/www) to create html directory, and then in the html put a test.html; 2. configure the server in nginx.conf user mengday staff; http { server { listen 80; server_name localhost; client_max_body_size 1024M; # default location location / { root /usr/local/var/www/html; index index.html index.htm; index.html; index.htm; } } } 3. Access test http://localhost/ points to /usr/local/var/www/index.html, index.html is the html that comes with nginx installation http://localhost/test.html points to /usr/local/var/www/html/test.html\n Note: If you get 403 Forbidden errors when accessing images, it may be because the first line of nginx.conf user configuration is not correct, the default is #user nobody; it is commented out, change it to user root under linux; change it to user username group under macos; then reload the configuration file or reboot and try again. The user name can be checked by who am i command.\n 4. Command Introduction  server : used to define the service, there can be multiple server blocks in http listen : Specify the IP address and port for the server to listen to requests, if the address is omitted, the server will listen to all addresses, if the port is omitted, the standard port is used server_name : the name of the service, used to configure the domain name location : The configuration corresponding to the mapped path uri, a server can have multiple locations, location followed by a uri, can be a regular expression, / means match any path, when the client accesses the path meets this uri will execute the code inside the location block root : root path, when visit http://localhost/test.html, \u0026ldquo;/test.html\u0026rdquo; will match to \u0026ldquo;/\u0026rdquo; uri, find root as /usr/local/ var/www/html, the user accesses the resource physical address = root + uri = /usr/local/var/www/html + /test.html = /usr/local/var/www/html/test.html index : set the home page, when only access server_name without any path behind is not to go root directly to the index command; if the access path does not specify a specific file, then return the index set resources, if you visit http://localhost/html/ then the default return index.html  5. location uri regular expression  . : match any character other than the newline character ? : repeat 0 times or 1 times + : repeat 1 or more times * : repeat 0 or more times \\d ï¼šMatch a number ^ : Match the beginning of the string $ : Match the end of the string {n} : Repeat n times {n,} : Repeat n or more times [c] : matches a single character c [a-z] : matches any of the lowercase letters a-z (a|b|c) : the genus line means match any of the cases, each case is separated by a vertical line, usually enclosed in parentheses, and matches a character or a b character or a c character \\ Backslash: used to escape special characters  The content matched between the parentheses () can be referenced later by $1, and $2 indicates the content in the second () before. It is easy to confuse people inside the regular \\ escaping special characters.\n II. Static Server In the company often encounter a static server, usually provides a function of upload, other applications if you need static resources from the static server.\n Create images and img directories under /usr/local/var/www, and put a test.jpg under each directory respectively.  http { server { listen 80; server_name localhost; set $doc_root /usr/local/var/www; # default location location / { root /usr/local/var/www/html; index index.html index.htm; index.html; } location ^~ /images/ { root $doc_root; } location ~* \\. (gif|jpg|jpeg|png|bmp|ico|swf|css|js)$ { root $doc_root/img; } } } Custom variables use set directive, syntax set variable name value; reference use variable name value; reference use variable name; here customize doc_root variable.\nThere are two general ways to map static server location.\n Use path, such as /images/ Generally, images are placed in some image directory. Use suffixes such as .jpg, .png, etc. to match the pattern  Visit http://localhost/test.jpg to map to $doc_root/img\nVisit http://localhost/images/test.jpg When the same path meets more than one location, it will match the location with higher priority, because the priority of ^~ is higher than ~, so it will go to the location corresponding to /images/.\nThere are several common location path mapping paths.\n = Exact match for common characters. That is, exact match. ^~ prefix matching. If the match is successful, no other locations will be matched. ~ indicates a regular match, case sensitive ~* means perform a regular match, not case-sensitive /xxx/ regular string path matching /xxx/ generic match, any request will be matched to  Location priority When a path matches multiple locations, there is a priority order of which location can be matched, and the priority order is related to the expression type of the location value, not the order in the configuration file. For the same type of expression, the longer string will be matched first.\nThe following are the descriptions in order of priority.\n The equal sign type (=) has the highest priority. Once the match is successful, no other matches are found and the search stops. ^~ type expression, not a regular expression. Once the match is successful, no more matches are found and the search stops. The regular expression type (~ ~*) has the next highest priority. If more than one location can match, the one with the longest regular expression is used. Regular string match type. Match by prefix. / generic match, if no match, match the generic  Priority search problem: different types of location mapping decide whether to continue down the search\n equals type, ^~ type: once matched, the search stops, no other location will be matched Regular expression type (~ ~*), regular string matching type /xxx/ : after matching, it will continue to search for other locations until it finds the highest priority, or stop searching when it finds the first case  Location priority from highest to lowest:\n(location =) \u0026gt; (location full path) \u0026gt; (location ^~ path) \u0026gt; (location ~,~* regular order) \u0026gt; (location partial start path) \u0026gt; (/)\nlocation = / { # Exact match /, hostname cannot be followed by any string / [ configuration A ] } location / { # Match all requests that start with /. # But if a longer expression of the same type is available, the longer expression is chosen. # If there are regular expressions to match, the regular expressions are matched first. [ configuration B ] } location /documents/ { # Match all requests that start with /documents/, and continue down the list after the match. # But if there is a longer expression of the same type, the longer expression is chosen. # If there are regular expressions to match, the regular expressions are given priority. [ configuration C ] } location ^~ /images/ { # Match all expressions starting with /images/, and if the match is successful, stop matching the lookup and stop searching. # So, even if there is a matching regular expression location, it will not be used [ configuration D ] } location ~* \\. (gif|jpg|jpeg)$ { # Match all requests ending with gif jpg jpeg. # But requests starting with /images/ will use Configuration D, which has a higher priority [ configuration E ] } location /images/ { # Characters matching /images/ will continue to search down [ configuration F ] } location = /test.htm { root /usr/local/var/www/htm; index index.htm; index.htm; }  Note: The priority of location is not related to the location of location configuration\n  III. Reverse Proxy Sever Reverse proxy should be the most used feature of Nginx. Reverse proxy means that the proxy server accepts connection requests on the Internet, forwards the requests to a server on the internal network, and returns the results obtained from the server to the client requesting the connection on the Internet, at which point the proxy server behaves externally as a reverse proxy server.\nSimply put, the real server cannot be directly accessed by the external network, so a proxy server is needed, while the proxy server can be accessed by the external network and the real server in the same network environment, of course, it may be the same server, the port is different.\nReverse proxy through the proxy_pass command to achieve .\nStart a Java Web project with port 8081\nserver { listen 80; server_name localhost; location / { proxy_pass http://localhost:8081; proxy_set_header Host $host:$server_port; # Set user ip address proxy_set_header X-Forwarded-For $remote_addr; # When requesting server error to find another server proxy_next_upstream error timeout invalid_header http_500 http_502 http_503; } http_500 http_502; } When we access localhost, it\u0026rsquo;s the same as accessing localhost:8081\n IV. Load Balancer Load balancing is also a common feature of Nginx. Load balancing means spreading the execution across multiple operating units, such as web servers, FTP servers, enterprise critical application servers, and other mission-critical servers, so that they can work together to complete their tasks.\nSimply put, when there are two or more servers, the requests are randomly distributed to the specified servers according to the rules, and the load balancing configuration generally requires a reverse proxy to be configured at the same time to jump to the load balancing through the reverse proxy. Nginx currently supports three load balancing policies, and two common third-party policies.\nLoad balancing is achieved through the upstream directive. Recommended: Java Interview Questions\n1. RR (round robin :polling by default) Each request is assigned to different back-end servers one by one in chronological order, that is, the first request is assigned to the first server, the second request is assigned to the second server, and if there are only two servers, the third request continues to be assigned to the first one, so that the cycle of polling continues, that is, the ratio of requests received by servers is 1:1, and if the back-end server is down, it can be automatically eliminated. Polling is the default configuration and does not require much configuration\nStart the same project on ports 8081 and 8082 respectively\nupstream web_servers { server localhost:8081; server localhost:8082; } server { listen 80; server_name localhost; #access_log logs/host.access.log main; location / { proxy_pass http://web_servers; # Header Host must be specified proxy_set_header Host $host:$server_port; host $host:$server_port; } } The access address can still get the response http://localhost/api/user/login?username=zhangsan\u0026amp;password=111111, this way is polled\n2. weights Specify the polling rate, weight is proportional to the access ratio, that is, the proportion of requests received by the server is the proportion of the respective configured weight, used in the case of uneven performance of the back-end server, such as the server performance is poor to receive fewer requests, the server performance is better to handle more requests.\nupstream test { server localhost:8081 weight=1; server localhost:8082 weight=3; server localhost:8083 weight=4 backup; backup; } The example is that only one of the four requests is assigned to 8081, and the other three are assigned to 8082. backup means hot standby, which only goes to 8083 if both 8081 and 8082 are down\n3. ip_hash The above two ways have a problem, that is, the next request may be distributed to another server, when our program is not stateless (using the session to save data), then there is a big problem, such as the login information is saved to the session, then jump to another server when you need to log in again So many times we need a client to access only one server, then we need to use iphash, iphash each request by accessing the IP hash result distribution, so that each visitor fixed access to a back-end server, can solve the problem of session.\nupstream test { ip_hash; server localhost:8080; server localhost:8081; } 4. fair (third party) Distribute requests according to the response time of the backend server, with the shorter response time being assigned first. This is configured to give the user a faster response\nupstream backend { fair; server localhost:8080; server localhost:8081; } 5. url_hash (third party) Allocate requests by the hash result of the accessed url, so that each url is directed to the same backend server, which is more effective when the backend server is cached. Add the hash statement to the upstream, the server statement can not write other parameters such as weight, hash_method is the hash algorithm used\nupstream backend { hash $request_uri; hash_method crc32; server localhost:8080; server localhost:8081; } Each of the above five load balancing is applicable to different situations, so you can choose which policy mode to use according to the actual situation, but fair and url_hash need to install third-party modules to use.\n V. Separation of Static and Dynamic Separation of dynamic and static is to let the dynamic web pages in the dynamic website according to certain rules to the unchanging resources and often change the resources to distinguish, dynamic and static resources to do a good job of splitting, we can do caching operations based on the characteristics of static resources, which is the core idea of the static website processing.\nupstream web_servers { server localhost:8081; server localhost:8082; } server { listen 80; server_name localhost; set $doc_root /usr/local/var/www; location ~* \\. (gif|jpg|jpeg|png|bmp|ico|swf|css|js)$ { root $doc_root/img; } location / { proxy_pass http://web_servers; # Header Host must be specified proxy_set_header Host $host:$server_port; host $host:$server_port; } error_page 500 502 503 504 /50x.html; location = /50x.html { root $doc_root; } }  VI. Others 1. return directive Return the http status code and optionally the second parameter can be the redirect URL\nlocation /permanently/moved/url { return 301 http://www.example.com/moved/here; } 2. rewrite directive The rewrite URI request rewrite, which modifies the request URI multiple times during request processing by using the rewrite directive, has one optional parameter and two required parameters.\nThe first (required) parameter is a regular expression that the request URI must match.\nThe second parameter is the URI used to replace the matching URI.\nThe optional third parameter is a flag that can stop further processing of the rewrite directive or send a redirect (code 301 or 302)\nlocation /users/ { rewrite ^/users/(. *)$ /show?user=$1 break; } 3. error_page directive Using the error_page directive, you can configure NGINX to return a custom page with an error code, replace other error codes in the response, or redirect the browser to another URI. in the following example, the error_page directive specifies the page (/404.html) that will return the 404 page error code.\nerror_page 404 /404.html; 4. logs Access log: need to turn on compression gzip on; otherwise no log file is generated, open log_format, access_log comments\nlog_format main \u0026#39;$remote_addr - $remote_user [$time_local] \u0026#34;$request\u0026#34; \u0026#39; \u0026#39;$status $body_bytes_sent \u0026#34;$http_referer\u0026#34; \u0026#39; \u0026#39; \u0026#34;$http_user_agent\u0026#34; \u0026#34;$http_x_forwarded_for\u0026#34; \u0026#39; access_log /usr/local/etc/nginx/logs/host.access.log main; gzip on. 5; 5. deny command # Deny access to a directory location ~* \\. (txt|doc)${ root $doc_root; deny all; } 6. Built-in variables The built-in variables that can be used in nginx configuration files start with the dollar sign $, and are also called global variables by some people. The values of some of these predefined variables can be changed. Also, pay attention to the Java Voice public page, reply to \u0026ldquo;back-end interview\u0026rdquo;, and you will be sent a treasure trove of interview questions!\n $args: # This variable is equal to the parameter in the request line, same as $query_string $content_length : The Content-length field in the request header. $content_type : The Content-Type field in the request header. $document_root : The value specified in the root directive for the current request. $host : The request host header field, otherwise it is the server name. $http_user_agent : client-side agent information $http_cookie : client-side cookie information $limit_rate : This variable can limit the connection rate. $request_method : The action requested by the client, usually GET or POST. $remote_addr : IP address of the client. $remote_port : The port of the client. $remote_user : The user name that has been authenticated by Auth Basic Module. $request_filename : The path of the current request file, generated by the root or alias directive with the URI request. $scheme : HTTP method (e.g. http, https). $server_protocol : The protocol used for the request, usually HTTP/1.0 or HTTP/1.1. $server_addr : The server address, this value can be determined after a system call is completed. $server_name : The name of the server. $server_port : The port number on which the request reaches the server. $request_uri : The original URI containing the request parameters, without the host name, e.g. /foo/bar.php?arg=baz. $uri : The current URI without request parameters, $uri does not contain the host name, e.g. /foo/bar.html. $document_uri : Same as $uri  Source: https://mp.weixin.qq.com/s/_J7gUOJK6JWYnkIb4AYK2Q\n","date":"03 Jan, 2022","image":"images/blog/nginx1.png","permalink":"https://codelink.ai/blog/devops/five-application-scenarios-for-understanding-nginx-thoroughly/","tags":["nginx"],"title":"Five application scenarios for understanding Nginx thoroughly"},{"categories":["data science"],"contents":" We\u0026rsquo;d like to introduce you to an awesome spatial (geographic) data visualization tool: keplergl.\nKeplergl is completely open source by Uber and is the default tool for spatial data visualization within Uber.\nThrough its open interface package keplergl for Python, we can pass in a variety of formats of data by writing Python code in jupyter notebook, and use its built-in rich spatial data visualization functions in its interactive window embedded in notebook. Here are 3 main addresses for learning.\n  the official website address: https://kepler.gl/\n  jupyter notebook manual address: https://github.com/keplergl/kepler.gl/tree/master/docs/keplergl-jupyter#geojson\n  Case study address: https://github.com/keplergl/kepler.gl/tree/master/bindings/kepler.gl-jupyter/notebooks\n  Installation  The installation of keplergl is very simple.\npip install keplergl Amazing graphics  A wave of stunning graphics are coming.\n Getting Started  import pandas as pd import geopandas as gpd from keplergl import KeplerGl # Create an object kep1 = KeplerGl(height=600) # Activate the object and load it into jupyter notebook kep1 As you can see, after running the basic code in Jupyter directly generated the built-in graphics, the graphics themselves are also dynamic; dark black background is also my favorite:\nAdding data  By default, keplergl can add 3 types of data:\n csv GeoJSON DataFrame  csv format There is a csv data in the local directory: china.csv, which records the latitude and longitude of each province in China.\nwith open(\u0026#34;china.csv\u0026#34;, \u0026#34;r\u0026#34;) as f: csv_data = f.read() # add_data add data kep1.add_data(data=csv_data, name=\u0026#34;csv_kep\u0026#34;) kep1  DataFrame format china = pd.read_csv(\u0026#34;china.csv\u0026#34;) kep1.add_data(data=china, name=\u0026#34;dataframe_kep\u0026#34;) kep1  GeoJson format url = \u0026#39;http://eric.clst.org/assets/wiki/uploads/Stuff/gz_2010_us_040_00_500k.json\u0026#39; country_gdf = gpd.read_file(url) # geopandas read json file kep1.add_data(data=country_gdf, name=\u0026#34;state\u0026#34;) kep1  Custom graphics  Keplergl\u0026rsquo;s customization method: the criticality button. Once inside, you can customize the operation\n Saving and reusing configurations The configuration of the instantiated kep can be saved and reused in the following instance objects.\n Save.  # Save as a file with open(\u0026#39;config1.py\u0026#39;,\u0026#39;w\u0026#39;) as f: f.write(\u0026#39;config={}\u0026#39;.format(kep1.config)) # Run: magic command %run %run config1.py Reuse  kep2 = KeplerGl(height=400, data={\u0026#34;layer1\u0026#34;:df}, config=kep1.config # configuration of kep1 ) kep2 Save graphics   minimalist version, mainly the file name  kep1.save_to_html(file_name=\u0026#34;first_kep.html\u0026#34;) full version: file name, configuration, data, readability  # 4 parameters kep1.save_to_html(file_name=\u0026#34;first_kep.html\u0026#34;, data={\u0026#39;data_1\u0026#39;:china}, config=config, read_only=True ) Web app  The operations shown above are all done in the notebook, we can also do them directly online: https://kepler.gl/demo\nWe will share more articles after we have studied this tool seriously, this library is worth studying\n Source: https://mp.weixin.qq.com/s/t-X8NtuYXY-lKPOrSY3aPQ\n","date":"02 Jan, 2022","image":"images/blog/post-1.webp","permalink":"https://codelink.ai/blog/data-science/spatial-data-visualization-wizard-keplergl/","tags":["visualization","python"],"title":"Spatial data visualization wizard keplergl"},{"categories":["web development"],"contents":" We recommend several popular websites that can help improve your programming efficiency.\nCodepen  Demo video: https://www.bilibili.com/video/BV1im4y1X7zb/\nHere you can find a lot of front-end code written by coding guru. In addition to various web layout codes, there are more kinds of fun, cool and novel front-end animations and effects.\nFor example, when Christmas is coming, many of you asked if I could draw a Christmas tree with code.\nI can\u0026rsquo;t, but if you type \u0026ldquo;Christmas Tree\u0026rdquo; in this website, you can see different styles of Christmas tree pages!\nClick on the page you like and you\u0026rsquo;ll be taken to the code editing page, where you can modify the HTML, CSS, and JavaScript front-end code and view the results in real time in the area at the bottom, which is very convenient!\nAfter editing a web page, you can browse it in full screen, favorite, clone, share, etc. in the menu at the bottom right corner of the web page, and directly embed the web page into our own project or download the complete code package to local.\nThanks to the development of front-end technology, this site provides developers with a one-stop service to search for projects, edit them online, and share and export them, making it easy for us to learn other people\u0026rsquo;s good code in an independent practice.\nHere are a few more similar sites.\nCodeSandbox  CodeSandbox, as the name suggests, helps you run front-end projects in an isolated environment.\nHere you can create your own sandboxes (projects) based on rich templates for common front-end frameworks like React, Vue, Angular, VuePress, Svelte, etc..\nOnce you create your sandbox, you can edit your code online, view your results in real time, or share your sandbox with other people.\nJSFiddle  JSFiddle is a front-end development practice, you can also write code online and view the effect in real time. Compared with Codepen, I feel that this site has a better editing experience.\nWhen you see a great piece of JS code or plugin on the web, you don\u0026rsquo;t have to download it locally. Paste the code directly into JSFiddle and you\u0026rsquo;ll be able to see it in action in the fastest way possible. Many front-end component libraries now also use this platform to give developers a WYSIWYG experience.\nJSRUN  China\u0026rsquo;s online programming site, in addition to front-end, even supports online debugging and running of up to 30 programming languages!\nLike Codepen, you can see many code snippets written by others here and download them directly. You can also save and share your code, and create your own little code collection.\nI have to say, this site is one of the best in China, with great access and functionality!\nGitpod  This platform is a bit more advanced than the above mentioned sites. It is a powerful online IDE (Integrated Programming Environment) that provides a VSCode-style editor that allows you to write code online to complete your development.\nGitpod is based on container technology and will help you compile, build, and run any GitHub project, not just the front end, with one click! And each project runs in isolation from each other, so you can create them as you go and recycle them whenever you\u0026rsquo;re done.\nIf you\u0026rsquo;ve got your eye on a GitHub project and you don\u0026rsquo;t want to build it locally to see how it works, the best way to build and run it online is with Gitpod. There are more and more GitHub projects that have access to Gitpod, and if you see the button below, you can deploy it with one click, which is much more efficient!\nSource: https://mp.weixin.qq.com/s/VJtMNyhAYROYURfBa1nKfw\n","date":"27 Dec, 2021","image":"images/blog/post-2.webp","permalink":"https://codelink.ai/blog/web-development/a-few-of-this-years-super-hot-programming-sites/","tags":["tools","javascript"],"title":"A few of this year's super-hot programming sites!"},{"categories":["data science"],"contents":" Xgboost is an integrated learning algorithm, which belongs to the category of boosting algorithms in the 3 commonly used integration methods (bagging, boosting, stacking). It is an additive model, and the base model is usually chosen as a tree model, but other types of models such as logistic regression can also be chosen.\n1. xgboost and GBDT  Xgboost belongs to the category of gradient boosted tree (GBDT) models. The basic idea of GBDT is to let the new base model (GBDT takes CART categorical regression tree as the base model) to fit the deviation of the previous model, so as to continuously reduce the deviation of the additive model.\nCompared with the classical GBDT, xgboost has made some improvements, resulting in significant improvements in effectiveness and performance (highlighting a common interview test).\n  GBDT expands the objective function Taylor to the first order, while xgboost expands the objective function Taylor to the second order. More information about the objective function is retained, which helps to improve the effect.\n  GBDT is finding a new fit label for the new base model (negative gradient of the previous additive model), while xgboost is finding a new objective function for the new base model (second-order Taylor expansion of the objective function about the new base model).\n  xgboost adds and L2 regularization term for the leaf weights, thus facilitating the model to obtain a lower variance.\n  xgboost adds a strategy to automatically handle missing value features. By dividing the samples with missing values into left subtree or right subtree respectively and comparing the advantages and disadvantages of the objective functions under the two schemes, the samples with missing values can be divided automatically without the need of filling preprocessing the missing features.\n  In addition, xgboost also supports candidate quantile cuts, feature parallelism, etc., which can improve performance.\n2. xgboost Basic Principle  The following is a general introduction to the principle of xgboost from three perspectives: assumption space, objective function, and optimization algorithm.\n1. Hypothesis space  2. Objective function  3. Optimization algorithm The basic idea: greedy method, learning tree by tree, each tree fits the deviation of the previous model.\nThird, the first t trees to learn what? To finish building the xgboost model, we need to determine some of the following things.\n  how to boost? If the additive model composed of the previous t-1 trees has been obtained, how to determine the learning goal of the tth tree?\n  How to generate the tree? If the learning goal of the tth tree is known, how to learn this tree? Specifically, does it involve splitting or not? Which feature is selected for splitting? What splitting point is chosen? How to take the value of the split leaf nodes?\n  We first consider the problem of how to boost, and then solve the problem of how to take the values of the split leaf nodes.\n 4. How to generate the tth tree?  xgboost uses a binary tree, and at the beginning, all the samples are on one leaf node. Then the leaf nodes are continuously bifurcated to gradually generate a tree.\nxgboost uses a levelwise generation strategy, i.e., it tries to split all the leaf nodes at the same level at a time.\nThe process of splitting leaf nodes to generate a tree has several basic questions: should we split? Which feature to choose for splitting? At what point of the feature to split? and what values are taken on the new leaves after the split?\nThe problem of taking values of leaf nodes has been solved earlier. Let\u0026rsquo;s focus on a few remaining questions.\n Should splitting be performed?  Depending on the pruning strategy of the tree, this problem is handled in two different ways. If it is a prepruning strategy, then splitting will be done only if there is some way of splitting that makes the objective function drop after splitting.\nHowever, if it is a post-pruning strategy, the splitting will be done unconditionally, and then after the tree generation is completed, the branches of the tree will be checked from top to bottom to see if they contribute positively to the decline of the objective function and thus pruned.\nxgboost uses a prepruning strategy and splits only if the gain after splitting is greater than 0.\nWhat features are selected for splitting?  xgboost uses feature parallelism to select the features to be split, i.e., it uses multiple threads to try to use each feature as a splitting feature, find the optimal splitting point for each feature, calculate the gain generated after splitting them, and select the feature with the largest gain as the splitting feature.\nWhat splitting point is selected?  There are two methods for xgboost to select the splitting point of a feature, one is the global scan method and the other is the candidate splitting point method.\nThe global scan method arranges all the values of the feature in the sample from smallest to largest, and tries all the possible splitting locations to find the one with the greatest gain, whose computational complexity is proportional to the number of different values of the sample feature on the leaf node.\nIn contrast, the candidate split point method is an approximate algorithm that selects only a constant number (e.g., 256) of candidate split positions, and then finds the best one from the candidate split positions.\n5. Example of xgboost usage  You can use pip to install xgboost\npip install xgboost The following is an example of using xgboost, you can refer to modify the use.\nimport numpy as np import pandas as pd import xgboost as xgb import datetime from sklearn import datasets from sklearn.model_selection import train_test_split from sklearn.metrics import accuracy_score def printlog(info): nowtime = datetime.datetime.now().strftime(\u0026#39;%Y-%m-%d%H:%M:%S\u0026#39;) print(\u0026#34;\\n\u0026#34;+\u0026#34;==========\u0026#34;*8 + \u0026#34;%s\u0026#34;%nowtime) print(info+\u0026#39;... \\n\\n\u0026#39;) # ================================================================================ # I. Reading data # ================================================================================ printlog(\u0026#34;step1: reading data...\u0026#34;) # read dftrain,dftest breast = datasets.load_breast_cancer() df = pd.DataFrame(breast.data,columns = [x.replace(\u0026#39; \u0026#39;,\u0026#39;_\u0026#39;) for x in breast.feature_names]) df[\u0026#39;label\u0026#39;] = breast.target dftrain,dftest = train_test_split(df) xgb_train = xgb.DMatrix(dftrain.drop(\u0026#34;label\u0026#34;,axis = 1),dftrain[[\u0026#34;label\u0026#34;]]) xgb_valid = xgb.DMatrix(dftest.drop(\u0026#34;label\u0026#34;,axis = 1),dftest[[\u0026#34;label\u0026#34;]]) # ================================================================================ # Two, set the parameters # ================================================================================ printlog(\u0026#34;step2: setting parameters...\u0026#34;) num_boost_rounds = 100 early_stopping_rounds = 20 # Configure xgboost model parameters params_dict = dict() # booster parameters params_dict[\u0026#39;learning_rate\u0026#39;] = 0.05 # Learning rate, usually smaller is better. params_dict[\u0026#39;objective\u0026#39;] = \u0026#39;binary:logistic\u0026#39; # tree parameters params_dict[\u0026#39;max_depth\u0026#39;] = 3 # depth of the tree, usually between [3,10] params_dict[\u0026#39;min_child_weight\u0026#39;] = 30 # minimum leaf node sample weight sum, the larger the model the more conservative. params_dict[\u0026#39;gamma\u0026#39;]= 0 # Minimum drop value of loss function required for node splitting, the larger the model the more conservative. params_dict[\u0026#39;subsample\u0026#39;]= 0.8 # horizontal sampling, sample sampling ratio, usually between [0.5, 1].  params_dict[\u0026#39;colsample_bytree\u0026#39;] = 1.0 # longitudinal sampling, feature sampling ratio, usually between [0.5, 1  params_dict[\u0026#39;tree_method\u0026#39;] = \u0026#39;hist\u0026#39; # strategy for constructing the tree, can be auto, exact, approx, hist # regulazation parameters  # Omega(f) = gamma*T + reg_alpha* sum(abs(wj)) + reg_lambda* sum(wj**2)  params_dict[\u0026#39;reg_alpha\u0026#39;] = 0.0 #L1 weight coefficient of the regularization term, the larger the model the more conservative it is, usually takes a value between [0,1]. params_dict[\u0026#39;reg_lambda\u0026#39;] = 1.0 #L2 The weight coefficient of the regularization term, the larger the model the more conservative it is, usually takes a value between [1,100]. # Other parameters params_dict[\u0026#39;eval_metric\u0026#39;] = \u0026#39;auc\u0026#39; params_dict[\u0026#39;silent\u0026#39;] = 1 params_dict[\u0026#39;nthread\u0026#39;] = 2 params_dict[\u0026#39;scale_pos_weight\u0026#39;] = 1 # Setting to positive value for unbalanced samples will make the algorithm converge faster. params_dict[\u0026#39;seed\u0026#39;] = 0 # ================================================================================ # Third, train the model # ================================================================================ printlog(\u0026#34;step3: training model...\u0026#34;) result = {} watchlist = [(xgb_train, \u0026#39;train\u0026#39;),(xgb_valid, \u0026#39;valid\u0026#39;)] bst = xgb.train(params = params_dict, dtrain = xgb_train, num_boost_round = num_boost_round, verbose_eval= 1, evals = watchlist, early_stopping_rounds = early_stopping_rounds, evals_result = result) # ================================================================================ # IV, Evaluation Model # ================================================================================ printlog(\u0026#34;step4: evaluating model ...\u0026#34;) y_pred_train = bst.predict(xgb_train, ntree_limit=bst.best_iteration) y_pred_test = bst.predict(xgb_valid, ntree_limit=bst.best_iteration) print(\u0026#39;train accuracy: {:.5}\u0026#39;.format(accuracy_score(dftrain[\u0026#39;label\u0026#39;], y_pred_train\u0026gt;0.5))) print(\u0026#39;valid accuracy: {:.5}\\n\u0026#39;.format(accuracy_score(dftest[\u0026#39;label\u0026#39;], y_pred_test\u0026gt;0.5))) %matplotlib inline %config InlineBackend.figure_format = \u0026#39;svg\u0026#39; dfresult = pd.DataFrame({(dataset+\u0026#39;_\u0026#39;+feval): result[dataset][feval] for dataset in [\u0026#34;train\u0026#34;, \u0026#34;valid\u0026#34;] for feval in [\u0026#39;auc\u0026#39;]}) dfresult.index = range(1,len(dfresult)+1) ax = dfresult.plot(kind=\u0026#39;line\u0026#39;,figsize=(8,6),fontsize = 12,grid = True) ax.set_title(\u0026#34;Metric During Training\u0026#34;,fontsize = 12) ax.set_xlabel(\u0026#34;Iterations\u0026#34;,fontsize = 12) ax.set_ylabel(\u0026#34;auc\u0026#34;,fontsize = 12) ax = xgb.plot_importance(bst,importance_type = \u0026#34;gain\u0026#34;,xlabel=\u0026#39;Feature Gain\u0026#39;) ax.set_xlabel(\u0026#34;Feature Gain\u0026#34;,fontsize = 12) ax.set_ylabel(\u0026#34;Features\u0026#34;,fontsize = 12) fig = ax.get_figure() fig.set_figwidth(8) fig.set_figheight(6) # ================================================================================ # v. Save the model # ================================================================================ printlog(\u0026#34;step5: saving model ...\u0026#34;) model_dir = \u0026#34;data/bst.model\u0026#34; print(\u0026#34;model_dir: %s\u0026#34;%model_dir) bst.save_model(model_dir) bst_loaded = xgb.Booster(model_file=model_dir) printlog(\u0026#34;task end...\u0026#34;) Source: https://mp.weixin.qq.com/s/eAVcbnsh9zzVnlOFz9w5Dw\n","date":"22 Nov, 2021","image":"images/blog/post-6.webp","permalink":"https://codelink.ai/blog/data-science/a-30-minute-guide-to-xgboost/","tags":["algorithm","python"],"title":"A 30-minute's guide to XGBoost (Python code)"},{"categories":["data science"],"contents":" KalidoKit is the integration of a variety of algorithms to achieve, Facemesh, Blazepose, Handpose, Holistic. Let\u0026rsquo;s see the effect.\nThe virtual image is driven by the movements of real human limbs, faces and hands.\nThe mainstream application direction of this technology is virtual anchor.\nIt is possible to drive avatars to dance.\nIt can also capture the whole body movements, facial expressions, gestures, etc., like the motion picture at the beginning.\nIn addition to this type of driving virtual image type, you can also use your imagination to make some interesting small applications.\nKalidoKit  This project is based on Tensorflow.js implementation.\n Project address: https://github.com/yeemachine/kalidokit\n The key point information captured can be used to drive 2D and 3D avatars, combined with some avatar driving engines, to achieve the effect shown at the beginning of the article.\nIt is possible to drive both Live2D images and 3D VRM images.\nThe technical points involved here can\u0026rsquo;t be finished in one article, so today we mainly talk about the basic key point detection technologies: face key point detection, human pose estimation, and gesture pose estimation.\nFace keypoint detection  Face keypoint detection, there are sparse and dense.\nLike the basic one, 68 keypoints are detected.\nGenerally speaking, for the detection of closed eyes, head posture, open and closed mouth, a simple 68 keypoints is enough.\nOf course, there are also more dense keypoints detection.\nFor some skin beauty applications, a dense keypoint detection algorithm is needed, with thousands of keypoints.\nBut the idea of the algorithm is the same, to return the location coordinates of these keypoints, usually used with face detection algorithms.\nFor those who want to learn face keypoint detection algorithms, we recommend two introductory projects.\n  https://github.com/1adrianb/face-alignment https://github.com/ChanChiChoi/awesome-Face_Recognition   One is a basic introductory project, and the other integrates the mainstream algorithms for face keypoints.\nHuman Pose Estimation  Human pose estimation is also a very basic problem in computer vision.\nFrom the point of view of the name, it can be understood as the estimation of the position of the \u0026ldquo;human body\u0026rdquo; pose (key points, such as head, left hand, right foot, etc.).\nGenerally, there are 4 types of tasks.\n Single-Person Skeleton Estimation (SPSE) Multi-person Pose Estimation Video Pose Tracking 3D Skeleton Estimation  Simply put, it is the detection of human skeleton joint points to locate the human pose.\nHuman pose estimation has a wide range of applications, for example, pose detection and action prediction of pedestrians in street scenes in the autonomous driving industry; pedestrian re-identification problems in the security field, specific action monitoring in special scenes; movie special effects in the film industry, etc.\nFor those who want to learn, you can read this compiled paper at\n https://github.com/cbsudux/awesome-human-pose-estimation\n Gestural posture estimation  Hand joints are more flexible, agile and self-obscuring, so it is a little more complicated.\nBut the principle is similar to human posture estimation.\nIn addition to this regular gesture recognition, it can also be used to do some special effects.\nIn fact, many of these human effects, the positioning of the position, are achieved with the help of these key points.\nAs above, to learn, you can see this integrated material at\n https://github.com/xinghaochen/awesome-hand-pose-estimation\n Source: https://mp.weixin.qq.com/s/t3qOKkErm8ZbmKDOhHqCOA\n","date":"22 Nov, 2021","image":"images/blog/post-5.png","permalink":"https://codelink.ai/blog/data-science/algorithm-kalidokit/","tags":["computer vision","python"],"title":"KalidoKit: algorithms to achieve, Facemesh, Blazepose, Handpose, Holistic"},{"categories":["python"],"contents":" This article will focus on the threading module, and for everyday developers, this content is a must-have, and also a high frequency interview FAQ.\n Official documentation (https://docs.python.org/zh-cn/3.6/library/threading.html)\n Thread safety  Thread safety is a concept in multi-threaded or multi-process programming. In a program where multiple threads with shared data are executed in parallel, thread-safe code will ensure that each thread is executed properly and correctly through a synchronization mechanism, without data contamination or other unexpected situations.\nFor example, if there are 10 candies (resources) in a room (process), and there are 3 villains (1 main thread and 2 sub-threads), when villain A eats 3 candies and is forced to rest by the system, he thinks there are 7 candies left, and when villain B eats 3 candies after working, then when villain A comes back on duty, he thinks there are 7 candies left, but in fact there are only 4.\nThe above example where the data of thread A and thread B are not synchronized is a thread safety issue which can lead to very serious surprises, let\u0026rsquo;s go by the following example.\nHere we have a value num with an initial value of 0. We open 2 threads.\n  Thread 1 performs a 10 million + 1 operation on num\n  Thread 2 performs a -1 operation on num 10 million times\n  The result may be staggering, as num does not end up being 0 as we thought.\nimport threading num = 0 def add(): global num for i in range(10_000_000): num += 1 def sub(): global num for i in range(10_000_000): num -= 1 if __name__ == \u0026#34;__main__\u0026#34;: subThread01 = threading.Thread(target=add) subThread02 = threading. subThread01.start() subThread02.start() subThread01.join() subThread02.join() print(\u0026#34;num result : %s\u0026#34; % num) # The results are collected three times # num result : 669214 # num result : -1849179 # num result : -525674 This is a very good case above, and to solve this problem we have to secure the timing of thread switching through locks.\nIt is worth noting that the Python basic data types list, tuple, and dict are thread-safe, so if there are multiple threads operating on these three containers, we don\u0026rsquo;t need to consider thread-safety issues.\nThe role of locks  Locks are a means by which Python provides us with the ability to manipulate thread switching on our own, and they can be used to make thread switching orderly.\nOnce thread switching is ordered, access and modification of data between threads becomes controlled, so to ensure thread safety, locks must be used.\nThe threading module provides the five most common types of locks, which are divided by function as follows.\n synchronous locks: lock (only one can be released at a time) recursive locks: rlock (only one can be released at a time) conditional locks: condition (any one can be released at a time) Event lock: event (all at once) semaphore lock: semaphore (can release a specific one at a time)  1. Lock() synchronous lock  Basic introduction Lock lock has many names, such as.\n Synchronous lock Mutual exclusion lock  What do they mean? As follows.\n  Mutual exclusion means that a resource can be accessed by only one visitor at the same time, and is unique and exclusive, but mutual exclusion cannot restrict the order of access to the resource by the visitor, i.e., the access is unordered\n  Synchronization means that on the basis of mutual exclusion (in most cases), other mechanisms are used to achieve orderly access to resources by visitors\n  Synchronization is actually a more complex implementation of mutual exclusion, because it implements orderly access on top of mutual exclusion\n  The following methods are provided by the threading module in connection with synchronous locks.\n   Method Description     threading.Lock() returns a synchronous lock object   lockObject.acquire(blocking=True, timeout=1) lock, when a thread is executing the locked block, it will not be allowed to switch to other threads, the default lock expiration time is 1 second   lockObject.release() Unlock, when a thread is executing an unlocked block, it will allow the system to switch to other threads according to the policy   lockObject.locked() determines whether the lock object is locked or not, and returns a boolean value    Usage  Synchronous locks can only release one thread at a time. A locked thread will not surrender execution rights while running, but will only hand over execution rights to other threads through system scheduling when the thread is unlocked.\nThe top problem is solved using synchronous locking as follows.\nimport threading num = 0 def add(): lock.acquire() global num for i in range(10_000_000): num += 1 lock.release() def sub(): lock.acquire() global num for i in range(10_000_000): num -= 1 lock.release() if __name__ == \u0026#34;__main__\u0026#34;: lock = threading.Lock() subThread01 = threading.Thread(target=add) subThread02 = threading. subThread01.start() subThread02.start() subThread01.join() subThread02.join() print(\u0026#34;num result : %s\u0026#34; % num) # The results are collected three times # num result : 0 # num result : 0 # num result : 0 This makes the code completely serial, which is not as fast as directly using serialized single-threaded execution for such computationally intensive I/O operations, so this example is only meant as an example and does not outline the real use of locks.\nDeadlock phenomenon  For synchronous locks, one acquire() must correspond to one release(), and the operation of using multiple acquires() followed by multiple releases() cannot be repeated continuously, which will cause a deadlock causing the program to block and not move at all, as follows.\nimport threading num = 0 def add(): lock.acquire() # locking lock.acquire() # deadlock # Do not execute global num for i in range(10_000_000): num += 1 lock.release() lock.release() def sub(): lock.acquire() # locking lock.acquire() # deadlock # Do not execute global num for i in range(10_000_000): num -= 1 lock.release() lock.release() if __name__ == \u0026#34;__main__\u0026#34;: lock = threading.Lock() subThread01 = threading.Thread(target=add) subThread02 = threading. subThread01.start() subThread02.start() subThread01.join() subThread02.join() print(\u0026#34;num result : %s\u0026#34; % num) The with statement  Since the __enter__() and __exit__() methods are implemented in the threading.Lock() object, we can use the with statement to perform context-managed locking and unlocking operations in the following way.\nimport threading num = 0 def add(): with lock: # auto-lock global num for i in range(10_000_000): num += 1 # Auto-unlock def sub(): with lock: # Auto-lock global num for i in range(10_000_000): num -= 1 # Auto-unlock if __name__ == \u0026#34;__main__\u0026#34;: lock = threading.Lock() subThread01 = threading.Thread(target=add) subThread02 = threading. subThread01.start() subThread02.start() subThread01.join() subThread02.join() print(\u0026#34;num result : %s\u0026#34; % num) # The results are collected three times # num result : 0 # num result : 0 # num result : 0 2. RLock() Recursive lock  Basic introduction Recursive locking is an upgraded version of synchronous locking, which can be done on the basis of synchronous locking by repeatedly using acquire() and then repeatedly using release(), but it must be noted that the number of locks and unlocks must be the same, otherwise it will also cause deadlock phenomenon.\nThe following methods are provided by the threading module with recursive locks.\n   Method Description     threading.RLock() returns a recursive lock object   lockObject.acquire(blocking=True, timeout=1) lock, when a thread is executing the locked block, it will not be allowed to switch to other threads, the default lock expiration time is 1 second   lockObject.release() Unlock, when a thread is executing an unlocked block, it will allow the system to switch to other threads according to the policy   lockObject.locked() determines whether the lock object is locked or not, and returns a boolean value    Usage The following is a simple use of recursive locking. If you use synchronous locking, deadlocking will occur, but recursive locking will not.\nimport threading num = 0 def add(): lock.acquire() lock.acquire() global num for i in range(10_000_000): num += 1 lock.release() lock.release() def sub(): lock.acquire() lock.acquire() global num for i in range(10_000_000): num -= 1 lock.release() lock.release() if __name__ == \u0026#34;__main__\u0026#34;: lock = threading.RLock() subThread01 = threading.Thread(target=add) subThread02 = threading. subThread01.start() subThread02.start() subThread01.join() subThread02.join() print(\u0026#34;num result : %s\u0026#34; % num) # The results are collected three times # num result : 0 # num result : 0 # num result : 0 The with statement Since the __enter__() and __exit__() methods are implemented in the threading.RLock() object, we can use the with statement to perform context-managed locking and unlocking operations in the form of\nimport threading num = 0 def add(): with lock: # auto-lock global num for i in range(10_000_000): num += 1 # Auto-unlock def sub(): with lock: # Auto-lock global num for i in range(10_000_000): num -= 1 # Auto-unlock if __name__ == \u0026#34;__main__\u0026#34;: lock = threading.RLock() subThread01 = threading.Thread(target=add) subThread02 = threading. subThread01.start() subThread02.start() subThread01.join() subThread02.join() print(\u0026#34;num result : %s\u0026#34; % num) # The results are collected three times # num result : 0 # num result : 0 # num result : 0 3. Condition() Condition lock  Basic introduction Condition lock is based on the recursive lock to add the function to suspend the running of the thread. And we can use wait() and notify() to control the number of threads executed.\nNote: Conditional locks can be freely set to release several threads at a time.\nThe following methods are provided by the threading module and the conditional lock.\n   Method Description     threading.Condition() returns a conditional lock object   lockObject.acquire(blocking=True, timeout=1) lock, when a thread is executing the locked block, it will not be allowed to switch to another thread, the default lock expiration time is 1 second   lockObject.release() Unlock, when a thread is executing an unlocked block, it will allow the system to switch to other threads according to the policy   lockObject.wait(timeout=None) sets the current thread to a \u0026ldquo;wait\u0026rdquo; state, which will only continue after the thread is \u0026ldquo;notified\u0026rdquo; or the timeout expires. The thread in the \u0026ldquo;wait\u0026rdquo; state will allow the system to switch to other threads according to the policy   lockObject.wait_for(predicate, timeout=None) sets the current thread to the \u0026ldquo;waiting\u0026rdquo; state, and will only continue to run after the thread\u0026rsquo;s predicate returns a True or the timeout expires. The thread in the \u0026ldquo;waiting\u0026rdquo; state will allow the system to switch to other threads according to the policy. Note: the predicate parameter should be passed as a callable object and return a bool type result   lockObject.notify(n=1) notifies a thread with the current status of \u0026ldquo;waiting\u0026rdquo; to continue running, or multiple threads with the n parameter   lockObject.notify_all() notifies all threads whose current state is \u0026ldquo;waiting\u0026rdquo; to continue running    Usage The following example starts 10 sub-threads and immediately sets the 10 sub-threads to the waiting state.\nThen we can send one or more notifications to resume the waiting subthreads.\nimport threading currentRunThreadNumber = 0 maxSubThreadNumber = 10 def task(): global currentRunThreadNumber thName = threading.currentThread().name condLock.acquire() # lock print(\u0026#34;start and wait run thread : %s\u0026#34; % thName) condLock.wait() # suspend the thread and wait to wake it up currentRunThreadNumber += 1 print(\u0026#34;carry on run thread : %s\u0026#34; % thName) condLock.release() # unlock if __name__ == \u0026#34;__main__\u0026#34;: condLock = threading.Condition() for i in range(maxSubThreadNumber): subThreadIns = threading.Thread(target=task) subThreadIns.start() while currentRunThreadNumber \u0026lt; maxSubThreadNumber: notifyNumber = int( input(\u0026#34;Please enter the number of threads that need to be notified to run:\u0026#34;)) condLock.acquire() condLock.notify(notifyNumber) # release condLock.release() print(\u0026#34;main thread run end\u0026#34;) # Start 10 subthreads first, then all of them will become waiting # start and wait run thread : Thread-1 # start and wait run thread : Thread-2 # start and wait run thread : Thread-3 # start and wait run thread : Thread-4 # start and wait run thread : Thread-5 # start and wait run thread : Thread-6 # start and wait run thread : Thread-7 # start and wait run thread : Thread-8 # start and wait run thread : Thread-9 # start and wait run thread : Thread-10 # Batch send notification to release a specific number of sub threads to continue running # Please enter the number of threads that need to be notified to run: 5 # Release 5 # carry on run thread : Thread-4 # carry on run thread : Thread-3 # carry on run thread : Thread-1 # carry on run thread : Thread-2 # carry on run thread : Thread-5 # Please enter the number of threads that need to be notified to run : 5 # release 5 # carry on run thread : Thread-8 # carry on run thread : Thread-10 # carry on run thread : Thread-6 # carry on run thread : Thread-9 # carry on run thread : Thread-7 # Please enter the number of threads that need to be notified to run: 1 # main thread run end with statement Since the __enter__() and __exit__() methods are implemented in the threading.Condition() object, we can use the with statement to perform context-managed locking and unlocking operations in the form of\nimport threading currentRunThreadNumber = 0 maxSubThreadNumber = 10 def task(): global currentRunThreadNumber thName = threading.currentThread().name with condLock: print(\u0026#34;start and wait run thread : %s\u0026#34; % thName) condLock.wait() # suspend the thread and wait to wake it up currentRunThreadNumber += 1 print(\u0026#34;carry on run thread : %s\u0026#34; % thName) if __name__ == \u0026#34;__main__\u0026#34;: condLock = threading. for i in range(maxSubThreadNumber): subThreadIns = threading.Thread(target=task) subThreadIns.start() while currentRunThreadNumber \u0026lt; maxSubThreadNumber: notifyNumber = int( input(\u0026#34;Please enter the number of threads that need to be notified to run:\u0026#34;)) with condLock: condLock.notify(notifyNumber) # Release print(\u0026#34;main thread run end\u0026#34;) 4. Event() event lock  Basic introduction Event lock is based on conditional locking. The difference between it and conditional locking is that it can only release all the threads at once, and cannot release any number of child threads to continue running.\nWe can think of event lock as a traffic light, when the light is red all sub-threads are suspended and enter the \u0026ldquo;waiting\u0026rdquo; state, when the light is green all sub-threads are back to \u0026ldquo;running\u0026rdquo;.\nThe following methods are provided by the threading module in relation to the event lock.\n   Method Description     threading.Event() returns an event lock object   lockObject.clear() sets the event lock to a red light, i.e. all threads are suspended   lockObject.is_set() is used to determine the current event lock status, red is False, green is True   lockObject.set() sets the event lock to a green state, i.e. all threads resume running   lockObject.wait(timeout=None) sets the current thread to the \u0026ldquo;wait\u0026rdquo; state, which will continue to run only after the thread receives the \u0026ldquo;green light\u0026rdquo; or the timeout expires. The thread in the \u0026ldquo;wait\u0026rdquo; state will allow the system to switch to other threads according to the policy.    Usage Event locks cannot be used with the with statement, only in the usual way.\nLet\u0026rsquo;s simulate the operation of a thread and a traffic light, stop on red and go on green as follows\nimport threading maxSubThreadNumber = 3 def task(): thName = threading.currentThread().name print(\u0026#34;start and wait run thread : %s\u0026#34; % thName) eventLock.wait() # pause run and wait for green light print(\u0026#34;green light, %scarry on run\u0026#34; % thName) print(\u0026#34;red light, %sstop run\u0026#34; % thName) eventLock.wait() # pause run, wait for green light print(\u0026#34;green light, %scarry on run\u0026#34; % thName) print(\u0026#34;sub thread %srun end\u0026#34; % thName) if __name__ == \u0026#34;__main__\u0026#34;: eventLock = threading.Event() for i in range(maxSubThreadNumber): subThreadIns = threading.Thread(target=task) subThreadIns.start() eventLock.set() # set to green eventLock.clear() # set to red eventLock.set() # set to green # start and wait run thread : Thread-1 # start and wait run thread : Thread-2 # start and wait run thread : Thread-3 # green light, Thread-1 carry on run # red light, Thread-1 stop run # green light, Thread-1 carry on run # sub thread Thread-1 run end # green light, Thread-3 carry on run # red light, Thread-3 stop run # green light, Thread-3 carry on run # sub thread Thread-3 run end # green light, Thread-2 carry on run # red light, Thread-2 stop run # green light, Thread-2 carry on run # sub thread Thread-2 run end 5. Semaphore() semaphore lock  Basic Introduction A semaphore lock is also based on a conditional lock. It differs from a conditional lock and an event lock as follows.\nConditional lock: You can release any thread that is in the \u0026ldquo;waiting\u0026rdquo; state at one time.\nEvent lock: All threads in the \u0026ldquo;waiting\u0026rdquo; state can be released at once.\nSemaphore locks: a specified number of threads can be released in a batch in a \u0026ldquo;locked\u0026rdquo; state.\nThe following methods are provided by the threading module in relation to semaphore locks.\n   Method Description     threading.Semaphore() returns a semaphore lock object   lockObject.acquire(blocking=True, timeout=1) lock, when a thread is executing a locked block, it will not be allowed to switch to another thread, the default lock expiration time is 1 second   lockObject.release() Unlock, when a thread is executing an unlocked block, it will allow the system to switch to other threads according to the policy    Usage The following is a sample usage, which you can use as a width-limited section where only the same number of threads can be released at a time.\nimport threading import time maxSubThreadNumber = 6 def task(): thName = threading.currentThread().name semaLock.acquire() print(\u0026#34;run sub thread %s\u0026#34; % thName) time.sleep(3) semaLock.release() if __name__ == \u0026#34;__main__\u0026#34;: # Only 2 can be released at a time semaLock = threading.Semaphore(2) for i in range(maxSubThreadNumber): subThreadIns = threading.Thread(target=task) subThreadIns.start() # run sub thread Thread-1 # run sub thread Thread-2 # run sub thread Thread-3 # run sub thread Thread-4 # run sub thread Thread-6 # run sub thread Thread-5 The with statement Since the __enter__() and __exit__() methods are implemented in the threading.Semaphore() object, we can use the with statement to perform context-managed locking and unlocking operations.\nimport threading import time maxSubThreadNumber = 6 def task(): thName = threading.currentThread().name with semaLock: print(\u0026#34;run sub thread %s\u0026#34; % thName) time.sleep(3) if __name__ == \u0026#34;__main__\u0026#34;: semaLock = threading.Semaphore(2) for i in range(maxSubThreadNumber): subThreadIns = threading.Thread(target=task) subThreadIns.start() Lock Relationships  The above 5 types of locks can be said to be based on synchronous locks to do, which you can find from the source code.\nFirst, let\u0026rsquo;s look at the RLock recursive lock. The implementation of recursive lock is very simple, it maintains an internal counter, when the counter is not 0, the thread cannot be switched by I/O operations and time polling mechanism. This is not the case when the counter is 0:\ndef __init__(self): self._block = _allocate_lock() self._owner = None self._count = 0 # counter The Condition conditional lock actually has two locks inside, a bottom-level lock (synchronous lock) and a high-level lock (recursive lock).\nThere are two ways to unlock the low-level lock. Using the wait() method temporarily unlocks the bottom-level lock and adds a high-level lock, and only when it receives a notfiy() from another thread does it unlock the high-level lock and re-lock the low-level lock, which means that the condition lock is implemented based on the constant switching between synchronous and recursive locks.\ndef __init__(self, lock=None): if lock is None: lock = RLock() # You can see that conditional locking is internally based on recursive locking, which in turn is based on synchronous locking self._lock = lock self.acquire = lock.acquire self.release = lock.release try: self._release_save = lock._release_save except AttributeError: pass try: self._acquire_restore = lock._acquire_restore except AttributeError: pass try: self._is_owned = lock._is_owned except AttributeError: pass self._waiters = _deque() Event event locks are internally based on conditional locks to do the following.\nclass Event: def __init__(self): self._cond = Condition(Lock()) # Instantiates a conditional lock. self._flag = False def _reset_internal_locks(self): # private! called by Thread._reset_internal_locks by _after_fork() self._cond.__init__(Lock()) def is_set(self): \u0026#34;\u0026#34;\u0026#34;Return true if and only if the internal flag is true.\u0026#34;\u0026#34;\u0026#34; return self._flag isSet = is_set Semaphore semaphore locks are also internally based on conditional locks to do the following.\nclass Semaphore: def __init__(self, value=1): if value \u0026lt; 0: raise ValueError(\u0026#34;semaphore initial value must be \u0026gt;= 0\u0026#34;) self._cond = Condition(Lock()) # As you can see, a conditional lock is instantiated here self._value = value Basic Exercises  Application of conditional locks Requirement: An empty list with two threads taking turns adding values to it (one adding an even number, one adding an odd number), so that the values in the list are 1 - 100, and are ordered.\nimport threading lst = [] def even(): \u0026#34;\u0026#34;\u0026#34;Add even numbers\u0026#34;\u0026#34;\u0026#34;\u0026#34; with condLock: for i in range(2, 101, 2): # Determine if the current list is exhausted at length 2 # If so, add an odd number # If not, add an even number if len(lst) % 2 ! = 0: # Add an even number lst.append(i) # Add the value first condLock.notify() # tell the other thread that you can add the odd number, but here you don\u0026#39;t immediately hand over execution condLock.wait() # hand over execution rights and wait for another thread to notify to add an even number else: # Add an odd number condLock.wait() # surrender execution rights and wait for another thread to notify to add an even number lst.append(i) condLock.notify() condLock.notify() def odd(): \u0026#34;\u0026#34;\u0026#34;add odd numbers\u0026#34;\u0026#34;\u0026#34;\u0026#34; with condLock: for i in range(1, 101, 2): if len(lst) % 2 == 0: lst.append(i) condLock.notify() condLock.wait() condLock.notify() if __name__ == \u0026#34;__main__\u0026#34;: condLock = threading.Condition() addEvenTask = threading.Thread(target=even) addOddTask = threading. addEvenTask.start() addOddTask.start() addEvenTask.join() addOddTask.join() print(lst) Application of event locks There are 2 task threads to play Li Bai and Du Fu, how can we make them reply to each other in one sentence? The text is as follows.\nDu Fu: Old Li, come drink! Li Bai: Old Du, I can't drink anymore! Du Fu: Old Li, one more pot? Du Fu: ... old Li? Li Bai: Hoo hoo hoo... fell asleep... The code is as follows.\nimport threading def libai(): event.wait() print(\u0026#34;Li Bai: Lao Du ah, do not drink I can not drink!\u0026#34;) event.set() event.clear() event.wait() print(\u0026#34;Li Bai: Hoo hoo hoo... Sleeping...\u0026#34;) def dufu(): print(\u0026#34;Dufu: Old Li, come drink!\u0026#34;) event.set() event.clear() event.wait() print(\u0026#34;Du Fu: Old Li ah, another pot?\u0026#34;) print(\u0026#34;Du Fu: ... Old Li?\u0026#34;) event.set() if __name__ == \u0026#39;__main__\u0026#39;: event = threading.Event() t1 = threading.Thread(target=libai) Thread(target=dufu) t1.start() t2.start() t1.join() t2.join() Original link: https://mp.weixin.qq.com/s/4PBaW4mT7tFhqcgurAM7-A\n","date":"20 Nov, 2021","image":"images/blog/post-7.webp","permalink":"https://codelink.ai/blog/python/explaining-the-5-python-thread-locks/","tags":["multi-threading"],"title":"Explaining the 5 Python thread locks"},{"categories":["python"],"contents":" Today we share with you 3 relatively cold knowledge.\nThe first one: the magic dictionary key  some_dict = {} some_dict[5.5] = \u0026#34;Ruby\u0026#34; some_dict[5.0] = \u0026#34;JavaScript\u0026#34; some_dict[5] = \u0026#34;Python\u0026#34; Output:\n\u0026gt;\u0026gt;\u0026gt; some_dict[5.5] \u0026#34;Ruby\u0026#34; \u0026gt;\u0026gt;\u0026gt; some_dict[5.0] \u0026#34;Python\u0026#34; \u0026gt;\u0026gt;\u0026gt; some_dict[5] \u0026#34;Python\u0026#34; \u0026ldquo;Python\u0026rdquo; eliminates the existence of \u0026ldquo;JavaScript\u0026rdquo;?\nðŸ’¡ Description:\n  The Python dictionary determines whether two keys are identical by checking for key equality and comparing hash values.\n  Immutable objects with the same value always have the same hash value in Python.\n  Note: Objects with different values may also have the same hash (hash collision).\n\u0026gt;\u0026gt; 5 == 5.0 True \u0026gt;\u0026gt;\u0026gt; hash(5) == hash(5.0) True When executing the statement some_dict[5] = \u0026quot;Python\u0026quot;, the existing value \u0026ldquo;JavaScript\u0026rdquo; is overwritten by \u0026ldquo;Python\u0026rdquo; because Python recognizes 5 and 5.0 as the same key of some_dict.\nSecond: return in exception handling  def some_func(): try: return \u0026#39;from_try\u0026#39; finally: return \u0026#39;from_finally\u0026#39; Output:\n\u0026gt;\u0026gt;\u0026gt; some_func() \u0026#39;from_finally\u0026#39; ðŸ’¡ Description:\n  When return, break or continue is executed in the try of the \u0026ldquo;try\u0026hellip;finally\u0026rdquo; statement, the finally clause is still executed.\n  The return value of the function is determined by the last executed return statement. Since the finally clause will always be executed, the return in the finally clause will always be the last statement executed.\n  Third: Determination of identical objects  class WTF: pass Output:\n\u0026gt;\u0026gt;\u0026gt; WTF() == WTF() # Two different objects should not be equal False \u0026gt;\u0026gt;\u0026gt; WTF() is WTF() # also not the same False \u0026gt;\u0026gt;\u0026gt; hash(WTF()) == hash(WTF()) # The hash values should also be different True \u0026gt;\u0026gt;\u0026gt; id(WTF()) == id(WTF()) True ðŸ’¡ Description:\n  When the id function is called, Python creates an object of class WTF and passes it to the id function. The id function then gets its id value (that is, its memory address), and discards the object. The object is then destroyed.\n  When we do this twice in a row, Python allocates the same memory address to the second object. Because the id function (in CPython) uses the object\u0026rsquo;s memory address as the object\u0026rsquo;s id value, the id values of both objects are the same.\n  In summary, an object\u0026rsquo;s id value is unique only for the life of the object. After the object is destroyed, or before it is created, other objects can have the same id value.\n  So why does the is operation result in False? Let\u0026rsquo;s look at this code.\n  class WTF(object): def __init__(self): print(\u0026#34;I\u0026#34;) def __del__(self): print(\u0026#34;D\u0026#34;) Output:\n\u0026gt;\u0026gt;\u0026gt; WTF() is WTF() I I D D False \u0026gt;\u0026gt;\u0026gt; id(WTF()) == id(WTF()) I D I D True As you can see, the order of object destruction is the reason for all the differences.\nOriginal link: https://github.com/leisurelicht/wtfpython-cn\n","date":"19 Oct, 2021","image":"images/blog/post-4.webp","permalink":"https://codelink.ai/blog/python/there-are-3-incredible-return-functions-in-python/","tags":["learning"],"title":"There are 3 incredible return functions in Python"},{"categories":["web development"],"contents":" There is no doubt: making good use of online resources and tools can speed up development, improve quality, and make life more Chill ðŸ˜Ž~.\nThis article brings you 10 great free web resources for front-end developers â­ ðŸ˜Ž (à¹‘-Ì€ã…‚-Ì)Ùˆâœ§\n1. Undraw  If you need free SVG illustrations for your website, don\u0026rsquo;t miss Undraw!\nSVG illustration resources are huge, with search function available; and, you can also customize the color scheme of the illustration, simply too NICE ~\nA large number of resources, support search ðŸ” Feel free to change the color scheme ðŸŒˆ\n2. Error 404  I don\u0026rsquo;t know where you would normally go to find 404 page material ~\nNow you have one more option: Error 404\nCool, cool, cool!\n3. Squoosh  Compressed images!\nCompared to tinypng has better compression effect.\ntinypng compression\nSquoosh compression\nCompression effect: the former is 80%, the latter is 95%; the final result is also good ~ðŸ‘\nWhy not try ?\n4. DevDocs  DevDocs, as the name suggests, is the technical documentation for web development and is a very good learning manual!\nOther than that, I like the UI! Also supports adding common technical documents, changing the theme, etc. ~\n5. iHateRegex  If you hate regular expressions, then do not miss this site (Ë‰â–½Ë‰;)\u0026hellip;\nNot only that, but there are also detailed illustrations! Damn, it\u0026rsquo;s so well done â•®(â•¯â–½â–½)â•­\n6. Carbon  People often ask: \u0026ldquo;How do I generate such nice code snippets?\u0026rdquo; and the answer is in Carbon!\nYou can generate code snippets for various themes and languages and export them as images or copy them to other platforms, it\u0026rsquo;s really nice to use ðŸ‘Œ ðŸ‘Œ ðŸ‘Œ comfortable~~\n7. Dribbble  For web design inspiration, look no further than Dribbble!!!\nWhen you see other people\u0026rsquo;s backend designs, you want to go back and rip up your own ðŸ¶\n8. Animista  Css animation, copy the code and you can use it! No installation, doesn\u0026rsquo;t it sound good?\n9. Shape Divider  You can generate all kinds of dividers and export them in SVG format.\nFancy, I like it (â¤ Ï‰ â¤)\n10. Notion  If you need a platform for note-taking, we recommend one option: Notion\nQuick Notes, TaskList, Diary, Reading List, all types, everything, recommended~\nSource: https://mp.weixin.qq.com/s/n71kwdVSLoJatAmCs-djJQ\n","date":"17 Oct, 2021","image":"images/blog/post-3.webp","permalink":"https://codelink.ai/blog/web-development/recommend-10-very-wow-web-resources-to-the-front-end-developers/","tags":["tools","frontend","web"],"title":"Recommend 10 very 'wow' Web 'resources' to the front-end developers"},{"categories":["devops"],"contents":" ag faster than grep, ack recursive search file content.\n tig Interactive view of git projects in character mode, can replace git command.\n mycli mysql client, support syntax highlighting and command completion, similar to ipython, can replace mysql command.\n jq json file processing and formatting display, support highlighting, can replace python -m json.tool.\n shellcheck shell script static checking tool, can identify syntax errors and irregular writing style.\n fzf command line fuzzy search tool, can interactively and intelligently search and select files or content, with terminal ctrl-r history command search is perfect.\n PathPicker(fpp) Automatically identifies directories and files in the command line output, supports interactive, very useful with git.\nRun the following command.\ngit diff HEAD~8 --stat | fpp   htop Provides a more beautiful and convenient process monitoring tool, replacing the top command.\n glances A more powerful alternative to htop / top.\nhtop replaces top, glances replaces htop: htop replaces top, glances replaces htop.\nInformation is much richer and more complete than htop, isn\u0026rsquo;t it? In addition to the command line view, glances also provides a page service that allows you to view the status of a server from the page at any time.\n axel a multi-threaded download tool that can replace curl and wget when downloading files.\naxel -n 20 http://centos.ustc.edu.cn/centos/7/isos/x86_64/CentOS-7-x86_64-Minimal-1511.iso   sz/rz interactive file transfer, very good for transferring files under multiple jumpers, no need to transfer at one level.\n cloc code statistics tool, can count the number of empty lines of code, comment lines, programming language.\n tmux terminal reuse tool, instead of screen, nohup.\n script/scriptreplay Terminal session recording.\n# recording script -t 2\u0026gt;time.txt session.typescript # your commands # end of recording exit # Playback scriptreplay -t time.txt session.typescript  multitail Often you have more than one log file to monitor, what should you do? It takes up too much space to open multiple tabs in the terminal software, try this tool.\nSource: https://mp.weixin.qq.com/s/PkIUB3zTYpTXKcrgZg4f-A\n","date":"13 Sep, 2021","image":"images/blog/Linux.jpeg","permalink":"https://codelink.ai/blog/devops/must-have-linux-tools/","tags":["tools"],"title":"These Linux tools are must-haves! Which one have you used?"}]