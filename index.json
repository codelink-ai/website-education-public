[{"categories":["web development"],"contents":" This article is about manually configuring a front-end project from scratch, which will involve Webpack, React, Babel, TypeScript, Ant Design, Sass, Eslint, Prettier.\nThis article is based on the attitude of \u0026ldquo;don\u0026rsquo;t seek to understand\u0026rdquo;, mainly over the use of each module, suitable for following step by step from zero.\nThe front-end engineering project is built in the node.js environment, after which you need to install various npm packages, so first the computer must have been configured with a node environment.\nCreate a new directory and run npm init to initialize a project.\nnpm init and enter all the way back, it just generates the package.json file, which can be changed later if you want.\nWebpack  The front end is constantly evolving, but many features are not always supported by browsers - ES6 modules, CommonJs modules, Scss/less, jsx, etc. With Webpack we can package all the files, compress and obfuscate them, and finally convert them to browser-aware code.\nIn addition to installing Webpack, we need to install the corresponding command line tool webpack-cli, as well as webpack-dev-server which implements hot-loading, i.e. automatically listens for changes to our files and then refreshes the page.\nSince these tools are only used in the development phase, we can install them with the -D(\u0026ndash;save-dev) command so that the development environment is not packaged.\nnpm i -D webpack webpack-cli webpack-dev-server After installation, package.json will automatically record the node packages we have installed, and the corresponding versions are as follows, some configurations may be slightly different if the installation is different from mine.\n{ ... \u0026#34;devDependencies\u0026#34;: { \u0026#34;webpack\u0026#34;: \u0026#34;^5.51.1\u0026#34;, \u0026#34;webpack-cli\u0026#34;: \u0026#34;^4.8.0\u0026#34;, \u0026#34;webpack-dev-server\u0026#34;: \u0026#34;^4.0.0\u0026#34; } } Next, create a new webpack.config.js in the root directory to configure the project, mainly configuring the entry files, the package loss directory, and the devServer directory.\nconst path = require(\u0026#39;path\u0026#39;) module.exports = { entry: \u0026#39;./src/main.js\u0026#39;, output: { path: path.resolve(__dirname, \u0026#39;./dist\u0026#39;), filename: \u0026#39;bundle.js\u0026#39; }, devServer: { static: path.resolve(__dirname, \u0026#39;./dist\u0026#39;) } } Create the corresponding file above.\nThe main.js file mainly implements writing hello world in the web page.\n// /src/main.js document.write(\u0026#39;hello world\u0026#39;) Create a new dist directory, create a new index.html file inside, and introduce \u0026lt;script src=\u0026quot;bundle.js\u0026quot;\u0026gt;\u0026lt;/script\u0026gt;.\n\u0026lt;!DOCTYPE html\u0026gt; \u0026lt;html\u0026gt; \u0026lt;head\u0026gt; \u0026lt;meta charset=\u0026#34;utf-8\u0026#34;\u0026gt; \u0026lt;meta name=\u0026#34;viewport\u0026#34; content=\u0026#34;width=device-width,initial-scale=1.0\u0026#34;\u0026gt; \u0026lt;title\u0026gt;front end app\u0026lt;/title\u0026gt; \u0026lt;/head\u0026gt; \u0026lt;body\u0026gt; \u0026lt;div id=\u0026#34;app\u0026#34; /\u0026gt; \u0026lt;script src=\u0026#34;bundle.js\u0026#34;\u0026gt;\u0026lt;/script\u0026gt; \u0026lt;/body\u0026gt; \u0026lt;/html\u0026gt; Finally, create two new commands in package.json, the default test command can be deleted directly.\n... \u0026#34;scripts\u0026#34;: { \u0026#34;dev\u0026#34;: \u0026#34;webpack-dev-server --mode development --open\u0026#34;, \u0026#34;build\u0026#34;: \u0026#34;webpack --mode production\u0026#34; }, ... Run npm run dev, which will automatically open http://localhost:8080/.\nReact  React allows us to focus on building the UI without having to manually maintain updates to the dom elements, and of course with VUE.\nInstall the core library react, and react-dom for rendering the web.\nnpm i react react-dom Modify src/main.js to get a taste of it.\n// /src/main.js import React from \u0026#39;react\u0026#39;; import ReactDOM from \u0026#39;react-dom\u0026#39;; class Hello extends React.Component { render() { return React.createElement(\u0026#39;div\u0026#39;, null, `Hello ${this.props.toWhat}`); } } ReactDOM.render( React.createElement(Hello, { toWhat: \u0026#39;World by React\u0026#39; }, null), document.getElementById(\u0026#39;app\u0026#39;) ); npm run dev to see the effect.\nCreateElement to create the element. If the page is complex, it would be too tedious to put one layer on top of the other.\nLet\u0026rsquo;s rewrite it.\n// /src/main.js import React from \u0026#39;react\u0026#39;; import ReactDOM from \u0026#39;react-dom\u0026#39;; class Hello extends React.Component { render() { return \u0026lt;div\u0026gt;Hello {this.props.toWhat}\u0026lt;/div\u0026gt;; } } ReactDOM.render( \u0026lt;Hello toWhat=\u0026#34;World by jsx\u0026#34; /\u0026gt;, document.getElementById(\u0026#39;app\u0026#39;) ); But then you will find that the project does not run\nNow, we need Babel.\nBabel  babel converts syntax and new features into browser-aware js for us. Let\u0026rsquo;s start by installing babel and the babel-loader we use in webpack.\nnpm i -D @babel/core babel-loader Then introduce babel-loader in webpack to convert the js and change the webpack.config.js file.\nconst path = require(\u0026#39;path\u0026#39;) module.exports = { entry: \u0026#39;./src/main.js\u0026#39;, output: { path: path.resolve(__dirname, \u0026#39;./dist\u0026#39;), filename: \u0026#39;bundle.js\u0026#39; }, module: { rules: [ { test: /\\.(js)x?$/, exclude: /node_modules/, use: { loader: \u0026#39;babel-loader\u0026#39;, }, }, ], }, devServer: { static: path.resolve(__dirname, \u0026#39;./dist\u0026#39;) } } Then let\u0026rsquo;s install @babel/preset-react to convert the jsx syntax.\nnpm i -D @babel/preset-react Create a new babel configuration file, babel.config.json, in the root directory.\n// babel.config.json { \u0026#34;presets\u0026#34;: [ \u0026#34;@babel/preset-react\u0026#34; ] } At this point, we can run npm run dev again and see that the project is up and running!\nThen we can install some other babel to use the latest ES syntax, such as arrow functions, async await, question mark expressions, etc., and configure whatever we need. When the browser doesn\u0026rsquo;t support these features, babel can help us implement polyfill to downgrade.\n@babel/preset-env contains many new ES features, and core-js implements ployfill, so with these two babel features you can use all the latest ES features with confidence, and if you don\u0026rsquo;t meet them we can configure the babel plugin separately.\nnpm i -D @babel/preset-env core-js Then we\u0026rsquo;ll modify the babel configuration file.\n// babel.config.json { \u0026#34;presets\u0026#34;: [ [ \u0026#34;@babel/preset-env\u0026#34;, { \u0026#34;useBuiltIns\u0026#34;: \u0026#34;usage\u0026#34;, \u0026#34;corejs\u0026#34;: 3 } ], \u0026#34;@babel/preset-react\u0026#34; ], \u0026#34;plugins\u0026#34;: [ ] } where useBuiltIns\u0026quot;: \u0026quot;usage\u0026quot; means that each file automatically determines whether ployfill is introduced, and corejs: 3 is the specified version.\nTypeScript  More and more projects have introduced TypeScript, especially larger projects, through ts can make some bugs exposed in advance, usually their own development, you can also introduce ts to learn in advance.\nThere are two ways to introduce ts into a project.\nUse TypeScript Compiler (TSC) to compile ts to ES5 so that it can run in the browser. And use TSC for type checking.\nUse Babel to translate TS and use TSC for type checking.\nIn this case, we use the second approach, so that Babel and TSC can each do their job.\nFirst install TypeScript and type for React.\nnpm i -D typescript @types/react @types/react-dom Create a new tsconfig.json in the root directory for the ts configuration.\n// tsconfig.json { \u0026#34;compilerOptions\u0026#34;: { \u0026#34;target\u0026#34;: \u0026#34;es5\u0026#34;, \u0026#34;module\u0026#34;: \u0026#34;commonjs\u0026#34;, \u0026#34;lib\u0026#34;: [ \u0026#34;dom\u0026#34; ], \u0026#34;jsx\u0026#34;: \u0026#34;react\u0026#34;, \u0026#34;noEmit\u0026#34;: true, \u0026#34;sourceMap\u0026#34;: true, /* Strict Type-Checking Options */ \u0026#34;strict\u0026#34;: true, \u0026#34;noImplicitAny\u0026#34;: true, \u0026#34;strictNullChecks\u0026#34;: true, }, \u0026#34;include\u0026#34;: [ \u0026#34;src\u0026#34; ] } \u0026quot;noEmit\u0026quot;: true, indicating that ts only does type checking and does not compile the output.\nThen we modify src/main.js to src/main.tsx and add the type.\n// /src/main.js import * as React from \u0026#39;react\u0026#39;; import * as ReactDOM from \u0026#39;react-dom\u0026#39;; type Props = { toWhat: string; }; type State = { }; class Hello extends React.Component\u0026lt;Props, State\u0026gt; { render() { return \u0026lt;div\u0026gt;Hello {this.props.toWhat}\u0026lt;/div\u0026gt;; } } ReactDOM.render( \u0026lt;Hello toWhat=\u0026#34;World by jsx\u0026#34; /\u0026gt;, document.getElementById(\u0026#39;app\u0026#39;) ); The next step is to configure babel, install @babel/preset-typescript, and convert our code from ts to js.\nnpm i -D @babel/preset-typescript Add it to the babel configuration file.\n// babel.config.json { \u0026#34;presets\u0026#34;: [ \u0026#34;@babel/preset-typescript\u0026#34;, [ \u0026#34;@babel/preset-env\u0026#34;, { \u0026#34;useBuiltIns\u0026#34;: \u0026#34;usage\u0026#34;, \u0026#34;corejs\u0026#34;: 3 } ], \u0026#34;@babel/preset-react\u0026#34; ], \u0026#34;plugins\u0026#34;: [ ] } Finally, add tsx to the path matched by babel in webpack.config.js.\nconst path = require(\u0026#39;path\u0026#39;) module.exports = { entry: \u0026#39;./src/main.tsx\u0026#39;, output: { path: path.resolve(__dirname, \u0026#39;./dist\u0026#39;), filename: \u0026#39;bundle.js\u0026#39; }, module: { rules: [ { test: /\\.(js|ts)x?$/, exclude: /node_modules/, use: { loader: \u0026#39;babel-loader\u0026#39;, }, }, ], }, resolve: { // You can omit these suffixes when introducing modules  extensions: [\u0026#39;.tsx\u0026#39;, \u0026#39;.ts\u0026#39;, \u0026#39;.jsx\u0026#39;, \u0026#39;.js\u0026#39;], }, devServer: { static: path.resolve(__dirname, \u0026#39;./dist\u0026#39;) } } We can install typescript globally to facilitate type checking with the tsc command.\nnpm install -g typescript You can run tsc -w to do type checking in real time.\nAnt Design  Introduce component libraries for faster development.\nnpm install antd By the way, you can extract the hello component from main.tsx and name it app.tsx as usual.\n// /src/App.tsx import * as React from \u0026#39;react\u0026#39;; import { DatePicker } from \u0026#39;antd\u0026#39;; type Props = { toWhat: string; }; type State = { }; class App extends React.Component\u0026lt;Props, State\u0026gt; { render(): JSX.Element { return \u0026lt;div\u0026gt; Hello {this.props.toWhat} \u0026lt;div\u0026gt; \u0026lt;DatePicker\u0026gt;\u0026lt;/DatePicker\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;/div\u0026gt;; } } export default App; Then we introduce antd\u0026rsquo;s css file in main.tsx.\n// /src/main.tsx import * as React from \u0026#39;react\u0026#39;; import * as ReactDOM from \u0026#39;react-dom\u0026#39;; import \u0026#39;antd/dist/antd.css\u0026#39;; import App from \u0026#39;. /App\u0026#39; ReactDOM.render( \u0026lt;App toWhat=\u0026#34;World by jsx\u0026#34; /\u0026gt;, document.getElementById(\u0026#39;app\u0026#39;) ); At this point, you need to install the css loader in the webpack.config.js configuration file, first.\nnpm i -D style-loader css-loader css-loader allows us to introduce css in js, and style-loader helps us to insert css into the page as style tags.\nOnce installed, configure the loader.\nconst path = require(\u0026#39;path\u0026#39;) module.exports = { entry: \u0026#39;. /src/main.tsx\u0026#39;, output: { path: path.resolve(__dirname, \u0026#39;. /dist\u0026#39;), filename: \u0026#39;bundle.js\u0026#39; }, module: { rules: [ { test: /\\. (js|ts)x?$/, exclude: /node_modules/, use: { loader: \u0026#39;babel-loader\u0026#39;, }, }, { test: /\\.css$/i, use: [\u0026#34;style-loader\u0026#34;, \u0026#34;css-loader\u0026#34;], }, ], }, resolve: { // You can omit these suffixes when introducing modules  extensions: [\u0026#39;.tsx\u0026#39;, \u0026#39;.ts\u0026#39;, \u0026#39;.jsx\u0026#39;, \u0026#39;.js\u0026#39;], }, devServer: { static: path.resolve(__dirname, \u0026#39;. /dist\u0026#39;) } } Then the date picker is successfully introduced.\nSass  Sass is a pre-compiler for css, which allows us to write styles more smoothly, specific features can refer to the official website, I use the most is to write css in nested form, very convenient.\nLet\u0026rsquo;s install Sass and its loader.\nnpm install sass-loader sass --save-dev Then configure it in webpack.config.js\nconst path = require(\u0026#39;path\u0026#39;); module.exports = { entry: \u0026#39;. /src/main.tsx\u0026#39;, output: { path: path.resolve(__dirname, \u0026#39;. /dist\u0026#39;), filename: \u0026#39;bundle.js\u0026#39;, }, module: { rules: [ { test: /\\. (js|ts)x?$/, exclude: /node_modules/, use: { loader: \u0026#39;babel-loader\u0026#39;, }, }, { test: /\\.css$/i, use: [\u0026#39;style-loader\u0026#39;, \u0026#39;css-loader\u0026#39;], }, { test: /\\.s[ac]ss$/i, use: [ // Generate JS strings as style nodes  \u0026#39;style-loader\u0026#39;, // Convert CSS into a CommonJS module  \u0026#39;css-loader\u0026#39;, // Compile Sass into CSS  \u0026#39;sass-loader\u0026#39;, ], }, ], }, resolve: { // You can omit these suffixes when introducing modules  extensions: [\u0026#39;.tsx\u0026#39;, \u0026#39;.ts\u0026#39;, \u0026#39;.jsx\u0026#39;, \u0026#39;.js\u0026#39;], }, devServer: { static: path.resolve(__dirname, \u0026#39;. /dist\u0026#39;), }, }; Add a few class names to App.jsx and introduce App.scss.\n// /src/App.tsx import * as React from \u0026#39;react\u0026#39;; import { DatePicker } from \u0026#39;antd\u0026#39;; import \u0026#39;./App.scss\u0026#39;; type Props = { toWhat: string; }; type State = {}; class App extends React.Component\u0026lt;Props, State\u0026gt; { render(): JSX.Element { return ( \u0026lt;div className=\u0026#34;app\u0026#34;\u0026gt; \u0026lt;div className=\u0026#34;text\u0026#34;\u0026gt;Hello\u0026lt;/div\u0026gt; \u0026lt;div\u0026gt;{this.props.toWhat}\u0026lt;/div\u0026gt; \u0026lt;div\u0026gt; \u0026lt;DatePicker\u0026gt;\u0026lt;/DatePicker\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;/div\u0026gt; ); } } export default App; Create a new App.scss and add colors to experiment with it.\n.app { .text { color: #f00; } } npm run dev to see the effect\nEslint  You can configure eslint to do static checks on syntax and also on ts.\nnpm i eslint -D The npm i -g npx command can be installed globally to make it easier to run commands from the node_modules/.bin directory.\nOtherwise, to run the eslint command, we need to run . /node_modules/.bin/eslint --version to get it. Or we can install typescript globally to execute the tsc command as above, or add a custom command to package.json. But npx is the most convenient.\nLet\u0026rsquo;s initialize eslint.\nnpx eslint --init and then select the options according to the project needs, and finally install the dependencies automatically.\nThen eslint automatically generates the .eslintrc.js configuration file for us, with a \u0026quot;node\u0026quot;: true, otherwise module.exports would report an error.\nmodule.exports = { \u0026#34;env\u0026#34;: { \u0026#34;browser\u0026#34;: true, \u0026#34;es2021\u0026#34;: true, \u0026#34;node\u0026#34;: true, }, \u0026#34;extends\u0026#34;: [ \u0026#34;eslint:recommended\u0026#34;, \u0026#34;plugin:react/recommended\u0026#34;, \u0026#34;plugin:@typescript-eslint/recommended\u0026#34; ], \u0026#34;parser\u0026#34;: \u0026#34;@typescript-eslint/parser\u0026#34;, \u0026#34;parserOptions\u0026#34;: { \u0026#34;ecmaFeatures\u0026#34;: { \u0026#34;jsx\u0026#34;: true }, \u0026#34;ecmaVersion\u0026#34;: 12, \u0026#34;sourceType\u0026#34;: \u0026#34;module\u0026#34; }, \u0026#34;plugins\u0026#34;: [ \u0026#34;react\u0026#34;, \u0026#34;@typescript-eslint\u0026#34; ], \u0026#34;rules\u0026#34;: { } }; Then we can add a lint command to package.json to fix the code.\n{ \u0026#34;name\u0026#34;: \u0026#34;fe-learn\u0026#34;, \u0026#34;version\u0026#34;: \u0026#34;1.0.0\u0026#34;, \u0026#34;description\u0026#34;: \u0026#34;web dev study\u0026#34;, \u0026#34;main\u0026#34;: \u0026#34;index.js\u0026#34;, \u0026#34;scripts\u0026#34;: { \u0026#34;dev\u0026#34;: \u0026#34;webpack-dev-server --mode development --open\u0026#34;, \u0026#34;build\u0026#34;: \u0026#34;webpack --mode production\u0026#34;, \u0026#34;lint\u0026#34;: \u0026#34;eslint src --fix\u0026#34; }, \u0026#34;author\u0026#34;: \u0026#34;windliang\u0026#34;, \u0026#34;license\u0026#34;: \u0026#34;ISC\u0026#34;, \u0026#34;devDependencies\u0026#34;: { \u0026#34;@babel/core\u0026#34;: \u0026#34;^7.15.0\u0026#34;, \u0026#34;@babel/preset-env\u0026#34;: \u0026#34;^7.15.0\u0026#34;, \u0026#34;@babel/preset-react\u0026#34;: \u0026#34;^7.14.5\u0026#34;, \u0026#34;@babel/preset-typescript\u0026#34;: \u0026#34;^7.15.0\u0026#34;, \u0026#34;@types/react\u0026#34;: \u0026#34;^17.0.19\u0026#34;, \u0026#34;@types/react-dom\u0026#34;: \u0026#34;^17.0.9\u0026#34;, \u0026#34;@typescript-eslint/eslint-plugin\u0026#34;: \u0026#34;^4.29.2\u0026#34;, \u0026#34;@typescript-eslint/parser\u0026#34;: \u0026#34;^4.29.2\u0026#34;, \u0026#34;babel-loader\u0026#34;: \u0026#34;^8.2.2\u0026#34;, \u0026#34;core-js\u0026#34;: \u0026#34;^3.16.2\u0026#34;, \u0026#34;eslint\u0026#34;: \u0026#34;^7.32.0\u0026#34;, \u0026#34;eslint-plugin-react\u0026#34;: \u0026#34;^7.24.0\u0026#34;, \u0026#34;typescript\u0026#34;: \u0026#34;^4.3.5\u0026#34;, \u0026#34;webpack\u0026#34;: \u0026#34;^5.51.1\u0026#34;, \u0026#34;webpack-cli\u0026#34;: \u0026#34;^4.8.0\u0026#34;, \u0026#34;webpack-dev-server\u0026#34;: \u0026#34;^4.0.0\u0026#34; }, \u0026#34;dependencies\u0026#34;: { \u0026#34;react\u0026#34;: \u0026#34;^17.0.2\u0026#34;, \u0026#34;react-dom\u0026#34;: \u0026#34;^17.0.2\u0026#34; } } Then we can run npm run lint to fix eslint.\nWith Vscode we can also automatically detect eslint as we write and fix eslint related errors when we save.\nYou can install the Eslint plugin and add the following configuration to the vscode settings, which can be edited directly by clicking on the top right corner of the image below.\n{ \u0026#34;eslint.validate\u0026#34;: [\u0026#34;javascript\u0026#34;, \u0026#34;javascriptreact\u0026#34;, \u0026#34;vue\u0026#34;, \u0026#34;typescript\u0026#34;, \u0026#34;typescriptreact\u0026#34;], \u0026#34;editor.codeActionsOnSave\u0026#34;: { \u0026#34;source.fixAll.eslint\u0026#34;: true }, } To use a more complete eslint configuration, we can also directly refer to the Tencent Alloy team\u0026rsquo;s recommended configuration, see here.\nPrettier  prettier is mainly used to check the style of the code, whether the string is double-quoted or single-quoted? How many spaces? Something like that.\nOf course eslint can also be configured for this, but to separate their respective responsibilities, it\u0026rsquo;s best to use prettier to format the code style, so install it first.\nnpm i -D prettier Then create a new configuration file .prettierrc.js, which directly references the Tencent Alloy team\u0026rsquo;s recommended configuration.\n// .prettierrc.js module.exports = { // max 120 characters per line  printWidth: 120, // use 2 spaces for indentation  tabWidth: 2, // use spaces instead of indentations  useTabs: false, // semicolon at the end of the line  semi: true, // use single quotes  singleQuote: true, // object\u0026#39;s key is quoted only when necessary  quoteProps: \u0026#39;as-needed\u0026#39;, // use double quotes instead of single quotes in jsx  jsxSingleQuote: false, // no comma at the end  trailingComma: \u0026#39;all\u0026#39;, // spaces are required at the beginning and end of the braces  bracketSpacing: true, // end tag of jsx need to wrap  jsxBracketSameLine: false, // brackets are required for arrow function parameter, even when there is only one parameter  arrowParens: \u0026#39;always\u0026#39;, // format the entire contents of the file  rangeStart: 0, rangeEnd: Infinity, // no need to write the beginning @prettier of the file  requirePragma: false, // No need to automatically insert @prettier at the beginning of the file  insertPragma: false, // use default break criteria  proseWrap: \u0026#39;preserve\u0026#39;, // decide whether to break the html according to the display style  htmlWhitespaceSensitivity: \u0026#39;css\u0026#39;, // vue files script and style tags indentation  vueIndentScriptAndStyle: false, // lf for newline  endOfLine: \u0026#39;lf\u0026#39;, // formats quoted code embedded  embeddedLanguageFormatting: \u0026#39;auto\u0026#39;, }; Again, to automatically format the code for us when saving, we can install Vscode\u0026rsquo;s Prettier plugin and modify Vscode\u0026rsquo;s configuration again.\n{ \u0026#34;files.eol\u0026#34;: \u0026#34;\\n\u0026#34;, \u0026#34;editor.tabSize\u0026#34;: 2, \u0026#34;editor.formatOnSave\u0026#34;: true, \u0026#34;editor.defaultFormatter\u0026#34;: \u0026#34;esbenp.prettier-vscode\u0026#34;, \u0026#34;eslint.validate\u0026#34;: [\u0026#34;javascript\u0026#34;, \u0026#34;javascriptreact\u0026#34;, \u0026#34;vue\u0026#34;, \u0026#34;typescript\u0026#34;, \u0026#34;typescriptreact\u0026#34;], \u0026#34;editor.codeActionsOnSave\u0026#34;: { \u0026#34;source.fixAll.eslint\u0026#34;: true } } Summary  After going through the above series of operations, you can start to write the project happily.\n Reference\n","date":"09 Jan, 2022","image":"images/blog/web-dev-tools.png","permalink":"https://codelink.ai/blog/web-development/a-2022-guide-to-developing-front-end-projects-from-scratch/","tags":["learn","web","react","babel","typescript","webpack"],"title":"A 2021's Guide to Developing Front-End Projects from Scratch"},{"categories":["web development"],"contents":" If you\u0026rsquo;re a developer just starting out on the Web, this article will help you quickly grasp how the Web works.\nNowadays, various development frameworks are blooming everywhere and evolving more and more powerful. In the workplace, developers often ignore the principles behind each Web framework in order to quickly implement business functions, and it can be easy to forget the basics of the Web.\nWhen you type \u0026ldquo;www.github.com\u0026rdquo; directly into the address bar of your browser, what will the browser do and what are the hidden secrets behind it? Let\u0026rsquo;s unravel the mystery one by one.\nDefinition of network terms  Getting to grips with all things web can be daunting, as there is a lot of expertise involved. Unfortunately, some of these terms are crucial to understanding the rest of this article.\nIf you want to learn the secrets of the World Wide Web, here are the terms that must be mastered.\nClient: An application, such as Chrome or Firefox, that runs on a computer and connects to the Internet. its main role is to take user interactions and convert them into requests to another computer called a Web server. Although we usually use a browser to access the Web, you can think of the entire computer as the \u0026ldquo;client\u0026rdquo; part of the client-server model. Each client computer has a unique address, called an IP address, that other computers can use to identify it.\nServer: A machine that is connected to the Internet and has an IP address. The server waits for requests from other machines (such as clients) and responds to them. Unlike your computer (i.e., the client), which also has an IP address, the server installs and runs special server software that tells it how to respond to incoming requests from browsers. the primary function of a Web server is to store, process, and deliver Web pages to the client. There are several types of servers, including Web servers, database servers, file servers, application servers, and so on. (In this article, we are talking about Web servers.)\nIP address: Internet Protocol address. a numeric identifier for a device (computer, server, printer, router, etc.) on a TCP/IP network. Each computer on the Internet has an IP address, which is used to identify and communicate with other computers. IP addresses have four sets of numbers separated by decimal points (for example, 244.155.65.2). This is called a \u0026ldquo;logical address\u0026rdquo;. To locate a device on a network, the TCP/IP protocol software converts the logical IP address into a physical address. This physical address (i.e., MAC address) is built into your hardware.\nISP: Internet Service Provider. an ISP is the middleman between the client and the server. For the typical homeowner, the ISP is usually a \u0026ldquo;cable company\u0026rdquo;. When your browser receives your request to visit www.github.com, it doesn\u0026rsquo;t know where to look for www.github.com. Therefore, it is the ISP\u0026rsquo;s job to do a DNS (Domain Name System) lookup to ask which IP address is configured for the site you are trying to visit.\nDNS: Domain Name System. A distributed database used to track the domain names of computers on the Internet and their corresponding IP addresses. Now don\u0026rsquo;t worry about how \u0026ldquo;distributed databases\u0026rdquo; work: just know that the DNS exists so that users can enter www.github.com rather than IP addresses.\nDomain name: Used to identify one or more IP addresses. Users use domain names (such as www.github.com) to access websites on the Internet. When you type a domain name into your browser, DNS uses it to find the corresponding IP address for a given website.\nTCP/IP: Transmission Control Protocol/Internet Protocol. The most widely used communication protocol. \u0026ldquo;TCP/IP is used as a standard for transmitting data over the network.\nPort number: A 16-bit integer that identifies a specific port on a server and is always associated with an IP address. It is used as a way to identify a specific process on a server to which a network request can be forwarded.\nHost: A computer connected to the network - it can be a client, a server, or any other type of device. Each host has a unique IP address. For a site like www.google.com, the host can be the web server that serves the pages of the site. There is often some confusion between hosts and servers, but please note that they are two different things. A server is a host - they are a specific machine. A host, on the other hand, can refer to an entire organization that provides hosting services to maintain multiple Web servers. In this sense, you can run a server from a host.\nHTTP: Hypertext Transfer Protocol, a protocol used by Web browsers and Web servers to communicate with each other over the Internet.\nURL: Uniform Resource Locator. a URL identifies a specific Web resource. A simple example is https://github.com/someone. The URL specifies the protocol (\u0026ldquo;https\u0026rdquo;), the host name (github.com), and the file name (someone\u0026rsquo;s profile page). A user can retrieve the Web resource identified by this URL from a Web host with the domain name github.com via HTTP.\nStarting the code to web journey  Okay, now that we have the basic definition, let\u0026rsquo;s look through the Github search to see how we get from a URL entered into the address bar to a running web page.\nYou type a URL into your browser\nThe browser parses the information contained in the URL. This includes the protocol (\u0026ldquo;https\u0026rdquo;), the domain name (\u0026ldquo;github.com\u0026rdquo;), and the resource (\u0026quot;/\u0026quot;). In this case, there is nothing after the \u0026ldquo;.com\u0026rdquo; to indicate a specific resource, so the browser knows to retrieve only the main (index) page\nThe browser communicates with your ISP to perform a DNS lookup of the IP address of the web server hosting www.github.com. The DNS service will first contact the root name server, which will look at the IP address of the name server for the top-level \u0026quot;.com\u0026rdquo; domain of https://www.github.com and reply back with the domain\u0026rsquo;s name server IP address. This address will be sent back to your DNS service. The DNS service performs another outreach to the \u0026quot;.com\u0026quot; name server and asks it to provide https://www.github.com\u0026rsquo;s address.\nOnce the ISP receives the IP address of the target server, it sends it to your web browser\nYour browser gets the IP address and the given port number from the URL (port 80 by default for HTTP protocol and port 443 by default for HTTPS) and opens a TCP socket connection. At this point, your web browser and the web server are finally connected.\nYour web browser sends an HTTP request to the web server to retrieve the www.github.com\u0026rsquo;s HTML page.\nThe web server receives the request and looks for the HTML page. If the page exists, the web server prepares a response and sends it back to your browser. If the server cannot find the requested page, it sends an HTTP 404 error message, which means \u0026ldquo;page not found\u0026rdquo;.\nYour web browser takes the HTML page it receives and then fully parses it to find other assets listed, such as images, CSS files, JavaScript files, etc.\nFor each asset listed, the browser repeats the entire process above, making additional HTTP requests to the server for each resource.\nAfter the browser loads all the other assets listed in the HTML page, the page is finally loaded into the browser window and the connection is closed\nHow is the information transferred?  One thing worth noting is how the information is transferred when you request it. When you make a request, the information is broken down into a number of small pieces called packets. Each packet is marked with a TCP header, which includes the source and destination port numbers, and an IP header, which includes the source and destination IP addresses to give it identity. The packet is then transmitted over an Ethernet, WiFi, or cellular network and is allowed to propagate over any route and make as many hops as necessary to reach its final destination.\n(We don\u0026rsquo;t actually care how the packets get there - what matters is that they get there safely and unharmed!) Once the packets reach their destination, they are reassembled again and delivered as a whole.\nSo how do all the packets know how to get to their destination without being lost?\nThe answer is TCP/IP.\nTCP/IP is a two-part system that acts as the basic \u0026ldquo;control system\u0026rdquo; for the Internet. IP stands for Internet Protocol; its job is to send and route packets to other computers using the IP header (i.e., IP address) on each packet. The second part, Transmission Control Protocol (TCP), is responsible for breaking the message or file into smaller packets, routing the packets to the correct application on the target computer using TCP headers, resending the packets if they are lost along the way, and reassembling the packets in the correct order once they reach the other end.\nDOM tree rendering\nBut wait - the job isn\u0026rsquo;t done yet! Since your browser owns the resources that make up your website (HTML, CSS, JavaScript, images, etc.), it must go through several steps before it can render the resources to you as a human-readable web page.\nYour browser has a rendering engine that is responsible for displaying the content. The rendering engine receives the content of the resource in small chunks. Then there is an HTML parsing algorithm that tells the browser how to parse the resource.\nAfter parsing, it generates a tree structure of DOM elements. the DOM represents the Document Object Model, which is a convention for how objects located in an HTML document are represented. These objects (or \u0026ldquo;nodes\u0026rdquo;) of each document can be manipulated using a scripting language such as JavaScript.\nAfter the DOM tree is built, the style sheet is parsed to understand how to set the style of each node. The browser uses this information to traverse down through the DOM nodes and calculate the CSS style, position, coordinates, etc. for each node.\nOnce the browser has the DOM nodes and their styles, it is finally ready to draw the page to your screen accordingly. The result: everything you\u0026rsquo;ve ever seen on the Internet.\nReference\n","date":"09 Jan, 2022","image":"images/blog/web-dns.webp","permalink":"https://codelink.ai/blog/web-development/in-just-30-minutes-you-will-thoroughly-understand-how-the-web-works/","tags":["learn","web"],"title":"In just 30 minutes, you'll thoroughly understand how the Web works"},{"categories":["devops"],"contents":" I\u0026rsquo;m sure we all use Git to manage our code, and I\u0026rsquo;ve found that we all have more or less delayed Git because we\u0026rsquo;re not familiar with it, for example\n Why did you report detached HEAD again? I can\u0026rsquo;t push it, it\u0026rsquo;s not fast-forwards, what the hell? I want to open source the project I\u0026rsquo;m working on to GitHub, how can I push it to both my company\u0026rsquo;s code platform and GitHub? How do I do code review on GitLab?  The root cause of this is that you haven\u0026rsquo;t learned Git systematically, so you just add, commit, pull, and push.\nCompared to similar software, Git has many advantages. One of them is that it is very easy to branch and merge versions.\nWhile some traditional version management software actually generates a physical copy of the existing code for branching, Git only generates a pointer to the current version (aka \u0026ldquo;snapshot\u0026rdquo;), so it is very fast and easy to use.\nHowever, this convenience can have side effects. If you don\u0026rsquo;t pay attention, you\u0026rsquo;re likely to be left with a repository that is sprawling and open, with branches all over the place, and no trace of the main development.\nSo is there a good branching strategy? The answer is of course yes.\n1. Master branch  First, there should be one and only one master branch of the codebase. All official versions available to users are released on this master branch.\nThe default name of the Git master branch is Master, and it\u0026rsquo;s created automatically, so after the repository is initialized, development is done on the master branch by default.\nThe development branch is called Develop. The master branch is only used for major releases. Daily development should be done on a separate branch. We call the branch for development, Develop.\nThis branch can be used to generate the latest overnight version (nightly) of the code. If you want to release it to the public, you can merge the Develop branch on the Master branch.\nThe Git command to create a Develop branch is\ngit checkout -b develop master The command to publish the Develop branch to the Master branch is\n# switch to the master branch git checkout master # Merge the Develop branch git merge --no-ff develop Here\u0026rsquo;s a little explanation of what the --no-ff parameter means in the previous command. By default, Git performs a \u0026ldquo;fast-farward merge\u0026rdquo;, which points the Master branch directly to the Develop branch.\nWith the --no-ff parameter, a normal merge is performed, creating a new node on the Master branch. We prefer this approach for clarity of version evolution.\n2. Temporary branches  As mentioned earlier, there are two main branches of the repository: Master and Develop, the former is used for official releases and the latter is used for daily development. In fact, these two branches are sufficient for permanent branches, and nothing else is needed.\nHowever, in addition to the permanent branches, there are also some temporary branches that are used to cope with some specific purposes of version development. There are three main types of temporary branches.\n feature (feature) branches pre-release branches fixbug branches  All three of these branches are temporary and should be deleted after use, so that the only permanent branches in the codebase are Master and Develop.\nNext, let\u0026rsquo;s look at these three \u0026ldquo;temporary branches\u0026rdquo; one by one.\n2.1 Feataure branch The first is a feature branch, which is a branch that is split off from the Develop branch to develop a specific feature. When the development is finished, it is merged back into the Develop branch.\nThe name of a feature branch can be in the form of feature-*.\nTo create a feature branch.\ngit checkout -b feature-x develop When development is complete, merge the feature branch into the develop branch: git checkout\ngit checkout develop git merge --no-ff feature-x Delete the feature branch: git branch -d feature-x\ngit branch -d feature-x 2.2 Pre-release branch The second type of branch is the pre-release branch, which is where we may need to have a pre-release version to test before releasing the official version (i.e. before merging into the Master branch).\nThe pre-release branch is split from the Develop branch and must be merged into the Develop and Master branches after the pre-release is finished. It can be named in the form of release-*.\nTo create a pre-release branch.\ngit checkout -b release-1.2 develop Once you\u0026rsquo;ve verified that there are no problems, merge into the master branch:\ngit checkout master git merge --no-ff release-1.2 # Make a tag for the new node created by the merge git tag -a 1.2 Then merge into the develop branch:\ngit checkout develop git merge --no-ff release-1.2 Finally, delete the pre-release branch:\ngit branch -d release-1.2 2.3 Bugfix branch The last type of branch is the bugfix branch. After the software is officially released, it will inevitably have bugs, so you need to create a branch to patch the bugs.\nA bugfix branch is a branch that is split off from the master branch. After fixing, it is merged into the Master and Develop branches. It can be named in the form of fixbug-*.\nTo create a fixbug branch.\ngit checkout -b fixbug-0.1 master After the fix is done, merge it into the master branch:\ngit checkout master git merge --no-ff fixbug-0.1 git tag -a 0.1.1 Then merge into the develop branch:\ngit checkout develop git merge --no-ff fixbug-0.1 Finally, delete the \u0026ldquo;fixbug branch\u0026rdquo;:\ngit branch -d fixbug-0.1 Reference\n","date":"09 Jan, 2022","image":"images/blog/git.png","permalink":"https://codelink.ai/blog/devops/my-girlfriend-messed-up-with-git-and-almost-deleted-my-code/","tags":["learning","git"],"title":"My girlfriend messed up with Git and almost deleted my code!"},{"categories":["python"],"contents":" Asynchronous tasks are the most common requirement in web backend development, and are ideal for multitasking and highly concurrent scenarios. This article shares how to use docker-compose, FastAPI, and rq to quickly create a REST API that contains a cluster of asynchronous task queues, and the nodes that execute the tasks on the backend can scale at will.\nArchitecture diagram of the system.\nEach box in the above diagram can be interpreted as a server.\nThe user requests the api, the api puts the tasks into the redis queue, the worker automatically goes to the redis queue to retrieve the tasks and execute them, and the worker nodes can be scaled horizontally at will.\nNext, let\u0026rsquo;s implement a demo of this architecture, and you can see the power and convenience of docker.\n1 Installing dependencies  dependencies on fastapi, redis, and rq libraries, and generate a requirements.txt file after installation\nmkdir myproject python3 -m venv env source env/bin/activate pip install rq pip install fastapi pip install redis pip freeze \u0026gt; requirements.txt 2 Coding the REST API Worker  REST is a style that is not the focus here. We use FastAPI to quickly create an interface by creating a new api.py file with the following content.\nfrom fastapi import FastAPI from redis import Redis from rq import Queue from worker import send_captcha app = FastAPI() # Note that host is the host name, which is the service name in docker, and the service name in docker-compose.ymal will be the same redis_conn = Redis(host=\u0026#39;myproj_redis\u0026#39;, port=6379, db=0) # Define a queue with the name my_queue q = Queue(\u0026#39;my_queue\u0026#39;, connection=redis_conn) @app.get(\u0026#39;/hello\u0026#39;) def hello(): \u0026#34;\u0026#34;\u0026#34;Test endpoint\u0026#34;\u0026#34;\u0026#34;\u0026#34; return {\u0026#39;hello\u0026#39;: \u0026#39;world\u0026#39;} # Rest API example @app.post(\u0026#39;/send_captcha/{phone_number}\u0026#39;, status_code=201) def addTask(phone_number: str): \u0026#34;\u0026#34;\u0026#34; Adds tasks to worker queue. Expects body as dictionary matching the Group class. \u0026#34;\u0026#34;\u0026#34; job = q.enqueue(send_captcha, phone_number) return {\u0026#39;job\u0026#39;: \u0026#34;tasks add done.\u0026#34;} The send_captcha function here is an asynchronous task, imported from worker.py, which looks like this\nimport time def send_captcha(phone_number): \u0026#34;\u0026#34;\u0026#34; Simulate a time-consuming asynchronous task \u0026#34;\u0026#34;\u0026#34; print(f\u0026#39;{time.strftime(\u0026#34;%T\u0026#34;)}ready to send phone captcha\u0026#39;) # in place of actual logging print(f\u0026#39;{time.strftime(\u0026#34;%T\u0026#34;)}generating random captcha and storing it in redis, setting 5 minutes to expire\u0026#39;) time.sleep(5) # simulate long running task print(f\u0026#39;{time.strftime(\u0026#34;%T\u0026#34;)}{phone_number}sending complete\u0026#39;) return { phone_number: \u0026#39;task complete\u0026#39;} 3 Building the Dokcer image The goal now is to implement a cluster with two execution nodes. We need to start 4 containers to complete a cluster deployment.\n Container 1: running the FastAPI app Container 2: running the Redis service Container 3: running worker 1 service Container 4: running worker 2 service  Containers 1, 3, and 4 are all Python applications and can share a single Python image.\nTo facilitate debugging, we can make containers 1, 3, and 4 share our local path so that we don\u0026rsquo;t need to rebuild the image if we change the code, which is more convenient.\nCreating a Python image with dependencies\nNow let\u0026rsquo;s create a Python image that contains the previous requirements.txt dependency, and write a Dockerfile with the following content.\nFROMpython:3.8-alpine RUN adduser -D myproj WORKDIR/home/myproj COPY requirements.txt requirements.txt RUN pip install -r requirements.txt RUN chown -R myproj:myproj . / USERmyproj CMD uvicorn api:app --host 0.0.0.0 --port 5057 Content Description.\nFROMpython:3.8-alpine Specify python:3.8-alpine, a container with Python 3.8 pre-installed, and run docker search python from the command line to see what Python images are available.\nRUN adduser -D myproj Add a user myproj, the main purpose of this step is to generate the directory /home/myproj\nWORKDIR/home/myproj Set the execution path of the program to /home/myproj\nCOPY requirements.txt requirements.txt Copy requirements.txt from the current path to /home/myproj in the container. The .py file is not copied here because we will share the local path when we start the container later, so we don\u0026rsquo;t need to copy it anymore.\nRUN pip install -r requirements.txt Install the dependencies in the container\nRUN chown -R myproj:myproj . / Change the owner and group of the files under the /home/myproj path to myproj, this step is to use the myproj user to start the fastapi service, production environments usually start with the root user, so this command is not needed.\nUSERmyproj Switch to the myproj user\nCMD uvicorn api:app --host 0.0.0.0 --port 5057 The command to execute after the container is started, with service port 5057\nPlease refer to the official documentation for more Dockerfile syntax, this is only a brief description.\nNow run the following command to build an image in the directory where the Dockerfile is located.\ndocker build -t myproject:latest . Once created, you can use docker images to view it.\n‚ùØ docker images | grep myproj myproject latest 6d4c3a7f5e34 13 hours ago 58.5MB 4 Starting the cluster  Here we use Docker Compose to start 4 containers, why use Docker Compose? Because it is convenient, if you don\u0026rsquo;t use it, you need to start one container by one container manually.\nDocker Compose reads a configuration file in yaml format and starts containers based on the configuration file, and each container shares the same network. Remember the Redis hostname used in api.py, here you need to set the redis service name to that hostname.\nWrite a docker-compose.yml that reads\nversion: \u0026#39;3\u0026#39; services: myproj_redis: image: redis:4.0-alpine ports: - \u0026#34;6379:6379\u0026#34; volumes: - . /redis:/data myproj_api: image: myproject:latest command: uvicorn api:app --host 0.0.0.0 --port 5057 ports: - \u0026#34;5057:5057\u0026#34; volumes: - . /:/home/myproj myproj_worker1: image: myproject:latest command: rq worker --url redis://myproj_redis:6379 my_queue volumes: - . /:/home/myproj myproj_worker2: image: myproject:latest command: rq worker --url redis://myproj_redis:6379 my_queue volumes: - . /:/home/myproj The first container is myproj_redis, running the redis service. redis data is stored locally via volumes, so you need to create a local redis directory to map the /data directory inside the container.\nThe second container is the fastapi service on port 5057, using the local path mapped to /home/myproj\nThe third and fourth container is the worker node, which also maps to a local path, but only uses the worker.py file. When there are too many tasks, the worker node can be extended to solve the load pressure.\nThe final directory looks like this.\nExecute the docker compose command to start 4 containers:\ndocker compose -f docker-compose.yml up You can see that all 4 services are up and printing the log output normally.\n5 Testing  Now let\u0026rsquo;s test the window on the left, where I quickly sent 3 post requests using Python:\nimport subprocess for i in range(3): subprocess.run(\u0026#34;curl -v -X POST \u0026#39;http://localhost:5057/send_captcha/18012345678\u0026#39;\u0026#34;,shell = True) The log output shows that both worker1 and worker2 have executed tasks, with worker1 executing 2 and worker2 executing 1.\nReference\n","date":"09 Jan, 2022","image":"images/blog/python.png","permalink":"https://codelink.ai/blog/python/how-to-quickly-create-a-rest-api-with-a-cluster-of-asynchronous-task-queues/","tags":["learning","redis","fastapi","REST API"],"title":"How to quickly create a REST API with a cluster of asynchronous task queues"},{"categories":["devops"],"contents":" We will be sharing several ways to run background tasks under linux: \u0026amp;, nohup, ctrl + z, jobs, fg, bg, and screen commands.\n1. Introduction of the problem  The most intolerable thing for programmers is that when using the terminal, often because of the network, close the screen, perform CTRL + C and other reasons caused ssh disconnected caused by running programs to exit, making our work lost.\nThe main reason behind the above-mentioned operations, the shell by default will send an interrupt signal to the terminal session associated with the process, thus causing the process to follow the terminal exit, in order to clarify this issue we first need to understand the two interrupt signals:\n  sigint: signal interrupt, ctrl+c will send this signal to actively close the program\n  sighup: signal hang up, close the terminal, network disconnection, close the screen will send this hang up signal.\n  Today, we will introduce several methods of executing background tasks in linux to avoid the above problems.\n2. \u0026amp; symbol  This is a kind of \u0026amp; at the end of the execution command, so that the program started to ignore the sigint signal, at this time the execution of ctrl + c close will not close the process, but when the screen is closed, disconnected from the network will still cause the process to exit.\nsh test.sh \u0026amp; 3. nohup command  nohup (no hang up), meaning no hang up, run command with nohup can make the command execute permanently, and there is no relationship with the user terminal, disconnect SSH does not affect the operation, nohup captures the SIGHUP, and do ignore the processing, so when the screen is closed, disconnected, etc. cause ssh interruption process will not exit. But ctrl+c can close the process to shut it down. So in most cases programs that are started with both nohup and \u0026amp;, ctrl+c and closing the terminal will not close them. By default all output is redirected to a file called nohup.out.\nThe basic usage format of the nohup command is\nnohup Command [ Arg ... ] [ \u0026amp; ] Example\nExecute without interruption in the background. /test.sh, stdout is output to out.log, stderr is output to err.log\nnohup . /test.sh \u0026gt; out.log 2\u0026gt;err.log \u0026amp; The meaning of the associated numbers is as follows.\n0 - stdin (standard input). 1 - stdout (standard output), obviously nohup command \u0026gt; out.log is equivalent to nohup command 1\u0026gt; out.log, which is the default behavior. 2 - stderr (standard error)\nYou may also see this written in such a way that it means that stderr is also redirected to stdin\nnohup . /test.sh \u0026gt; out.log 2\u0026gt;\u0026amp;1 \u0026amp; 4. ctrl + z, jobs, fg, bg  What if our program doesn\u0026rsquo;t use \u0026amp;, nohup at startup? Do we need to execute ctrl + c to terminate the process executing in the foreground before restarting it? There\u0026rsquo;s obviously a good way to do it!\n4.1 ctrl + z Put a job process that is executing in the foreground into the background and suspend it, or in terminology, hang it, and then execute it as follows.\n[1]+ Stopped . /test.sh 4.2 jobs Check how many commands are currently running in the background, [jobnumber] is the job number.\njobs [1]+ Stopped . /test.sh [2]+ Running . /test2.sh \u0026amp; 4.3 bg Continue running a suspended (hung) job in the background, e.g. put job #1 (. /test.sh) into the background, and note that it is already running with \u0026amp;\nbg 1 [1]+ . /test.sh \u0026amp; 4.4 fg Move the job process in the background to the foreground to continue running, e.g. move job #2 (. /test2.sh \u0026amp;) to the foreground\nfg 2 . /test2.sh 5. screen commands  5.1 Introduction If the above method implements front and backend task scheduling through linux-related commands themselves, screen offers another way of thinking.\nThe non-human version: GNU Screen is a free software developed by the GNU Project for command-line terminal switching. GNU Screen can be thought of as a command-line interface version of the Window Manager. It provides a unified interface for managing multiple sessions and the corresponding functions.\nThe human version: We can roughly think of screen as a virtual terminal software that starts another background program directly inside the linux system that takes over (maintains) your terminal session, so that when your directly connected terminal ssh is disconnected, it still makes the program think that your ssh is continuously connected, so that the process does not receive an interruption signal and exit.\n5.2 Installation yum install screen 5.3 Using  Create a new session  screen -S yourname -\u0026gt; create a new session called yourname List all current sessions  screen -ls Resume the session (back to the session called yourname)  screen -r yourname detach a session  screen -d yourname -\u0026gt; detach a session remotely screen -d -r yourname -\u0026gt; end the current session and return to the session yourname Delete the session  screen -S pid-X quit Source\n","date":"09 Jan, 2022","image":"images/blog/linux.png","permalink":"https://codelink.ai/blog/devops/several-ways-to-run-background-tasks-under-linux/","tags":["learning","linux"],"title":"Several ways to run background tasks under linux"},{"categories":["python","performance"],"contents":" 1. confusing operations  This section compares some of Python\u0026rsquo;s more confusing operations.\n1.1 Random sampling with and without put-back import random random.choices(seq, k=1) # list of length k, with put-back sampling random.sample(seq, k) # list of length k, without put-back sampling 1.2 Parameters of the lambda function func = lambda y: x + y # The value of x is bound at function runtime func = lambda y, x=x: x + y # The value of x is bound at function definition time 1.3 copy and deepcopy import copy y = copy.copy(x) # only the topmost level is copied y = copy.deepcopy(x) # Copy all nested parts Copy and variable aliasing are confusing when combined with.\na = [1, 2, [3, 4]] # Alias. b_alias = a assert b_alias == a and b_alias is a # Shallow copy. b_shallow_copy = a[:] assert b_shallow_copy == a and b_shallow_copy is not a and b_shallow_copy[2] is a[2] # Deep copy. import copy b_deep_copy = copy.deepcopy(a) assert b_deep_copy == a and b_deep_copy is not a and b_deep_copy[2] is not a[2] Changes to the alias affect the original variable. The elements in the (shallow) copy are aliases of the elements in the original list, while the deep copy is made recursively, and changes to the deep copy do not affect the original variable. 1.4 == and is x == y # whether the two references have the same value x is y # whether the two references point to the same object 1.5 Determining the type type(a) == int # Ignore polymorphic features in object-oriented design isinstance(a, int) # takes into account the polymorphic features of object-oriented design 1.6 String Search str.find(sub, start=None, end=None); str.rfind(...) # Return -1 if not found str.index(sub, start=None, end=None); str.rindex(...) # Throw a ValueError exception if not found 1.7 List backward indexing This is just a matter of habit, forward indexing when the subscript starts from 0, if the reverse index also want to start from 0 can use ~.\nprint(a[-1], a[-2], a[-3]) print(a[~0], a[~1], a[~2]) 2. C/C++ User\u0026rsquo;s Guide  Many Python users migrated from C/C++, and there are some differences in syntax and code style between the two languages, which are briefly described in this section.\n2.1 Very Large Numbers and Very Small Numbers Whereas the C/C++ convention is to define a very large number, Python has inf and -inf\na = float(\u0026#39;inf\u0026#39;) b = float(\u0026#39;-inf\u0026#39;) 2.2 Boolean values While the C/C++ convention is to use 0 and non-0 values for True and False, Python recommends using True and False directly for Boolean values.\na = True b = False 2.3 Determining Null The C/C++ convention for null pointers is if (a) and if (!a); Python for None is\nif x is None:s pass If you use if not x, you will treat all other objects (such as strings of length 0, lists, tuples, dictionaries, etc.) as False.\n2.4 Swapping values The C/C++ convention is to define a temporary variable that can be used to swap values. With Python\u0026rsquo;s Tuple operation, you can do this in one step.\na, b = b, a 2.5 Comparing The C/C++ convention is to use two conditions. With Python, you can do this in one step.\nif 0 \u0026lt; a \u0026lt; 5: pass 2.6 Set and Get Class Members The C/C++ convention is to set class members to private and access their values through a series of Set and Get functions. While it is possible to set the corresponding Set and Get functions in Python via @property, @setter, and @deleter, we should avoid unnecessary abstraction, which can be 4 - 5 times slower than direct access.\n2.7 Input and output parameters of functions It is customary in C/C++ to list both input and output parameters as arguments to a function, and to change the value of the output parameter via a pointer. The return value of a function is the execution state, and the function caller checks the return value to determine whether it was successfully executed. In Python, there is no need for the function caller to check the return value, and the function throws an exception directly when it encounters a special case.\n2.8 Reading Files Reading a file in Python is much simpler than in C/C++. The opened file is an iterable object that returns one line at a time.\nwith open(file_path, \u0026#39;rt\u0026#39;, encoding=\u0026#39;utf-8\u0026#39;) as f: for line in f: print(line) # The \\n at the end is preserved 2.9 File path splicing Python\u0026rsquo;s os.path.join automatically adds a / or \\ separator between paths, depending on the operating system.\nimport os os.path.join(\u0026#39;usr\u0026#39;, \u0026#39;lib\u0026#39;, \u0026#39;local\u0026#39;) 2.10 Parsing command-line options While Python can use sys.argv to parse command-line options directly, as in C/C++, the ArgumentParser utility under argparse is more convenient and powerful.\n2.11 Calling External Commands While Python can use os.system to invoke external commands directly, as in C/C++, you can use subprocess.check_output to freely choose whether to execute the shell or not, and to get the results of external command execution.\nimport subprocess # If the external command returns a non-zero value, throw a subprocess.CalledProcessError exception result = subprocess.check_output([\u0026#39;cmd\u0026#39;, \u0026#39;arg1\u0026#39;, \u0026#39;arg2\u0026#39;]).decode(\u0026#39;utf-8\u0026#39;) # Collect both standard output and standard errors result = subprocess.check_output([\u0026#39;cmd\u0026#39;, \u0026#39;arg1\u0026#39;, \u0026#39;arg2\u0026#39;], stderr=subprocess.STDOUT).decode(\u0026#39;utf-8\u0026#39;) # Execute shell commands (pipes, redirects, etc.), you can use shlex.quote() to double quote the arguments to cause result = subprocess.check_output(\u0026#39;grep python | wc \u0026gt; out\u0026#39;, shell=True).decode(\u0026#39;utf-8\u0026#39;) 2.12 Do not repeat the wheel Don\u0026rsquo;t build wheels repeatedly. Python is called batteries included, which means that Python provides solutions to many common problems.\n3. Common tools  3.1 Reading and writing CSV files import csv # Read and write without header with open(name, \u0026#39;rt\u0026#39;, encoding=\u0026#39;utf-8\u0026#39;, newline=\u0026#39;\u0026#39;) as f: # newline=\u0026#39;\u0026#39; lets Python not handle line feeds uniformly for row in csv.reader(f): print(row[0], row[1]) # CSV reads all data as str with open(name, mode=\u0026#39;wt\u0026#39;) as f: f_csv = csv.writer(f) f_csv.writerow([\u0026#39;symbol\u0026#39;, \u0026#39;change\u0026#39;]) # Read and write with header with open(name, mode=\u0026#39;rt\u0026#39;, newline=\u0026#39;\u0026#39;) as f: for row in csv.DictReader(f): print(row[\u0026#39;symbol\u0026#39;], row[\u0026#39;change\u0026#39;]) with open(name, mode=\u0026#39;wt\u0026#39;) as f: header = [\u0026#39;symbol\u0026#39;, \u0026#39;change\u0026#39;] f_csv = csv.DictWriter(f, header) f_csv.writeheader() f_csv.writerow({\u0026#39;symbol\u0026#39;: xx, \u0026#39;change\u0026#39;: xx}) When csv file is too large, there will be an error. _csv.Error: field larger than field limit (131072), fix by changing the limit\nimport sys csv.field_size_limit(sys.maxsize) csv can also read data split by \\t\nf = csv.reader(f, delimiter=\u0026#39;\\t\u0026#39;) 3.2 Iterator tools A number of iterator tools are defined in itertools, such as the subsequence tool.\nimport itertools itertools.islice(iterable, start=None, stop, step=None) # islice(\u0026#39;ABCDEF\u0026#39;, 2, None) -\u0026gt; C, D, E, F itertools.filterfalse(predicate, iterable) # Filter out elements whose predicate is False # filterfalse(lambda x: x \u0026lt; 5, [1, 4, 6, 4, 1]) -\u0026gt; 6 itertools.takewhile(predicate, iterable) # stop iterating when predicate is False # takewhile(lambda x: x \u0026lt; 5, [1, 4, 6, 4, 1]) -\u0026gt; 1, 4 itertools.dropwhile(predicate, iterable) # start iterating when predicate is False # dropwhile(lambda x: x \u0026lt; 5, [1, 4, 6, 4, 1]) -\u0026gt; 6, 4, 1 itertools.compress(iterable, selectors) # select based on whether each element of selectors is True or False # compress(\u0026#39;ABCDEF\u0026#39;, [1, 0, 1, 0, 1, 1]) -\u0026gt; A, C, E, F Sequence sorting.\nsorted(iterable, key=None, reverse=False) itertools.groupby(iterable, key=None) # group by value, iterable needs to be sorted first # groupby(sorted([1, 4, 6, 4, 1])) -\u0026gt; (1, iter1), (4, iter4), (6, iter6) itertools.permutations(iterable, r=None) # Arrange, return value is Tuple # permutations(\u0026#39;ABCD\u0026#39;, 2) -\u0026gt; AB, AC, AD, BA, BC, BD, CA, CB, CD, DA, DB, DC itertools.combinations(iterable, r=None) # Combinations, return value is Tuple itertools.combinations_with_replacement(...) # combinations(\u0026#39;ABCD\u0026#39;, 2) -\u0026gt; AB, AC, AD, BC, BD, CD Multiple sequences are merged.\nitertools.chain(*iterables) # Multiple sequences directly concatenated # chain(\u0026#39;ABC\u0026#39;, \u0026#39;DEF\u0026#39;) -\u0026gt; A, B, C, D, E, F import heapq heapq.merge(*iterables, key=None, reverse=False) # Multiple sequences in order # merge(\u0026#39;ABF\u0026#39;, \u0026#39;CDE\u0026#39;) -\u0026gt; A, B, C, D, E, F zip(*iterables) # Stop when the shortest sequence is exhausted, the result can only be consumed once itertools.zip_longest(*iterables, fillvalue=None) # Stop when the longest sequence is exhausted, the result can only be consumed once 3.3 Counters A counter counts the number of occurrences of each element in an iterable object.\nimport collections # Create collections.Counter(iterable) # frequency collections.Counter[key] # frequency of key occurrences # return the n most frequent elements and their corresponding frequencies, if n is None, return all elements collections.Counter.most_common(n=None) # Insert/Update collections.Counter.update(iterable) counter1 + counter2; counter1 - counter2 # counter plus or minus # Check if two strings have the same constituent elements collections.Counter(list1) == collections.Counter(list2) 3.4 Dict with default values When accessing a non-existent Key, defaultdict will set it to some default value.\nimport collections collections.defaultdict(type) # When a dict[key] is accessed for the first time, type is called without arguments, providing an initial value for the dict[key]. 3.5 Ordered Dict import collections OrderedDict(items=None) # Preserve the original insertion order when iterating 4. High Performance Programming and Debugging  4.1 Outputting error and warning messages Outputting messages to standard errors\nimport sys sys.stderr.write(\u0026#39;\u0026#39;) Exporting warning messages\nimport warnings warnings.warn(message, category=UserWarning) # The values of category are DeprecationWarning, SyntaxWarning, RuntimeWarning, ResourceWarning, FutureWarning Control the output of warning messages\n$ python -W all # Output all warnings, equivalent to setting warnings.simplefilter(\u0026#39;always\u0026#39;) $ python -W ignore # Ignore all warnings, equivalent to setting warnings.simplefilter(\u0026#39;ignore\u0026#39;) $ python -W error # Convert all warnings to exceptions, equivalent to setting warnings.simplefilter(\u0026#39;error\u0026#39;) 4.2 Testing in code Sometimes for debugging purposes, we want to add some code to our code, usually some print statements, which can be written as.\n# in the debug part of the code if __debug__: pass Once debugging is over, this part of the code will be ignored by executing the -O option on the command line:\n$ python -0 main.py 4.3 Code style checking Using pylint, you can perform a number of code style and syntax checks to catch errors before running\npylint main.py 4.4 Code consumption Time consumption tests\n$ python -m cProfile main.py Test a block of code for time consumption\n# block definition from contextlib import contextmanager from time import perf_counter @contextmanager def timeblock(label): tic = perf_counter() try: yield finally: toc = perf_counter() print(\u0026#39;%s: %s\u0026#39; % (label, toc - tic)) # Code block time consumption test with timeblock(\u0026#39;counting\u0026#39;): pass Some principles of code consumption optimization\n Focus on optimizing where performance bottlenecks occur, not on the entire code. Avoid using global variables. Local variables are faster to find than global variables, and running code with global variables defined in a function is typically 15-30% faster. Avoid using . to access properties. It is faster to use from module import name and to put the frequently accessed class member variable self.member into a local variable. Use built-in data structures as much as possible. str, list, set, dict, etc. are implemented in C and run quickly. Avoid creating unnecessary intermediate variables, and copy.deepcopy(). String splicing, e.g. a + ':' + b + ':' + c creates a lot of useless intermediate variables, ':'.join([a, b, c]) is much more efficient. Also consider whether string splicing is necessary; for example, print(':'.join([a, b, c])) is less efficient than print(a, b, c, sep=':').  5. Other Python tricks  5.1 argmin and argmax items = [2, 1, 3, 4] argmin = min(range(len(items)), key=items.__getitem__) argmax is the same.\n5.2 Transposing two-dimensional lists A = [[\u0026#39;a11\u0026#39;, \u0026#39;a12\u0026#39;], [\u0026#39;a21\u0026#39;, \u0026#39;a22\u0026#39;], [\u0026#39;a31\u0026#39;, \u0026#39;a32\u0026#39;]] A_transpose = list(zip(*A)) # list of tuple A_transpose = list(list(col) for col in zip(*A)) # list of list 5.3 Expanding a one-dimensional list into a two-dimensional list A = [1, 2, 3, 4, 5, 6] # Preferred. list(zip(*[iter(A)] * 2)) Reference\n","date":"08 Jan, 2022","image":"images/blog/python.png","permalink":"https://codelink.ai/blog/python/python-usage-and-high-performance-tips-summary/","tags":["learning"],"title":"Python Usage and High Performance Tips Summary"},{"categories":["python"],"contents":" Saleor is a fast-growing open source e-commerce platform based on Python and Django, and is constantly being updated, so don\u0026rsquo;t worry about the old version.\nIt has the following features:\n GraphQL API: GraphQL-based implementation of the front and back end separation , belonging to the cutting-edge technology . Dashboard: Administrators have full control over users, processes and products. Order: Integrated system for orders, shipments and refunds. Shopping cart: advanced payment and tax options, support for discounts and promotions Payments: Flexible API architecture allows integration of any payment method Geo-Adaptive: Automatic support for multi-country checkout experience Cloud deployment support: Docker deployment support. Support Google Analytics: Integrated with Google Analytics, you can easily analyze traffic going and staying.   Saleor repository address: https://github.com/mirumee/saleor\n 1. Deployment Guide  Saleor supports a variety of ways to run, you can use the manual installation and run the way, you can also use Docker to run, the following is to introduce the platform-wide common and the simplest Docker deployment scheme.\nBefore following the instructions below, you need to install Docker Desktop and Docker Compose, if you haven\u0026rsquo;t done so, you can check out this tutorial:\n https://www.runoob.com/docker/docker-tutorial.html\n Docker deployment of Saleor is very easy, you just need to clone the repository and build the image and run the service.\n# Python Practical Dictionary # Cloning a repository git clone https://github.com/mirumee/saleor-platform.git --recursive --jobs 3 cd saleor-platform # Build the Docker image docker-compose build Saleor uses shared folders to enable live code reloading. If you are using Windows or MacOS, you will need to.\n  Place the cloned saleor-platform directory into Docker\u0026rsquo;s shared directory configuration (Settings -\u0026gt; Shared Drives or Preferences -\u0026gt; Resources -\u0026gt; File sharing).\n  Make sure you have at least 5 GB of dedicated memory in Docker preferences (Settings -\u0026gt; Advanced or Preferences -\u0026gt; Resources -\u0026gt; Advanced)\n  Execute database migrations and package front-end resources.\ndocker-compose run --rm api python3 manage.py migrate docker-compose run --rm api python3 manage.py collectstatic --noinput (Optional) Populate the database with sample data.\ndocker-compose run --rm api python3 manage.py populatedb Finally, create an administrator account for yourself: docker-compose run --rm\ndocker-compose run --rm api python3 manage.py createsuperuser Run the service:\nRun Saleor with the following command:\ndocker-compose up  2. Introduction to the architecture  If you want to develop based on Saleor, then you must understand its architecture.\nSaleor consists of three important components.\n  Saleor Core, which is the backend server for the GraphQL API. Based on Django, it uses PostgreSQL as the database and stores some cached information in Redis.\n  Saleor Dashboard, a dashboard that can be used to run a store. It\u0026rsquo;s a static website, so it doesn\u0026rsquo;t have any backend code of its own, it\u0026rsquo;s a React application that talks to the Saleor Core server.\n  Saleor Storefront, this is the sample store based on React implementation, you can customize this part of the code to meet your own needs or you can build a custom storefront using Saleor SDK.\n  All three components use GraphQL to communicate via HTTPS.\n3. Extended Development  Although you can develop directly from the Saleor source code, it is not officially recommended to do so because if your code conflicts with the official Saleor source code, it will be difficult to keep up with the official updates and you will end up in an awkward situation where no one will maintain the code.\nTherefore Saleor provides two ways to add features:\n  Plug-in functionality: Plug-ins provide an ability to run additional code on Saleor Core and have access to the database.\n  APPS: Develop APP based on GraphQL API and Saleor Core, and also use WebHooks to subscribe to events.\n  Below we describe how to develop extensions based on plugins.\nAs shown above, Saleor Core provides a callback notification event to the plug-in, based on which the plug-in can perform related operations and interact with the database.\nTo develop a plug-in, you must inherit the BasePlugin base class and override some of the methods, such as the following example, which overrides the postprocess_order_creation method to add some operations to the order creation process.\n# Python Utility Dictionary # custom/plugin.py from django.conf import settings from urllib.parse import urljoin from . .base_plugin import BasePlugin from .tasks import api_post_request_task class CustomPlugin(BasePlugin): def postprocess_order_creation(self, order: \u0026#34;Order\u0026#34;, previous_value: Any): # Order creation operations data = ... transaction_url = urljoin(settings.CUSTOM_API_URL, \u0026#34;transactions/createoradjust\u0026#34;) api_post_request_task.delay(transaction_url, data) To load a plugin, you need to configure setup.py to automatically discover the installed plugins. To make the plugins discoverable, you need to set the saleor_plugins field of entry_points, and define the plugins using this syntax: package_name = package_name.path.to:PluginClass.\nThe example is as follows.\n# setup.py from setuptools import setup setup( ... , entry_points={ \u0026#34;saleor.plugins\u0026#34;: [ \u0026#34;my_plugin = my_plugin.plugin:MyPlugin\u0026#34; ] } ) If your plugin is a Django application, the package name (the part before the equal sign) will be added to Django\u0026rsquo;s INSTALLED_APPS so that you can take advantage of Django features such as ORM integration and database migration.\nNotice that our previous order creation operation uses the .delay syntax, which is an asynchronous task for Celery. Since some plugin operations should be done asynchronously, Saleor uses Celery and will find all the asynchronous tasks declared by tasks.py in the plugin directory.\n# custom_plugin/tasks.py import json from celery import shared_task from typing import Any, Dict import requests from requests.auth import HTTPBasicAuth from django.conf import settings @shared_task def api_post_request( url: str, data: Dict[str, Any], ): try: username = \u0026#34;username\u0026#34; password = \u0026#34;password\u0026#34; auth = HTTPBasicAuth(username, password) requests.post(url, auth=auth, data=json.dumps(data), timeout=settings.TIMEOUT) except requests.exceptions.RequestException: return The above api_post_request function is the asynchronous task used by the previous plugin. After the plugin calls the delay method, the task will be stuffed into the queue and executed asynchronously.\nThe above is a simple example of plug-in development, I personally think Saleor\u0026rsquo;s development model is still very good. If you need, you can use this project to build a mall of their own.\nSource\n","date":"04 Jan, 2022","image":"images/blog/saleor.webp","permalink":"https://codelink.ai/blog/python/deploy-a-gorgeous-python-open-source-e-commerce-project-saleor/","tags":["deployment","e-commerce"],"title":"Deploy a gorgeous Python open source e-commerce project - Saleor"},{"categories":["data science"],"contents":" DeepFaceLive is a real time face replacement software, one click installation, newbie friendly, and you can\u0026rsquo;t see any mistakes after face replacement.\nDemo  Welcome to \u0026ldquo;DeepFace Live\u0026rdquo;!\nNo need for plastic surgery! No minimally invasive!\nDouble eyelid, eye opening, face slimming are not a problem!\nYou will become a handsome man and a beautiful woman in seconds!\nLet me show you the very mature \u0026ldquo;plastic surgery technology\u0026rdquo;.\nA software can directly transform Angela Baby into Dilraba!\nJust want Dilraba\u0026rsquo;s teardrop and mouth? No problem!\nYou can also change the face of a blessed comedian Shen Teng into that of Jack Ma.\nAnd this time, the \u0026ldquo;plastic surgery technology\u0026rdquo; has a new upgrade!\nReal-time facelift\u0026quot; for live web stars!\nThe face of an internet celebrity is replaced with the face of Fan Bingbing, without any sense of \u0026ldquo;faking\u0026rdquo;.\nThat\u0026rsquo;s right, this is DeepFaceLive\u0026rsquo;s real-time face changing software.\n DeepFaceLive project address: https://github.com/iperov/DeepFaceLive\n Just open the software, you will be able to process the video in real time and give the live broadcaster a new face.\nHere is a big weapon: Liu Yifei model!\nZoom in to see, the five features are perfectly replaced.\nDeepFaceLive is also able to handle different gender face replacement.\nThe software launched by the team this time can change faces in real time for live video, but also during video calls.\nBehind the Scene  Of course, the model of face replacement has to be trained by DeepFaceLab algorithm first.\n Address: https://arxiv.org/pdf/2005.05535.pdf\n More than 95% of the Deep Fake videos on the web are now created with DeepFaceLab.\nFor example, the following popular YouTube channels.\n DeepFaceLab project address: https://github.com/iperov/DeepFaceLab\n With the launch of DeepFaceLive, there will definitely be more fun videos and even live streams.\nThe software is also very easy to run, requiring only a 64-bit Win 10 system and an NV graphics card.\nThat\u0026rsquo;s it!\nDeepFaceLive  Just click and change!\n(Remember to update your graphics card drivers)\nFace Detection The face detector is integrated with YoloV5, S3FD and CenterFace.\nYou can also choose to use the CPU for processing.\nFace Alignment Simple parameters can be modified to adjust the effect of face alignment.\nFace Marker The face tagger provides CPU-based OpenCV LBF and GPU-based Google FaceMesh.\nFace Swapper In the face swapper, you need to load a model trained by the user in advance with DeepFaceLab.\n A detailed tutorial can be found at: https://github.com/iperov/DeepFaceLive/blob/master/doc/setup_tutorial_windows/index.md\n DeepFaceLab  Lab enables smooth and realistic face swapping without the need to hand-pick features.\nOnly two videos are needed: the source video (src) and the target video (dst).\nMoreover, the two videos do not need to match the same facial expression between them.\nPart 1 Extracting faces The first stage of Lab is to extract faces from src and dst data.\nFace Detection In Lab, S3FD is used as the default face detector.\nFace Alignment Lab provides two typical face coordinate extraction algorithms to solve this problem.\nHeat map-based facial coordinate algorithm 2DFAN (for faces with standard pose) PRNet with 3D facial a priori information (for faces with large Euler angles, e.g. one of the sides is out of the line of sight).\nAfter retrieving the face coordinates, Lab provides an optional function with configurable time steps to smooth the face coordinates of consecutive frames in a single shot, further ensuring stability.\nThe classical point pattern mapping and transformation method is then used to compute the similarity transformation matrix for face alignment.\nSince a standard facial coordinate template is required for calculating the similarity transformation matrix, Lab provides a canonical aligned facial coordinate template.\nIn addition, Lab can automatically predict the Euler angles using the obtained facial coordinates.\nFace segmentation After alignment, a folder of face data with standard front or side views is obtained.\nWe use a fine-grained face segmentation network (TernausNet) on this basis to accurately segment faces with hair, finger or glasses occlusions, while also removing irregular occlusions.\nSince some SOTA face segmentation models are unable to generate fine-grained masks in some specific shots, Lab introduced XSeg into the mix.\nXSeg allows users to use multiple photos to train the model to segment specific faces.\nWith the help of XSeg, users can use it to remove the occlusion of hands, glasses and any other objects that may cover the face, and control specific areas for swapping.\nPart 2 Model training Since the authors want to avoid a strict matching of src and dst facial expressions, Lab proposes two structures to solve this problem.\nDF structure LIAE structure The DF structure consists of an encoder and an Inter with shared weights between src and dst, two decoders belonging to src and dst respectively.\nThe generalization of src and dst is achieved by the shared Encoder and Inter.\nThe DF structure can perform the task of face swapping but does not inherit enough information from dst, while the LIAE structure can be used to solve the consistency problem of light.\nThe LIAE structure is more complex, with an encoder that shares weights, a decoder and two separate inputs.\nIn addition, Lab uses hybrid loss (DSSIM+MSE) by default. dSSIM can generate faces faster, while MSE can provide better sharpness.\nIn addition, the authors use a real face mode, TrueFace, which can make the generated faces have better similarity with dst in the conversion stage.\nFrom the results, there is a significant improvement in the quality of the final generated faces.\nPart 3 Face Exchange Previous methods often ignore the importance of the transformation phase.\nLab allows users to swap src faces to dst and reverse the process.\nIn order to maintain consistent face color, Lab provides five more color transfer algorithms (Reinhard color transfer, iterative distribution transfer, etc.).\nLab\u0026rsquo;s liae architecture model comes with light and shadow learning, so when dealing with different skin tones, face shapes and lighting conditions, the combination of the two faces will not look abrupt as long as the edges are feathered.\nFinally, the face is sharpened.\nSince SOTA models produce faces that are more or less smooth and lacking in minute details (e.g., moles, wrinkles), Lab integrates a pre-trained sharpening tool to sharpen faces.\nTherefore, Lab integrates a pre-trained face super-resolution neural network for sharpening the blended faces.\nComparison of results The authors used an open source project from the FaceForensics++ dataset to test the face swapping results.\nExamples of face swapping with different expressions and face shapes\nTo be fair, the authors limited the training time to 3 hours and used a lightweight model with a DF structure: Quick96, which has an output resolution of 96√ó96.\nIn addition, the authors optimized the model using the Adam optimizer (lr=0.00005, Œ≤1=0.5, Œ≤2=0.999).\nThe models are trained on NVIDIA GeForce GTX 1080Ti GPUs and Intel Core i7-8700 CPUs.\nFaceForensics++ Qualitative face replacement results for face images\nLab can preserve more poses and expressions than DeepFakes and Nirkin\u0026rsquo;s models.\nIn addition, with the addition of the super-resolution network in the transformation stage, Lab can output more soulful eyes and well-defined teeth.\nHowever, this effect cannot be reflected in the SSIM score.\nReal-time face replacement, is it good or bad?  As researchers continue to pursue natural effects, AI face-swapping technology is becoming more and more \u0026ldquo;impeccable\u0026rdquo;.\nNow the live-streaming industry is riding on the wings of technological development, allowing businesses to profit more.\nThe developer of the software, \u0026ldquo;Rolling Stone, who wishes to remain anonymous,\u0026rdquo; says that if the live-streaming industry can use this face-swapping software, the hosts with interesting souls but not enough faces can have high faces and improve the attractiveness of their live-streaming rooms.\nIt greatly reduces the cost of opening a live room for businesses, while also improving the attractiveness of the live room.\nThe developer also expressed his concern: once the software is widely used, people with bad intentions may use real-time face-swapping technology to commit fraud and blackmail.\nPrevious face-swapping technology can only change the face of the video at most, if you want to fraud, as long as you remain vigilant, the video will soon be revealed.\nBut if real-time face-swapping technology is used for fraud, in this virtual world of real and fake, there may be no way for most people to tell if the end of the screen is the \u0026ldquo;real one\u0026rdquo;.\nIf the scam is for older people like our parents, who can interact with them, they may easily be tricked into transferring money when their discernment is not high.\nIn this AI world, can we still keep the last sincerity between people?\nReference:\nDeepFaceLive project address: https://github.com/iperov/DeepFaceLive\nDeepFaceLab project address: https://github.com/iperov/DeepFaceLab\nDeepFaceLab paper address: https://arxiv.org/pdf/2005.05535.pdf\nSource\n","date":"04 Jan, 2022","image":"images/blog/deepfacelive.png","permalink":"https://codelink.ai/blog/data-science/github-open-source-magic-let-you-become-a-celebrity-in-one-click/","tags":["computer vision","python"],"title":"GitHub open source magical project! Let you become a celebrity in one click!"},{"categories":["python"],"contents":" Python is not known to be a very efficient language to execute. In addition, looping is a very time-consuming operation in any language. If any simple single-step operation takes 1 unit of time, repeating the operation tens of thousands of times will eventually increase the time spent tens of thousands of times.\nwhile and for are two keywords commonly used in Python to implement loops, there is a real difference in their efficiency. For example, the following test code.\nimport timeit def while_loop(n=100_000_000): i = 0 s = 0 while i \u0026lt; n: s += i i += 1 return s def for_loop(n=100_000_000): s = 0 for i in range(n): s += i return s def main(): print(\u0026#39;while loop\\t\\t\u0026#39;, timeit.timeit(while_loop, number=1)) print(\u0026#39;for loop\\t\\t\u0026#39;, timeit.timeit(for_loop, number=1)) if __name__ == \u0026#39;__main__\u0026#39;: main() # =\u0026gt; while loop 4.718853999860585 # =\u0026gt; for loop 3.211570399813354 This is a simple summation operation that computes the sum of all natural numbers from 1 to n. You can see that the for loop is 1.5 seconds faster than the while loop.\nThe difference is mainly due to the different mechanics of the two.\nIn each loop, while actually performs two more steps than for: a bounds check and the self-incrementing of variable i. That is, for each loop, while performs two more steps than for. That is, for each loop, while does a bounds check (while i \u0026lt; n) and a self-increment calculation (i += 1). Both of these operations are explicitly pure Python code.\nThe for loop does not require a bounds check and self-increment operation, and adds no explicit Python code (pure Python code is less efficient than the underlying C code). When the number of loops is large enough, a significant efficiency gap emerges.\nTwo more functions can be added to add unnecessary bounds checking and self-incrementing to the for loop.\nimport timeit def while_loop(n=100_000_000): i = 0 s = 0 while i \u0026lt; n: s += i i += 1 return s def for_loop(n=100_000_000): s = 0 for i in range(n): s += i return s def for_loop_with_inc(n=100_000_000): s = 0 for i in range(n): s += i i += 1 return s def for_loop_with_test(n=100_000_000): s = 0 for i in range(n): if i \u0026lt; n: pass s += i return s def main(): print(\u0026#39;while loop\\t\\t\u0026#39;, timeit.timeit(while_loop, number=1)) print(\u0026#39;for loop\\t\\t\u0026#39;, timeit.timeit(for_loop, number=1)) print(\u0026#39;for loop with increment\\t\\t\u0026#39;, timeit.timeit(for_loop_with_inc, number=1)) print(\u0026#39;for loop with test\\t\\t\u0026#39;, timeit.timeit(for_loop_with_test, number=1)) if __name__ == \u0026#39;__main__\u0026#39;: main() # =\u0026gt; while loop 4.718853999860585 # =\u0026gt; for loop 3.211570399813354 # =\u0026gt; for loop with increment 4.602369500091299 # =\u0026gt; for loop with test 4.18337869993411 As you can see, the addition of the bounds check and self-increment operations does significantly affect the efficiency of the for loop.\nAs mentioned earlier, Python\u0026rsquo;s underlying interpreter and built-in functions are implemented in C. C is much more efficient than Python.\nFor the above sum of equal variables operation, Python\u0026rsquo;s built-in sum function can be used to obtain a much more efficient execution than a for or while loop.\nimport timeit def while_loop(n=100_000_000): i = 0 s = 0 while i \u0026lt; n: s += i i += 1 return s def for_loop(n=100_000_000): s = 0 for i in range(n): s += i return s def sum_range(n=100_000_000): return sum(range(n)) def main(): print(\u0026#39;while loop\\t\\t\u0026#39;, timeit.timeit(while_loop, number=1)) print(\u0026#39;for loop\\t\\t\u0026#39;, timeit.timeit(for_loop, number=1)) print(\u0026#39;sum range\\t\\t\u0026#39;, timeit.timeit(sum_range, number=1)) if __name__ == \u0026#39;__main__\u0026#39;: main() # =\u0026gt; while loop 4.718853999860585 # =\u0026gt; for loop 3.211570399813354 # =\u0026gt; sum range 0.8658821999561042 As you can see, using the built-in sum function instead of a loop increases the efficiency of code execution exponentially.\nThe sum operation of the built-in function is actually a loop, but it is implemented in C, whereas the sum operation in the for loop is implemented in pure Python code s += i. C \u0026gt; Python.\nExpand your thinking a bit. As a child, you\u0026rsquo;ve heard the story of the childhood Gaussian who cleverly calculated the sum of 1 to 100. 1\u0026hellip;100 equals (1 + 100) * 50. This same calculation can be applied to the summation operation above.\nimport timeit def while_loop(n=100_000_000): i = 0 s = 0 while i \u0026lt; n: s += i i += 1 return s def for_loop(n=100_000_000): s = 0 for i in range(n): s += i return s def sum_range(n=100_000_000): return sum(range(n)) def math_sum(n=100_000_000): return (n * (n - 1)) // 2 def main(): print(\u0026#39;while loop\\t\\t\u0026#39;, timeit.timeit(while_loop, number=1)) print(\u0026#39;for loop\\t\\t\u0026#39;, timeit.timeit(for_loop, number=1)) print(\u0026#39;sum range\\t\\t\u0026#39;, timeit.timeit(sum_range, number=1)) print(\u0026#39;math sum\\t\\t\u0026#39;, timeit.timeit(math_sum, number=1)) if __name__ == \u0026#39;__main__\u0026#39;: main() # =\u0026gt; while loop 4.718853999860585 # =\u0026gt; for loop 3.211570399813354 # =\u0026gt; sum range 0.8658821999561042 # =\u0026gt; math sum 2.400018274784088e-06 The final execution time of math sum is about 2.4e-6, which is a million times shorter. The idea here is that since loops are inefficient, a piece of code has to be executed hundreds of millions of times over.\nSo we just don\u0026rsquo;t need to loop, and use mathematical formulas to turn hundreds of millions of loops into a single step operation. The efficiency is naturally enhanced to an unprecedented degree.\nFinal conclusion (a bit riddler).\n The fastest way to implement loops \u0026ndash; is to not use them\n For Python, use built-in functions whenever possible to minimize the pure Python code in the loop.\nOf course, built-in functions aren\u0026rsquo;t the fastest in some cases. When creating lists, for example, it\u0026rsquo;s the literal writing that\u0026rsquo;s faster.\nSource: https://www.starky.ltd/2021/11/23/the-fastest-way-to-loop-in-python https://mp.weixin.qq.com/s/lJcl-4Xwb9XYEZNG9kuimg\n","date":"04 Jan, 2022","image":"images/blog/python.png","permalink":"https://codelink.ai/blog/python/pythons-fastest-way-to-implement-loops/","tags":["learning"],"title":"Python's fastest way to implement loops (for, while, etc. speed comparison)"},{"categories":["devops"],"contents":" We will share the five application scenarios for Nginx: HTTP server, static server, reverse proxy server, load balancer, and separation of static and dynamic contents.\nI. HTTP server Nginx itself is also a static resource server. When there are only static resources, you can use Nginx to be a server, if a website is only a static page, then it can be deployed in this way.\n1. first in the document root directory Docroot (/usr/local/var/www) to create html directory, and then in the html put a test.html; 2. configure the server in nginx.conf user mengday staff; http { server { listen 80; server_name localhost; client_max_body_size 1024M; # default location location / { root /usr/local/var/www/html; index index.html index.htm; index.html; index.htm; } } } 3. Access test http://localhost/ points to /usr/local/var/www/index.html, index.html is the html that comes with nginx installation http://localhost/test.html points to /usr/local/var/www/html/test.html\n Note: If you get 403 Forbidden errors when accessing images, it may be because the first line of nginx.conf user configuration is not correct, the default is #user nobody; it is commented out, change it to user root under linux; change it to user username group under macos; then reload the configuration file or reboot and try again. The user name can be checked by who am i command.\n 4. Command Introduction  server : used to define the service, there can be multiple server blocks in http listen : Specify the IP address and port for the server to listen to requests, if the address is omitted, the server will listen to all addresses, if the port is omitted, the standard port is used server_name : the name of the service, used to configure the domain name location : The configuration corresponding to the mapped path uri, a server can have multiple locations, location followed by a uri, can be a regular expression, / means match any path, when the client accesses the path meets this uri will execute the code inside the location block root : root path, when visit http://localhost/test.html, \u0026ldquo;/test.html\u0026rdquo; will match to \u0026ldquo;/\u0026rdquo; uri, find root as /usr/local/ var/www/html, the user accesses the resource physical address = root + uri = /usr/local/var/www/html + /test.html = /usr/local/var/www/html/test.html index : set the home page, when only access server_name without any path behind is not to go root directly to the index command; if the access path does not specify a specific file, then return the index set resources, if you visit http://localhost/html/ then the default return index.html  5. location uri regular expression  . : match any character other than the newline character ? : repeat 0 times or 1 times + : repeat 1 or more times * : repeat 0 or more times \\d ÔºöMatch a number ^ : Match the beginning of the string $ : Match the end of the string {n} : Repeat n times {n,} : Repeat n or more times [c] : matches a single character c [a-z] : matches any of the lowercase letters a-z (a|b|c) : the genus line means match any of the cases, each case is separated by a vertical line, usually enclosed in parentheses, and matches a character or a b character or a c character \\ Backslash: used to escape special characters  The content matched between the parentheses () can be referenced later by $1, and $2 indicates the content in the second () before. It is easy to confuse people inside the regular \\ escaping special characters.\n II. Static Server In the company often encounter a static server, usually provides a function of upload, other applications if you need static resources from the static server.\n Create images and img directories under /usr/local/var/www, and put a test.jpg under each directory respectively.  http { server { listen 80; server_name localhost; set $doc_root /usr/local/var/www; # default location location / { root /usr/local/var/www/html; index index.html index.htm; index.html; } location ^~ /images/ { root $doc_root; } location ~* \\. (gif|jpg|jpeg|png|bmp|ico|swf|css|js)$ { root $doc_root/img; } } } Custom variables use set directive, syntax set variable name value; reference use variable name value; reference use variable name; here customize doc_root variable.\nThere are two general ways to map static server location.\n Use path, such as /images/ Generally, images are placed in some image directory. Use suffixes such as .jpg, .png, etc. to match the pattern  Visit http://localhost/test.jpg to map to $doc_root/img\nVisit http://localhost/images/test.jpg When the same path meets more than one location, it will match the location with higher priority, because the priority of ^~ is higher than ~, so it will go to the location corresponding to /images/.\nThere are several common location path mapping paths.\n = Exact match for common characters. That is, exact match. ^~ prefix matching. If the match is successful, no other locations will be matched. ~ indicates a regular match, case sensitive ~* means perform a regular match, not case-sensitive /xxx/ regular string path matching /xxx/ generic match, any request will be matched to  Location priority When a path matches multiple locations, there is a priority order of which location can be matched, and the priority order is related to the expression type of the location value, not the order in the configuration file. For the same type of expression, the longer string will be matched first.\nThe following are the descriptions in order of priority.\n The equal sign type (=) has the highest priority. Once the match is successful, no other matches are found and the search stops. ^~ type expression, not a regular expression. Once the match is successful, no more matches are found and the search stops. The regular expression type (~ ~*) has the next highest priority. If more than one location can match, the one with the longest regular expression is used. Regular string match type. Match by prefix. / generic match, if no match, match the generic  Priority search problem: different types of location mapping decide whether to continue down the search\n equals type, ^~ type: once matched, the search stops, no other location will be matched Regular expression type (~ ~*), regular string matching type /xxx/ : after matching, it will continue to search for other locations until it finds the highest priority, or stop searching when it finds the first case  Location priority from highest to lowest:\n(location =) \u0026gt; (location full path) \u0026gt; (location ^~ path) \u0026gt; (location ~,~* regular order) \u0026gt; (location partial start path) \u0026gt; (/)\nlocation = / { # Exact match /, hostname cannot be followed by any string / [ configuration A ] } location / { # Match all requests that start with /. # But if a longer expression of the same type is available, the longer expression is chosen. # If there are regular expressions to match, the regular expressions are matched first. [ configuration B ] } location /documents/ { # Match all requests that start with /documents/, and continue down the list after the match. # But if there is a longer expression of the same type, the longer expression is chosen. # If there are regular expressions to match, the regular expressions are given priority. [ configuration C ] } location ^~ /images/ { # Match all expressions starting with /images/, and if the match is successful, stop matching the lookup and stop searching. # So, even if there is a matching regular expression location, it will not be used [ configuration D ] } location ~* \\. (gif|jpg|jpeg)$ { # Match all requests ending with gif jpg jpeg. # But requests starting with /images/ will use Configuration D, which has a higher priority [ configuration E ] } location /images/ { # Characters matching /images/ will continue to search down [ configuration F ] } location = /test.htm { root /usr/local/var/www/htm; index index.htm; index.htm; }  Note: The priority of location is not related to the location of location configuration\n  III. Reverse Proxy Sever Reverse proxy should be the most used feature of Nginx. Reverse proxy means that the proxy server accepts connection requests on the Internet, forwards the requests to a server on the internal network, and returns the results obtained from the server to the client requesting the connection on the Internet, at which point the proxy server behaves externally as a reverse proxy server.\nSimply put, the real server cannot be directly accessed by the external network, so a proxy server is needed, while the proxy server can be accessed by the external network and the real server in the same network environment, of course, it may be the same server, the port is different.\nReverse proxy through the proxy_pass command to achieve .\nStart a Java Web project with port 8081\nserver { listen 80; server_name localhost; location / { proxy_pass http://localhost:8081; proxy_set_header Host $host:$server_port; # Set user ip address proxy_set_header X-Forwarded-For $remote_addr; # When requesting server error to find another server proxy_next_upstream error timeout invalid_header http_500 http_502 http_503; } http_500 http_502; } When we access localhost, it\u0026rsquo;s the same as accessing localhost:8081\n IV. Load Balancer Load balancing is also a common feature of Nginx. Load balancing means spreading the execution across multiple operating units, such as web servers, FTP servers, enterprise critical application servers, and other mission-critical servers, so that they can work together to complete their tasks.\nSimply put, when there are two or more servers, the requests are randomly distributed to the specified servers according to the rules, and the load balancing configuration generally requires a reverse proxy to be configured at the same time to jump to the load balancing through the reverse proxy. Nginx currently supports three load balancing policies, and two common third-party policies.\nLoad balancing is achieved through the upstream directive. Recommended: Java Interview Questions\n1. RR (round robin :polling by default) Each request is assigned to different back-end servers one by one in chronological order, that is, the first request is assigned to the first server, the second request is assigned to the second server, and if there are only two servers, the third request continues to be assigned to the first one, so that the cycle of polling continues, that is, the ratio of requests received by servers is 1:1, and if the back-end server is down, it can be automatically eliminated. Polling is the default configuration and does not require much configuration\nStart the same project on ports 8081 and 8082 respectively\nupstream web_servers { server localhost:8081; server localhost:8082; } server { listen 80; server_name localhost; #access_log logs/host.access.log main; location / { proxy_pass http://web_servers; # Header Host must be specified proxy_set_header Host $host:$server_port; host $host:$server_port; } } The access address can still get the response http://localhost/api/user/login?username=zhangsan\u0026amp;password=111111, this way is polled\n2. weights Specify the polling rate, weight is proportional to the access ratio, that is, the proportion of requests received by the server is the proportion of the respective configured weight, used in the case of uneven performance of the back-end server, such as the server performance is poor to receive fewer requests, the server performance is better to handle more requests.\nupstream test { server localhost:8081 weight=1; server localhost:8082 weight=3; server localhost:8083 weight=4 backup; backup; } The example is that only one of the four requests is assigned to 8081, and the other three are assigned to 8082. backup means hot standby, which only goes to 8083 if both 8081 and 8082 are down\n3. ip_hash The above two ways have a problem, that is, the next request may be distributed to another server, when our program is not stateless (using the session to save data), then there is a big problem, such as the login information is saved to the session, then jump to another server when you need to log in again So many times we need a client to access only one server, then we need to use iphash, iphash each request by accessing the IP hash result distribution, so that each visitor fixed access to a back-end server, can solve the problem of session.\nupstream test { ip_hash; server localhost:8080; server localhost:8081; } 4. fair (third party) Distribute requests according to the response time of the backend server, with the shorter response time being assigned first. This is configured to give the user a faster response\nupstream backend { fair; server localhost:8080; server localhost:8081; } 5. url_hash (third party) Allocate requests by the hash result of the accessed url, so that each url is directed to the same backend server, which is more effective when the backend server is cached. Add the hash statement to the upstream, the server statement can not write other parameters such as weight, hash_method is the hash algorithm used\nupstream backend { hash $request_uri; hash_method crc32; server localhost:8080; server localhost:8081; } Each of the above five load balancing is applicable to different situations, so you can choose which policy mode to use according to the actual situation, but fair and url_hash need to install third-party modules to use.\n V. Separation of Static and Dynamic Separation of dynamic and static is to let the dynamic web pages in the dynamic website according to certain rules to the unchanging resources and often change the resources to distinguish, dynamic and static resources to do a good job of splitting, we can do caching operations based on the characteristics of static resources, which is the core idea of the static website processing.\nupstream web_servers { server localhost:8081; server localhost:8082; } server { listen 80; server_name localhost; set $doc_root /usr/local/var/www; location ~* \\. (gif|jpg|jpeg|png|bmp|ico|swf|css|js)$ { root $doc_root/img; } location / { proxy_pass http://web_servers; # Header Host must be specified proxy_set_header Host $host:$server_port; host $host:$server_port; } error_page 500 502 503 504 /50x.html; location = /50x.html { root $doc_root; } }  VI. Others 1. return directive Return the http status code and optionally the second parameter can be the redirect URL\nlocation /permanently/moved/url { return 301 http://www.example.com/moved/here; } 2. rewrite directive The rewrite URI request rewrite, which modifies the request URI multiple times during request processing by using the rewrite directive, has one optional parameter and two required parameters.\nThe first (required) parameter is a regular expression that the request URI must match.\nThe second parameter is the URI used to replace the matching URI.\nThe optional third parameter is a flag that can stop further processing of the rewrite directive or send a redirect (code 301 or 302)\nlocation /users/ { rewrite ^/users/(. *)$ /show?user=$1 break; } 3. error_page directive Using the error_page directive, you can configure NGINX to return a custom page with an error code, replace other error codes in the response, or redirect the browser to another URI. in the following example, the error_page directive specifies the page (/404.html) that will return the 404 page error code.\nerror_page 404 /404.html; 4. logs Access log: need to turn on compression gzip on; otherwise no log file is generated, open log_format, access_log comments\nlog_format main \u0026#39;$remote_addr - $remote_user [$time_local] \u0026#34;$request\u0026#34; \u0026#39; \u0026#39;$status $body_bytes_sent \u0026#34;$http_referer\u0026#34; \u0026#39; \u0026#39; \u0026#34;$http_user_agent\u0026#34; \u0026#34;$http_x_forwarded_for\u0026#34; \u0026#39; access_log /usr/local/etc/nginx/logs/host.access.log main; gzip on. 5; 5. deny command # Deny access to a directory location ~* \\. (txt|doc)${ root $doc_root; deny all; } 6. Built-in variables The built-in variables that can be used in nginx configuration files start with the dollar sign $, and are also called global variables by some people. The values of some of these predefined variables can be changed. Also, pay attention to the Java Voice public page, reply to \u0026ldquo;back-end interview\u0026rdquo;, and you will be sent a treasure trove of interview questions!\n $args: # This variable is equal to the parameter in the request line, same as $query_string $content_length : The Content-length field in the request header. $content_type : The Content-Type field in the request header. $document_root : The value specified in the root directive for the current request. $host : The request host header field, otherwise it is the server name. $http_user_agent : client-side agent information $http_cookie : client-side cookie information $limit_rate : This variable can limit the connection rate. $request_method : The action requested by the client, usually GET or POST. $remote_addr : IP address of the client. $remote_port : The port of the client. $remote_user : The user name that has been authenticated by Auth Basic Module. $request_filename : The path of the current request file, generated by the root or alias directive with the URI request. $scheme : HTTP method (e.g. http, https). $server_protocol : The protocol used for the request, usually HTTP/1.0 or HTTP/1.1. $server_addr : The server address, this value can be determined after a system call is completed. $server_name : The name of the server. $server_port : The port number on which the request reaches the server. $request_uri : The original URI containing the request parameters, without the host name, e.g. /foo/bar.php?arg=baz. $uri : The current URI without request parameters, $uri does not contain the host name, e.g. /foo/bar.html. $document_uri : Same as $uri  Source\n","date":"03 Jan, 2022","image":"images/blog/nginx.png","permalink":"https://codelink.ai/blog/devops/five-application-scenarios-for-understanding-nginx-thoroughly/","tags":["nginx"],"title":"Five application scenarios for understanding Nginx thoroughly"},{"categories":["data science"],"contents":" We\u0026rsquo;d like to introduce you to an awesome spatial (geographic) data visualization tool: keplergl.\nKeplergl is completely open source by Uber and is the default tool for spatial data visualization within Uber.\nThrough its open interface package keplergl for Python, we can pass in a variety of formats of data by writing Python code in jupyter notebook, and use its built-in rich spatial data visualization functions in its interactive window embedded in notebook. Here are 3 main addresses for learning.\n  the official website address: https://kepler.gl/\n  jupyter notebook manual address: https://github.com/keplergl/kepler.gl/tree/master/docs/keplergl-jupyter#geojson\n  Case study address: https://github.com/keplergl/kepler.gl/tree/master/bindings/kepler.gl-jupyter/notebooks\n  Installation  The installation of keplergl is very simple.\npip install keplergl Amazing graphics  A wave of stunning graphics are coming.\n Getting Started  import pandas as pd import geopandas as gpd from keplergl import KeplerGl # Create an object kep1 = KeplerGl(height=600) # Activate the object and load it into jupyter notebook kep1 As you can see, after running the basic code in Jupyter directly generated the built-in graphics, the graphics themselves are also dynamic; dark black background is also my favorite:\nAdding data  By default, keplergl can add 3 types of data:\n csv GeoJSON DataFrame  csv format There is a csv data in the local directory: china.csv, which records the latitude and longitude of each province in China.\nwith open(\u0026#34;china.csv\u0026#34;, \u0026#34;r\u0026#34;) as f: csv_data = f.read() # add_data add data kep1.add_data(data=csv_data, name=\u0026#34;csv_kep\u0026#34;) kep1  DataFrame format china = pd.read_csv(\u0026#34;china.csv\u0026#34;) kep1.add_data(data=china, name=\u0026#34;dataframe_kep\u0026#34;) kep1  GeoJson format url = \u0026#39;http://eric.clst.org/assets/wiki/uploads/Stuff/gz_2010_us_040_00_500k.json\u0026#39; country_gdf = gpd.read_file(url) # geopandas read json file kep1.add_data(data=country_gdf, name=\u0026#34;state\u0026#34;) kep1  Custom graphics  Keplergl\u0026rsquo;s customization method: the criticality button. Once inside, you can customize the operation\n Saving and reusing configurations The configuration of the instantiated kep can be saved and reused in the following instance objects.\n Save.  # Save as a file with open(\u0026#39;config1.py\u0026#39;,\u0026#39;w\u0026#39;) as f: f.write(\u0026#39;config={}\u0026#39;.format(kep1.config)) # Run: magic command %run %run config1.py Reuse  kep2 = KeplerGl(height=400, data={\u0026#34;layer1\u0026#34;:df}, config=kep1.config # configuration of kep1 ) kep2 Save graphics   minimalist version, mainly the file name  kep1.save_to_html(file_name=\u0026#34;first_kep.html\u0026#34;) full version: file name, configuration, data, readability  # 4 parameters kep1.save_to_html(file_name=\u0026#34;first_kep.html\u0026#34;, data={\u0026#39;data_1\u0026#39;:china}, config=config, read_only=True ) Web app  The operations shown above are all done in the notebook, we can also do them directly online: https://kepler.gl/demo\nWe will share more articles after we have studied this tool seriously, this library is worth studying\n Source\n","date":"02 Jan, 2022","image":"images/blog/keplergl.png","permalink":"https://codelink.ai/blog/data-science/spatial-data-visualization-wizard-keplergl/","tags":["visualization","python"],"title":"Spatial data visualization wizard keplergl"},{"categories":["web development","mobile development"],"contents":" We recommend several popular websites that can help improve your programming efficiency.\nCodepen  Demo video: https://www.bilibili.com/video/BV1im4y1X7zb/\nHere you can find a lot of front-end code written by coding guru. In addition to various web layout codes, there are more kinds of fun, cool and novel front-end animations and effects.\nFor example, when Christmas is coming, many of you asked if I could draw a Christmas tree with code.\nI can\u0026rsquo;t, but if you type \u0026ldquo;Christmas Tree\u0026rdquo; in this website, you can see different styles of Christmas tree pages!\nClick on the page you like and you\u0026rsquo;ll be taken to the code editing page, where you can modify the HTML, CSS, and JavaScript front-end code and view the results in real time in the area at the bottom, which is very convenient!\nAfter editing a web page, you can browse it in full screen, favorite, clone, share, etc. in the menu at the bottom right corner of the web page, and directly embed the web page into our own project or download the complete code package to local.\nThanks to the development of front-end technology, this site provides developers with a one-stop service to search for projects, edit them online, and share and export them, making it easy for us to learn other people\u0026rsquo;s good code in an independent practice.\nHere are a few more similar sites.\nCodeSandbox  CodeSandbox, as the name suggests, helps you run front-end projects in an isolated environment.\nHere you can create your own sandboxes (projects) based on rich templates for common front-end frameworks like React, Vue, Angular, VuePress, Svelte, etc..\nOnce you create your sandbox, you can edit your code online, view your results in real time, or share your sandbox with other people.\nJSFiddle  JSFiddle is a front-end development practice, you can also write code online and view the effect in real time. Compared with Codepen, I feel that this site has a better editing experience.\nWhen you see a great piece of JS code or plugin on the web, you don\u0026rsquo;t have to download it locally. Paste the code directly into JSFiddle and you\u0026rsquo;ll be able to see it in action in the fastest way possible. Many front-end component libraries now also use this platform to give developers a WYSIWYG experience.\nJSRUN  China\u0026rsquo;s online programming site, in addition to front-end, even supports online debugging and running of up to 30 programming languages!\nLike Codepen, you can see many code snippets written by others here and download them directly. You can also save and share your code, and create your own little code collection.\nI have to say, this site is one of the best in China, with great access and functionality!\nGitpod  This platform is a bit more advanced than the above mentioned sites. It is a powerful online IDE (Integrated Programming Environment) that provides a VSCode-style editor that allows you to write code online to complete your development.\nGitpod is based on container technology and will help you compile, build, and run any GitHub project, not just the front end, with one click! And each project runs in isolation from each other, so you can create them as you go and recycle them whenever you\u0026rsquo;re done.\nIf you\u0026rsquo;ve got your eye on a GitHub project and you don\u0026rsquo;t want to build it locally to see how it works, the best way to build and run it online is with Gitpod. There are more and more GitHub projects that have access to Gitpod, and if you see the button below, you can deploy it with one click, which is much more efficient!\nSource\n","date":"27 Dec, 2021","image":"images/blog/post-2.webp","permalink":"https://codelink.ai/blog/web-development/a-few-of-this-years-super-hot-programming-sites/","tags":["tools","javascript"],"title":"A few of this year's super-hot programming sites!"},{"categories":["data science"],"contents":" Xgboost is an integrated learning algorithm, which belongs to the category of boosting algorithms in the 3 commonly used integration methods (bagging, boosting, stacking). It is an additive model, and the base model is usually chosen as a tree model, but other types of models such as logistic regression can also be chosen.\n1. xgboost and GBDT  Xgboost belongs to the category of gradient boosted tree (GBDT) models. The basic idea of GBDT is to let the new base model (GBDT takes CART categorical regression tree as the base model) to fit the deviation of the previous model, so as to continuously reduce the deviation of the additive model.\nCompared with the classical GBDT, xgboost has made some improvements, resulting in significant improvements in effectiveness and performance (highlighting a common interview test).\n  GBDT expands the objective function Taylor to the first order, while xgboost expands the objective function Taylor to the second order. More information about the objective function is retained, which helps to improve the effect.\n  GBDT is finding a new fit label for the new base model (negative gradient of the previous additive model), while xgboost is finding a new objective function for the new base model (second-order Taylor expansion of the objective function about the new base model).\n  xgboost adds and L2 regularization term for the leaf weights, thus facilitating the model to obtain a lower variance.\n  xgboost adds a strategy to automatically handle missing value features. By dividing the samples with missing values into left subtree or right subtree respectively and comparing the advantages and disadvantages of the objective functions under the two schemes, the samples with missing values can be divided automatically without the need of filling preprocessing the missing features.\n  In addition, xgboost also supports candidate quantile cuts, feature parallelism, etc., which can improve performance.\n2. xgboost Basic Principle  The following is a general introduction to the principle of xgboost from three perspectives: assumption space, objective function, and optimization algorithm.\n1. Hypothesis space  2. Objective function  3. Optimization algorithm The basic idea: greedy method, learning tree by tree, each tree fits the deviation of the previous model.\nThird, the first t trees to learn what? To finish building the xgboost model, we need to determine some of the following things.\n  how to boost? If the additive model composed of the previous t-1 trees has been obtained, how to determine the learning goal of the tth tree?\n  How to generate the tree? If the learning goal of the tth tree is known, how to learn this tree? Specifically, does it involve splitting or not? Which feature is selected for splitting? What splitting point is chosen? How to take the value of the split leaf nodes?\n  We first consider the problem of how to boost, and then solve the problem of how to take the values of the split leaf nodes.\n 4. How to generate the tth tree?  xgboost uses a binary tree, and at the beginning, all the samples are on one leaf node. Then the leaf nodes are continuously bifurcated to gradually generate a tree.\nxgboost uses a levelwise generation strategy, i.e., it tries to split all the leaf nodes at the same level at a time.\nThe process of splitting leaf nodes to generate a tree has several basic questions: should we split? Which feature to choose for splitting? At what point of the feature to split? and what values are taken on the new leaves after the split?\nThe problem of taking values of leaf nodes has been solved earlier. Let\u0026rsquo;s focus on a few remaining questions.\n Should splitting be performed?  Depending on the pruning strategy of the tree, this problem is handled in two different ways. If it is a prepruning strategy, then splitting will be done only if there is some way of splitting that makes the objective function drop after splitting.\nHowever, if it is a post-pruning strategy, the splitting will be done unconditionally, and then after the tree generation is completed, the branches of the tree will be checked from top to bottom to see if they contribute positively to the decline of the objective function and thus pruned.\nxgboost uses a prepruning strategy and splits only if the gain after splitting is greater than 0.\nWhat features are selected for splitting?  xgboost uses feature parallelism to select the features to be split, i.e., it uses multiple threads to try to use each feature as a splitting feature, find the optimal splitting point for each feature, calculate the gain generated after splitting them, and select the feature with the largest gain as the splitting feature.\nWhat splitting point is selected?  There are two methods for xgboost to select the splitting point of a feature, one is the global scan method and the other is the candidate splitting point method.\nThe global scan method arranges all the values of the feature in the sample from smallest to largest, and tries all the possible splitting locations to find the one with the greatest gain, whose computational complexity is proportional to the number of different values of the sample feature on the leaf node.\nIn contrast, the candidate split point method is an approximate algorithm that selects only a constant number (e.g., 256) of candidate split positions, and then finds the best one from the candidate split positions.\n5. Example of xgboost usage  You can use pip to install xgboost\npip install xgboost The following is an example of using xgboost, you can refer to modify the use.\nimport numpy as np import pandas as pd import xgboost as xgb import datetime from sklearn import datasets from sklearn.model_selection import train_test_split from sklearn.metrics import accuracy_score def printlog(info): nowtime = datetime.datetime.now().strftime(\u0026#39;%Y-%m-%d%H:%M:%S\u0026#39;) print(\u0026#34;\\n\u0026#34;+\u0026#34;==========\u0026#34;*8 + \u0026#34;%s\u0026#34;%nowtime) print(info+\u0026#39;... \\n\\n\u0026#39;) # ================================================================================ # I. Reading data # ================================================================================ printlog(\u0026#34;step1: reading data...\u0026#34;) # read dftrain,dftest breast = datasets.load_breast_cancer() df = pd.DataFrame(breast.data,columns = [x.replace(\u0026#39; \u0026#39;,\u0026#39;_\u0026#39;) for x in breast.feature_names]) df[\u0026#39;label\u0026#39;] = breast.target dftrain,dftest = train_test_split(df) xgb_train = xgb.DMatrix(dftrain.drop(\u0026#34;label\u0026#34;,axis = 1),dftrain[[\u0026#34;label\u0026#34;]]) xgb_valid = xgb.DMatrix(dftest.drop(\u0026#34;label\u0026#34;,axis = 1),dftest[[\u0026#34;label\u0026#34;]]) # ================================================================================ # Two, set the parameters # ================================================================================ printlog(\u0026#34;step2: setting parameters...\u0026#34;) num_boost_rounds = 100 early_stopping_rounds = 20 # Configure xgboost model parameters params_dict = dict() # booster parameters params_dict[\u0026#39;learning_rate\u0026#39;] = 0.05 # Learning rate, usually smaller is better. params_dict[\u0026#39;objective\u0026#39;] = \u0026#39;binary:logistic\u0026#39; # tree parameters params_dict[\u0026#39;max_depth\u0026#39;] = 3 # depth of the tree, usually between [3,10] params_dict[\u0026#39;min_child_weight\u0026#39;] = 30 # minimum leaf node sample weight sum, the larger the model the more conservative. params_dict[\u0026#39;gamma\u0026#39;]= 0 # Minimum drop value of loss function required for node splitting, the larger the model the more conservative. params_dict[\u0026#39;subsample\u0026#39;]= 0.8 # horizontal sampling, sample sampling ratio, usually between [0.5, 1].  params_dict[\u0026#39;colsample_bytree\u0026#39;] = 1.0 # longitudinal sampling, feature sampling ratio, usually between [0.5, 1  params_dict[\u0026#39;tree_method\u0026#39;] = \u0026#39;hist\u0026#39; # strategy for constructing the tree, can be auto, exact, approx, hist # regulazation parameters  # Omega(f) = gamma*T + reg_alpha* sum(abs(wj)) + reg_lambda* sum(wj**2)  params_dict[\u0026#39;reg_alpha\u0026#39;] = 0.0 #L1 weight coefficient of the regularization term, the larger the model the more conservative it is, usually takes a value between [0,1]. params_dict[\u0026#39;reg_lambda\u0026#39;] = 1.0 #L2 The weight coefficient of the regularization term, the larger the model the more conservative it is, usually takes a value between [1,100]. # Other parameters params_dict[\u0026#39;eval_metric\u0026#39;] = \u0026#39;auc\u0026#39; params_dict[\u0026#39;silent\u0026#39;] = 1 params_dict[\u0026#39;nthread\u0026#39;] = 2 params_dict[\u0026#39;scale_pos_weight\u0026#39;] = 1 # Setting to positive value for unbalanced samples will make the algorithm converge faster. params_dict[\u0026#39;seed\u0026#39;] = 0 # ================================================================================ # Third, train the model # ================================================================================ printlog(\u0026#34;step3: training model...\u0026#34;) result = {} watchlist = [(xgb_train, \u0026#39;train\u0026#39;),(xgb_valid, \u0026#39;valid\u0026#39;)] bst = xgb.train(params = params_dict, dtrain = xgb_train, num_boost_round = num_boost_round, verbose_eval= 1, evals = watchlist, early_stopping_rounds = early_stopping_rounds, evals_result = result) # ================================================================================ # IV, Evaluation Model # ================================================================================ printlog(\u0026#34;step4: evaluating model ...\u0026#34;) y_pred_train = bst.predict(xgb_train, ntree_limit=bst.best_iteration) y_pred_test = bst.predict(xgb_valid, ntree_limit=bst.best_iteration) print(\u0026#39;train accuracy: {:.5}\u0026#39;.format(accuracy_score(dftrain[\u0026#39;label\u0026#39;], y_pred_train\u0026gt;0.5))) print(\u0026#39;valid accuracy: {:.5}\\n\u0026#39;.format(accuracy_score(dftest[\u0026#39;label\u0026#39;], y_pred_test\u0026gt;0.5))) %matplotlib inline %config InlineBackend.figure_format = \u0026#39;svg\u0026#39; dfresult = pd.DataFrame({(dataset+\u0026#39;_\u0026#39;+feval): result[dataset][feval] for dataset in [\u0026#34;train\u0026#34;, \u0026#34;valid\u0026#34;] for feval in [\u0026#39;auc\u0026#39;]}) dfresult.index = range(1,len(dfresult)+1) ax = dfresult.plot(kind=\u0026#39;line\u0026#39;,figsize=(8,6),fontsize = 12,grid = True) ax.set_title(\u0026#34;Metric During Training\u0026#34;,fontsize = 12) ax.set_xlabel(\u0026#34;Iterations\u0026#34;,fontsize = 12) ax.set_ylabel(\u0026#34;auc\u0026#34;,fontsize = 12) ax = xgb.plot_importance(bst,importance_type = \u0026#34;gain\u0026#34;,xlabel=\u0026#39;Feature Gain\u0026#39;) ax.set_xlabel(\u0026#34;Feature Gain\u0026#34;,fontsize = 12) ax.set_ylabel(\u0026#34;Features\u0026#34;,fontsize = 12) fig = ax.get_figure() fig.set_figwidth(8) fig.set_figheight(6) # ================================================================================ # v. Save the model # ================================================================================ printlog(\u0026#34;step5: saving model ...\u0026#34;) model_dir = \u0026#34;data/bst.model\u0026#34; print(\u0026#34;model_dir: %s\u0026#34;%model_dir) bst.save_model(model_dir) bst_loaded = xgb.Booster(model_file=model_dir) printlog(\u0026#34;task end...\u0026#34;) Source\n","date":"22 Nov, 2021","image":"images/blog/post-6.webp","permalink":"https://codelink.ai/blog/data-science/a-30-minute-guide-to-xgboost/","tags":["algorithm","python"],"title":"A 30-minute's guide to XGBoost (Python code)"},{"categories":["data science"],"contents":" KalidoKit is the integration of a variety of algorithms to achieve, Facemesh, Blazepose, Handpose, Holistic. Let\u0026rsquo;s see the effect.\nThe virtual image is driven by the movements of real human limbs, faces and hands.\nThe mainstream application direction of this technology is virtual anchor.\nIt is possible to drive avatars to dance.\nIt can also capture the whole body movements, facial expressions, gestures, etc., like the motion picture at the beginning.\nIn addition to this type of driving virtual image type, you can also use your imagination to make some interesting small applications.\nKalidoKit  This project is based on Tensorflow.js implementation.\n Project address: https://github.com/yeemachine/kalidokit\n The key point information captured can be used to drive 2D and 3D avatars, combined with some avatar driving engines, to achieve the effect shown at the beginning of the article.\nIt is possible to drive both Live2D images and 3D VRM images.\nThe technical points involved here can\u0026rsquo;t be finished in one article, so today we mainly talk about the basic key point detection technologies: face key point detection, human pose estimation, and gesture pose estimation.\nFace keypoint detection  Face keypoint detection, there are sparse and dense.\nLike the basic one, 68 keypoints are detected.\nGenerally speaking, for the detection of closed eyes, head posture, open and closed mouth, a simple 68 keypoints is enough.\nOf course, there are also more dense keypoints detection.\nFor some skin beauty applications, a dense keypoint detection algorithm is needed, with thousands of keypoints.\nBut the idea of the algorithm is the same, to return the location coordinates of these keypoints, usually used with face detection algorithms.\nFor those who want to learn face keypoint detection algorithms, we recommend two introductory projects.\n https://github.com/1adrianb/face-alignment https://github.com/ChanChiChoi/awesome-Face_Recognition  One is a basic introductory project, and the other integrates the mainstream algorithms for face keypoints.\nHuman Pose Estimation  Human pose estimation is also a very basic problem in computer vision.\nFrom the point of view of the name, it can be understood as the estimation of the position of the \u0026ldquo;human body\u0026rdquo; pose (key points, such as head, left hand, right foot, etc.).\nGenerally, there are 4 types of tasks.\n Single-Person Skeleton Estimation (SPSE) Multi-person Pose Estimation Video Pose Tracking 3D Skeleton Estimation  Simply put, it is the detection of human skeleton joint points to locate the human pose.\nHuman pose estimation has a wide range of applications, for example, pose detection and action prediction of pedestrians in street scenes in the autonomous driving industry; pedestrian re-identification problems in the security field, specific action monitoring in special scenes; movie special effects in the film industry, etc.\nFor those who want to learn, you can read this compiled paper at:\n https://github.com/cbsudux/awesome-human-pose-estimation\n Gestural posture estimation  Hand joints are more flexible, agile and self-obscuring, so it is a little more complicated.\nBut the principle is similar to human posture estimation.\nIn addition to this regular gesture recognition, it can also be used to do some special effects.\nIn fact, many of these human effects, the positioning of the position, are achieved with the help of these key points.\nAs above, to learn, you can see this integrated material at:\n https://github.com/xinghaochen/awesome-hand-pose-estimation\n Source\n","date":"22 Nov, 2021","image":"images/blog/post-5.png","permalink":"https://codelink.ai/blog/data-science/algorithm-kalidokit/","tags":["computer vision","python"],"title":"KalidoKit: algorithms to achieve, Facemesh, Blazepose, Handpose, Holistic"},{"categories":["python"],"contents":" This article will focus on the threading module, and for everyday developers, this content is a must-have, and also a high frequency interview FAQ.\n Official documentation (https://docs.python.org/zh-cn/3.6/library/threading.html)\n Thread safety  Thread safety is a concept in multi-threaded or multi-process programming. In a program where multiple threads with shared data are executed in parallel, thread-safe code will ensure that each thread is executed properly and correctly through a synchronization mechanism, without data contamination or other unexpected situations.\nFor example, if there are 10 candies (resources) in a room (process), and there are 3 villains (1 main thread and 2 sub-threads), when villain A eats 3 candies and is forced to rest by the system, he thinks there are 7 candies left, and when villain B eats 3 candies after working, then when villain A comes back on duty, he thinks there are 7 candies left, but in fact there are only 4.\nThe above example where the data of thread A and thread B are not synchronized is a thread safety issue which can lead to very serious surprises, let\u0026rsquo;s go by the following example.\nHere we have a value num with an initial value of 0. We open 2 threads.\n  Thread 1 performs a 10 million + 1 operation on num\n  Thread 2 performs a -1 operation on num 10 million times\n  The result may be staggering, as num does not end up being 0 as we thought.\nimport threading num = 0 def add(): global num for i in range(10_000_000): num += 1 def sub(): global num for i in range(10_000_000): num -= 1 if __name__ == \u0026#34;__main__\u0026#34;: subThread01 = threading.Thread(target=add) subThread02 = threading. subThread01.start() subThread02.start() subThread01.join() subThread02.join() print(\u0026#34;num result : %s\u0026#34; % num) # The results are collected three times # num result : 669214 # num result : -1849179 # num result : -525674 This is a very good case above, and to solve this problem we have to secure the timing of thread switching through locks.\nIt is worth noting that the Python basic data types list, tuple, and dict are thread-safe, so if there are multiple threads operating on these three containers, we don\u0026rsquo;t need to consider thread-safety issues.\nThe role of locks  Locks are a means by which Python provides us with the ability to manipulate thread switching on our own, and they can be used to make thread switching orderly.\nOnce thread switching is ordered, access and modification of data between threads becomes controlled, so to ensure thread safety, locks must be used.\nThe threading module provides the five most common types of locks, which are divided by function as follows.\n synchronous locks: lock (only one can be released at a time) recursive locks: rlock (only one can be released at a time) conditional locks: condition (any one can be released at a time) Event lock: event (all at once) semaphore lock: semaphore (can release a specific one at a time)  1. Lock() synchronous lock  Basic introduction Lock lock has many names, such as.\n Synchronous lock Mutual exclusion lock  What do they mean? As follows.\n  Mutual exclusion means that a resource can be accessed by only one visitor at the same time, and is unique and exclusive, but mutual exclusion cannot restrict the order of access to the resource by the visitor, i.e., the access is unordered\n  Synchronization means that on the basis of mutual exclusion (in most cases), other mechanisms are used to achieve orderly access to resources by visitors\n  Synchronization is actually a more complex implementation of mutual exclusion, because it implements orderly access on top of mutual exclusion\n  The following methods are provided by the threading module in connection with synchronous locks.\n   Method Description     threading.Lock() returns a synchronous lock object   lockObject.acquire(blocking=True, timeout=1) lock, when a thread is executing the locked block, it will not be allowed to switch to other threads, the default lock expiration time is 1 second   lockObject.release() Unlock, when a thread is executing an unlocked block, it will allow the system to switch to other threads according to the policy   lockObject.locked() determines whether the lock object is locked or not, and returns a boolean value    Usage  Synchronous locks can only release one thread at a time. A locked thread will not surrender execution rights while running, but will only hand over execution rights to other threads through system scheduling when the thread is unlocked.\nThe top problem is solved using synchronous locking as follows.\nimport threading num = 0 def add(): lock.acquire() global num for i in range(10_000_000): num += 1 lock.release() def sub(): lock.acquire() global num for i in range(10_000_000): num -= 1 lock.release() if __name__ == \u0026#34;__main__\u0026#34;: lock = threading.Lock() subThread01 = threading.Thread(target=add) subThread02 = threading. subThread01.start() subThread02.start() subThread01.join() subThread02.join() print(\u0026#34;num result : %s\u0026#34; % num) # The results are collected three times # num result : 0 # num result : 0 # num result : 0 This makes the code completely serial, which is not as fast as directly using serialized single-threaded execution for such computationally intensive I/O operations, so this example is only meant as an example and does not outline the real use of locks.\nDeadlock phenomenon  For synchronous locks, one acquire() must correspond to one release(), and the operation of using multiple acquires() followed by multiple releases() cannot be repeated continuously, which will cause a deadlock causing the program to block and not move at all, as follows.\nimport threading num = 0 def add(): lock.acquire() # locking lock.acquire() # deadlock # Do not execute global num for i in range(10_000_000): num += 1 lock.release() lock.release() def sub(): lock.acquire() # locking lock.acquire() # deadlock # Do not execute global num for i in range(10_000_000): num -= 1 lock.release() lock.release() if __name__ == \u0026#34;__main__\u0026#34;: lock = threading.Lock() subThread01 = threading.Thread(target=add) subThread02 = threading. subThread01.start() subThread02.start() subThread01.join() subThread02.join() print(\u0026#34;num result : %s\u0026#34; % num) The with statement  Since the __enter__() and __exit__() methods are implemented in the threading.Lock() object, we can use the with statement to perform context-managed locking and unlocking operations in the following way.\nimport threading num = 0 def add(): with lock: # auto-lock global num for i in range(10_000_000): num += 1 # Auto-unlock def sub(): with lock: # Auto-lock global num for i in range(10_000_000): num -= 1 # Auto-unlock if __name__ == \u0026#34;__main__\u0026#34;: lock = threading.Lock() subThread01 = threading.Thread(target=add) subThread02 = threading. subThread01.start() subThread02.start() subThread01.join() subThread02.join() print(\u0026#34;num result : %s\u0026#34; % num) # The results are collected three times # num result : 0 # num result : 0 # num result : 0 2. RLock() Recursive lock  Basic introduction Recursive locking is an upgraded version of synchronous locking, which can be done on the basis of synchronous locking by repeatedly using acquire() and then repeatedly using release(), but it must be noted that the number of locks and unlocks must be the same, otherwise it will also cause deadlock phenomenon.\nThe following methods are provided by the threading module with recursive locks.\n   Method Description     threading.RLock() returns a recursive lock object   lockObject.acquire(blocking=True, timeout=1) lock, when a thread is executing the locked block, it will not be allowed to switch to other threads, the default lock expiration time is 1 second   lockObject.release() Unlock, when a thread is executing an unlocked block, it will allow the system to switch to other threads according to the policy   lockObject.locked() determines whether the lock object is locked or not, and returns a boolean value    Usage The following is a simple use of recursive locking. If you use synchronous locking, deadlocking will occur, but recursive locking will not.\nimport threading num = 0 def add(): lock.acquire() lock.acquire() global num for i in range(10_000_000): num += 1 lock.release() lock.release() def sub(): lock.acquire() lock.acquire() global num for i in range(10_000_000): num -= 1 lock.release() lock.release() if __name__ == \u0026#34;__main__\u0026#34;: lock = threading.RLock() subThread01 = threading.Thread(target=add) subThread02 = threading. subThread01.start() subThread02.start() subThread01.join() subThread02.join() print(\u0026#34;num result : %s\u0026#34; % num) # The results are collected three times # num result : 0 # num result : 0 # num result : 0 The with statement Since the __enter__() and __exit__() methods are implemented in the threading.RLock() object, we can use the with statement to perform context-managed locking and unlocking operations in the form of\nimport threading num = 0 def add(): with lock: # auto-lock global num for i in range(10_000_000): num += 1 # Auto-unlock def sub(): with lock: # Auto-lock global num for i in range(10_000_000): num -= 1 # Auto-unlock if __name__ == \u0026#34;__main__\u0026#34;: lock = threading.RLock() subThread01 = threading.Thread(target=add) subThread02 = threading. subThread01.start() subThread02.start() subThread01.join() subThread02.join() print(\u0026#34;num result : %s\u0026#34; % num) # The results are collected three times # num result : 0 # num result : 0 # num result : 0 3. Condition() Condition lock  Basic introduction Condition lock is based on the recursive lock to add the function to suspend the running of the thread. And we can use wait() and notify() to control the number of threads executed.\nNote: Conditional locks can be freely set to release several threads at a time.\nThe following methods are provided by the threading module and the conditional lock.\n   Method Description     threading.Condition() returns a conditional lock object   lockObject.acquire(blocking=True, timeout=1) lock, when a thread is executing the locked block, it will not be allowed to switch to another thread, the default lock expiration time is 1 second   lockObject.release() Unlock, when a thread is executing an unlocked block, it will allow the system to switch to other threads according to the policy   lockObject.wait(timeout=None) sets the current thread to a \u0026ldquo;wait\u0026rdquo; state, which will only continue after the thread is \u0026ldquo;notified\u0026rdquo; or the timeout expires. The thread in the \u0026ldquo;wait\u0026rdquo; state will allow the system to switch to other threads according to the policy   lockObject.wait_for(predicate, timeout=None) sets the current thread to the \u0026ldquo;waiting\u0026rdquo; state, and will only continue to run after the thread\u0026rsquo;s predicate returns a True or the timeout expires. The thread in the \u0026ldquo;waiting\u0026rdquo; state will allow the system to switch to other threads according to the policy. Note: the predicate parameter should be passed as a callable object and return a bool type result   lockObject.notify(n=1) notifies a thread with the current status of \u0026ldquo;waiting\u0026rdquo; to continue running, or multiple threads with the n parameter   lockObject.notify_all() notifies all threads whose current state is \u0026ldquo;waiting\u0026rdquo; to continue running    Usage The following example starts 10 sub-threads and immediately sets the 10 sub-threads to the waiting state.\nThen we can send one or more notifications to resume the waiting subthreads.\nimport threading currentRunThreadNumber = 0 maxSubThreadNumber = 10 def task(): global currentRunThreadNumber thName = threading.currentThread().name condLock.acquire() # lock print(\u0026#34;start and wait run thread : %s\u0026#34; % thName) condLock.wait() # suspend the thread and wait to wake it up currentRunThreadNumber += 1 print(\u0026#34;carry on run thread : %s\u0026#34; % thName) condLock.release() # unlock if __name__ == \u0026#34;__main__\u0026#34;: condLock = threading.Condition() for i in range(maxSubThreadNumber): subThreadIns = threading.Thread(target=task) subThreadIns.start() while currentRunThreadNumber \u0026lt; maxSubThreadNumber: notifyNumber = int( input(\u0026#34;Please enter the number of threads that need to be notified to run:\u0026#34;)) condLock.acquire() condLock.notify(notifyNumber) # release condLock.release() print(\u0026#34;main thread run end\u0026#34;) # Start 10 subthreads first, then all of them will become waiting # start and wait run thread : Thread-1 # start and wait run thread : Thread-2 # start and wait run thread : Thread-3 # start and wait run thread : Thread-4 # start and wait run thread : Thread-5 # start and wait run thread : Thread-6 # start and wait run thread : Thread-7 # start and wait run thread : Thread-8 # start and wait run thread : Thread-9 # start and wait run thread : Thread-10 # Batch send notification to release a specific number of sub threads to continue running # Please enter the number of threads that need to be notified to run: 5 # Release 5 # carry on run thread : Thread-4 # carry on run thread : Thread-3 # carry on run thread : Thread-1 # carry on run thread : Thread-2 # carry on run thread : Thread-5 # Please enter the number of threads that need to be notified to run : 5 # release 5 # carry on run thread : Thread-8 # carry on run thread : Thread-10 # carry on run thread : Thread-6 # carry on run thread : Thread-9 # carry on run thread : Thread-7 # Please enter the number of threads that need to be notified to run: 1 # main thread run end with statement Since the __enter__() and __exit__() methods are implemented in the threading.Condition() object, we can use the with statement to perform context-managed locking and unlocking operations in the form of\nimport threading currentRunThreadNumber = 0 maxSubThreadNumber = 10 def task(): global currentRunThreadNumber thName = threading.currentThread().name with condLock: print(\u0026#34;start and wait run thread : %s\u0026#34; % thName) condLock.wait() # suspend the thread and wait to wake it up currentRunThreadNumber += 1 print(\u0026#34;carry on run thread : %s\u0026#34; % thName) if __name__ == \u0026#34;__main__\u0026#34;: condLock = threading. for i in range(maxSubThreadNumber): subThreadIns = threading.Thread(target=task) subThreadIns.start() while currentRunThreadNumber \u0026lt; maxSubThreadNumber: notifyNumber = int( input(\u0026#34;Please enter the number of threads that need to be notified to run:\u0026#34;)) with condLock: condLock.notify(notifyNumber) # Release print(\u0026#34;main thread run end\u0026#34;) 4. Event() event lock  Basic introduction Event lock is based on conditional locking. The difference between it and conditional locking is that it can only release all the threads at once, and cannot release any number of child threads to continue running.\nWe can think of event lock as a traffic light, when the light is red all sub-threads are suspended and enter the \u0026ldquo;waiting\u0026rdquo; state, when the light is green all sub-threads are back to \u0026ldquo;running\u0026rdquo;.\nThe following methods are provided by the threading module in relation to the event lock.\n   Method Description     threading.Event() returns an event lock object   lockObject.clear() sets the event lock to a red light, i.e. all threads are suspended   lockObject.is_set() is used to determine the current event lock status, red is False, green is True   lockObject.set() sets the event lock to a green state, i.e. all threads resume running   lockObject.wait(timeout=None) sets the current thread to the \u0026ldquo;wait\u0026rdquo; state, which will continue to run only after the thread receives the \u0026ldquo;green light\u0026rdquo; or the timeout expires. The thread in the \u0026ldquo;wait\u0026rdquo; state will allow the system to switch to other threads according to the policy.    Usage Event locks cannot be used with the with statement, only in the usual way.\nLet\u0026rsquo;s simulate the operation of a thread and a traffic light, stop on red and go on green as follows\nimport threading maxSubThreadNumber = 3 def task(): thName = threading.currentThread().name print(\u0026#34;start and wait run thread : %s\u0026#34; % thName) eventLock.wait() # pause run and wait for green light print(\u0026#34;green light, %scarry on run\u0026#34; % thName) print(\u0026#34;red light, %sstop run\u0026#34; % thName) eventLock.wait() # pause run, wait for green light print(\u0026#34;green light, %scarry on run\u0026#34; % thName) print(\u0026#34;sub thread %srun end\u0026#34; % thName) if __name__ == \u0026#34;__main__\u0026#34;: eventLock = threading.Event() for i in range(maxSubThreadNumber): subThreadIns = threading.Thread(target=task) subThreadIns.start() eventLock.set() # set to green eventLock.clear() # set to red eventLock.set() # set to green # start and wait run thread : Thread-1 # start and wait run thread : Thread-2 # start and wait run thread : Thread-3 # green light, Thread-1 carry on run # red light, Thread-1 stop run # green light, Thread-1 carry on run # sub thread Thread-1 run end # green light, Thread-3 carry on run # red light, Thread-3 stop run # green light, Thread-3 carry on run # sub thread Thread-3 run end # green light, Thread-2 carry on run # red light, Thread-2 stop run # green light, Thread-2 carry on run # sub thread Thread-2 run end 5. Semaphore() semaphore lock  Basic Introduction A semaphore lock is also based on a conditional lock. It differs from a conditional lock and an event lock as follows.\nConditional lock: You can release any thread that is in the \u0026ldquo;waiting\u0026rdquo; state at one time.\nEvent lock: All threads in the \u0026ldquo;waiting\u0026rdquo; state can be released at once.\nSemaphore locks: a specified number of threads can be released in a batch in a \u0026ldquo;locked\u0026rdquo; state.\nThe following methods are provided by the threading module in relation to semaphore locks.\n   Method Description     threading.Semaphore() returns a semaphore lock object   lockObject.acquire(blocking=True, timeout=1) lock, when a thread is executing a locked block, it will not be allowed to switch to another thread, the default lock expiration time is 1 second   lockObject.release() Unlock, when a thread is executing an unlocked block, it will allow the system to switch to other threads according to the policy    Usage The following is a sample usage, which you can use as a width-limited section where only the same number of threads can be released at a time.\nimport threading import time maxSubThreadNumber = 6 def task(): thName = threading.currentThread().name semaLock.acquire() print(\u0026#34;run sub thread %s\u0026#34; % thName) time.sleep(3) semaLock.release() if __name__ == \u0026#34;__main__\u0026#34;: # Only 2 can be released at a time semaLock = threading.Semaphore(2) for i in range(maxSubThreadNumber): subThreadIns = threading.Thread(target=task) subThreadIns.start() # run sub thread Thread-1 # run sub thread Thread-2 # run sub thread Thread-3 # run sub thread Thread-4 # run sub thread Thread-6 # run sub thread Thread-5 The with statement Since the __enter__() and __exit__() methods are implemented in the threading.Semaphore() object, we can use the with statement to perform context-managed locking and unlocking operations.\nimport threading import time maxSubThreadNumber = 6 def task(): thName = threading.currentThread().name with semaLock: print(\u0026#34;run sub thread %s\u0026#34; % thName) time.sleep(3) if __name__ == \u0026#34;__main__\u0026#34;: semaLock = threading.Semaphore(2) for i in range(maxSubThreadNumber): subThreadIns = threading.Thread(target=task) subThreadIns.start() Lock Relationships  The above 5 types of locks can be said to be based on synchronous locks to do, which you can find from the source code.\nFirst, let\u0026rsquo;s look at the RLock recursive lock. The implementation of recursive lock is very simple, it maintains an internal counter, when the counter is not 0, the thread cannot be switched by I/O operations and time polling mechanism. This is not the case when the counter is 0:\ndef __init__(self): self._block = _allocate_lock() self._owner = None self._count = 0 # counter The Condition conditional lock actually has two locks inside, a bottom-level lock (synchronous lock) and a high-level lock (recursive lock).\nThere are two ways to unlock the low-level lock. Using the wait() method temporarily unlocks the bottom-level lock and adds a high-level lock, and only when it receives a notfiy() from another thread does it unlock the high-level lock and re-lock the low-level lock, which means that the condition lock is implemented based on the constant switching between synchronous and recursive locks.\ndef __init__(self, lock=None): if lock is None: lock = RLock() # You can see that conditional locking is internally based on recursive locking, which in turn is based on synchronous locking self._lock = lock self.acquire = lock.acquire self.release = lock.release try: self._release_save = lock._release_save except AttributeError: pass try: self._acquire_restore = lock._acquire_restore except AttributeError: pass try: self._is_owned = lock._is_owned except AttributeError: pass self._waiters = _deque() Event event locks are internally based on conditional locks to do the following.\nclass Event: def __init__(self): self._cond = Condition(Lock()) # Instantiates a conditional lock. self._flag = False def _reset_internal_locks(self): # private! called by Thread._reset_internal_locks by _after_fork() self._cond.__init__(Lock()) def is_set(self): \u0026#34;\u0026#34;\u0026#34;Return true if and only if the internal flag is true.\u0026#34;\u0026#34;\u0026#34; return self._flag isSet = is_set Semaphore semaphore locks are also internally based on conditional locks to do the following.\nclass Semaphore: def __init__(self, value=1): if value \u0026lt; 0: raise ValueError(\u0026#34;semaphore initial value must be \u0026gt;= 0\u0026#34;) self._cond = Condition(Lock()) # As you can see, a conditional lock is instantiated here self._value = value Basic Exercises  Application of conditional locks Requirement: An empty list with two threads taking turns adding values to it (one adding an even number, one adding an odd number), so that the values in the list are 1 - 100, and are ordered.\nimport threading lst = [] def even(): \u0026#34;\u0026#34;\u0026#34;Add even numbers\u0026#34;\u0026#34;\u0026#34;\u0026#34; with condLock: for i in range(2, 101, 2): # Determine if the current list is exhausted at length 2 # If so, add an odd number # If not, add an even number if len(lst) % 2 ! = 0: # Add an even number lst.append(i) # Add the value first condLock.notify() # tell the other thread that you can add the odd number, but here you don\u0026#39;t immediately hand over execution condLock.wait() # hand over execution rights and wait for another thread to notify to add an even number else: # Add an odd number condLock.wait() # surrender execution rights and wait for another thread to notify to add an even number lst.append(i) condLock.notify() condLock.notify() def odd(): \u0026#34;\u0026#34;\u0026#34;add odd numbers\u0026#34;\u0026#34;\u0026#34;\u0026#34; with condLock: for i in range(1, 101, 2): if len(lst) % 2 == 0: lst.append(i) condLock.notify() condLock.wait() condLock.notify() if __name__ == \u0026#34;__main__\u0026#34;: condLock = threading.Condition() addEvenTask = threading.Thread(target=even) addOddTask = threading. addEvenTask.start() addOddTask.start() addEvenTask.join() addOddTask.join() print(lst) Application of event locks There are 2 task threads to play Li Bai and Du Fu, how can we make them reply to each other in one sentence? The text is as follows.\nDu Fu: Old Li, come drink! Li Bai: Old Du, I can't drink anymore! Du Fu: Old Li, one more pot? Du Fu: ... old Li? Li Bai: Hoo hoo hoo... fell asleep... The code is as follows.\nimport threading def libai(): event.wait() print(\u0026#34;Li Bai: Lao Du ah, do not drink I can not drink!\u0026#34;) event.set() event.clear() event.wait() print(\u0026#34;Li Bai: Hoo hoo hoo... Sleeping...\u0026#34;) def dufu(): print(\u0026#34;Dufu: Old Li, come drink!\u0026#34;) event.set() event.clear() event.wait() print(\u0026#34;Du Fu: Old Li ah, another pot?\u0026#34;) print(\u0026#34;Du Fu: ... Old Li?\u0026#34;) event.set() if __name__ == \u0026#39;__main__\u0026#39;: event = threading.Event() t1 = threading.Thread(target=libai) Thread(target=dufu) t1.start() t2.start() t1.join() t2.join() Source\n","date":"20 Nov, 2021","image":"images/blog/python.png","permalink":"https://codelink.ai/blog/python/explaining-the-5-python-thread-locks/","tags":["multi-threading"],"title":"Explaining the 5 Python thread locks"},{"categories":["python"],"contents":" I recently got a new task: I need to split a video of an event into smaller segments of two minutes or less for posting on a short video platform.\nI thought it would be a one-time job, but it turned out to be too big and too short to handle manually, so Python came to my rescue once again.\nSo what are you waiting for, let\u0026rsquo;s do it!\nThe most important thing  No matter what you do, you have to analyze what\u0026rsquo;s the most important thing, then focus on attacking it, and then move on to the most important thing.\nFor our task, it is not a big project, but then, we still need to find the most important thing to start, step by step, and eventually the whole problem will be solved.\nAs a whole, we need to read video files from a directory, then, crop each video file, and finally save the processed files.\nWhat is the most important thing in this process? I think, it\u0026rsquo;s video cropping. If you can\u0026rsquo;t crop the video easily, all the other work is in vain, right?\nCrop video  Nowadays, short videos are very popular, and there are many video editing software with rich features, and all we need is the cropping function, and we need to call it programmatically, so there is nothing better than ffmpeg.\nffmpeg is a command line tool that is powerful and can be called programmatically.\nDownload the version for your operating system from the ffmpeg website.\nAfter downloading, unzip it into a directory and configure the bin in the directory to the environment variables. Then open a command line and type.\n\u0026gt; ffmpeg -version ffmpeg version 2021-10-07-git-b6aeee2d8b-full_build- ... Test it out and it shows the version information, which means it\u0026rsquo;s configured.\nNow read the documentation and find that the command to split the video file is\nffmpeg -i [filename] -ss [starttime] -t [length] -c copy [newfilename]  i is the file to be cropped ss is the start time of the crop t is the end time or length of the crop c is the storage of the cropped file  Okay, write a function in Python:\nimport subprocess as sp def cut_video(filename, outfile, start, length=90): cmd = \u0026#34;ffmpeg -i %s-ss %d-t %d-c copy %s\u0026#34; % (filename, start, length, outfile) p = sp.Popen(cmd, shell=True) p.wait() return  Defines a function that passes in the information needed by ffmpeg via parameters Write the crop command as a string template and replace the arguments into it Execute the command with subprocess\u0026rsquo;s Popen, where the argument shell=True means execute the command as a whole p.wait() is important, because cropping takes a while and is executed in a separate process, so you need to wait for the execution to finish before doing subsequent work, otherwise you may not find the cropped file  So the video cropping is done, and then we\u0026rsquo;ll see what\u0026rsquo;s most important.\nCalculating segments  When video cropping, you need some parameters, especially the start time, how to determine it? If this thing is not done properly, the cropping work will be very troublesome.\nSo take a look at how to calculate the crop segments.\nI need to crop the video into small segments of one and a half minutes, then will need to know the duration of the target video file.\nGet the video length  How to get the length? ffmpeg provides another command \u0026ndash; ffprobe.\nAfter looking around, one can synthesize a command to get.\n\u0026gt; ffprobe -v error -show_entries format=duration -of default=noprint_wrappers=1:nokey=1 -i a.flv 920.667 The command is rather complicated, you can ignore the other parameters first, just pass in the video file to be analyzed. The result of the command is to display the length of a line of video files.\nSo you can write a function.\nimport subprocess as sp def get_video_duration(filename): cmd = \u0026#34;ffprobe -v error -show_entries format=duration -of default=noprint_wrappers=1:nokey=1 -i %s\u0026#34; % filename p = sp.Popen(cmd, stdout=sp.PIPE, stderr=sp.PIPE) p.wait() strout, strerr = p.communicate() # remove the last carriage return ret = strout.decode(\u0026#34;utf-8\u0026#34;).split(\u0026#34;\\n\u0026#34;)[0] return ret  The function has only one parameter, the video file path Synthesize the command statement and replace the video file path with it use subprocess to execute, note that here you need to set the output of the command execution use wait to wait for the command execution to finish Extract the output result by communicate Extracts the length of the video file from the result and returns  Segmentation  After getting the length of the video, determine the length of each segment, and then calculate how many segments are needed.\nThe code is simple.\nimport math duration = math.floor(float(get_video_duration(filename))) part = math.ceil(duration / length) Note that when calculating the segment, you need to do an upward rounding, i.e., use ceil, to include the last bit of the tail.\nOnce you have the number of segments you need, use a loop to calculate the start time of each segment.\nGetting the files Because there are many files to process, it is necessary to automatically fetch the files that need to be processed.\nThe method is simple and commonly used. You can generally use os.walk to get the files recursively, or you can write your own, depending on the actual situation.\nfor fname in os.listdir(dir): fname = os.path.join(dir, os.path.join(dir, fname)) basenames = os.path.basename(fname).split(\u0026#39;.\u0026#39;) mainname = basenames[0].split(\u0026#34;_\u0026#34;)[0] ... Provide the directory where the video file is located, get the files in the directory via os.listdir, and then, synthesize the absolute path of the file, because it is easier to call the crop command when you need the absolute path.\nGet the file name, in order to name the cropped file later.\nCode integration  Now that each part is written, the code can be integrated as follows\ndef main(dir): outdir = os.path.join(dir, \u0026#34;output\u0026#34;) if not os.path.exists(outdir): os.mkdir(outdir) for fname in os.listdir(dir): fname = os.path.join(dir, os.path.join(dir, fname)) if os.path.isfile(fname): split_video(fname, outdir)  The main method is a post-integration method First create a culled storage directory and put it in the output directory of the video file directory After getting the files by listdir, each file is processed, which determines whether it is a file or not Call the split_video method to start cropping a video file  Summary  Overall, this is a very simple application, the core function is to call a ffmpeg command.\nWhat is more important than the technology is how to analyze and break down a project and where to start.\nThe way to start here is to keep looking for the most important things, and to use the most important things as clues to keep moving forward and eventually solve the whole problem in a bottom-up way.\nI hope this article has inspired you.\nSource:\n ffmpeg: http://ffmpeg.org/ https://mp.weixin.qq.com/s/Ts3isK0qLU5xHfYhVOtBPg  ","date":"28 Oct, 2021","image":"images/blog/ffmpeg.png","permalink":"https://codelink.ai/blog/python/the-magic-tool-ffmpeg-operating-video-with-extreme-comfort/","tags":["learning","ffmpeg"],"title":"The magic tool ffmpeg -- editing video with extreme comfort"},{"categories":["python"],"contents":" Today we share with you 3 relatively cold knowledge.\nThe first one: the magic dictionary key  some_dict = {} some_dict[5.5] = \u0026#34;Ruby\u0026#34; some_dict[5.0] = \u0026#34;JavaScript\u0026#34; some_dict[5] = \u0026#34;Python\u0026#34; Output:\n\u0026gt;\u0026gt;\u0026gt; some_dict[5.5] \u0026#34;Ruby\u0026#34; \u0026gt;\u0026gt;\u0026gt; some_dict[5.0] \u0026#34;Python\u0026#34; \u0026gt;\u0026gt;\u0026gt; some_dict[5] \u0026#34;Python\u0026#34; \u0026ldquo;Python\u0026rdquo; eliminates the existence of \u0026ldquo;JavaScript\u0026rdquo;?\nüí° Description:\n  The Python dictionary determines whether two keys are identical by checking for key equality and comparing hash values.\n  Immutable objects with the same value always have the same hash value in Python.\n  Note: Objects with different values may also have the same hash (hash collision).\n\u0026gt;\u0026gt; 5 == 5.0 True \u0026gt;\u0026gt;\u0026gt; hash(5) == hash(5.0) True When executing the statement some_dict[5] = \u0026quot;Python\u0026quot;, the existing value \u0026ldquo;JavaScript\u0026rdquo; is overwritten by \u0026ldquo;Python\u0026rdquo; because Python recognizes 5 and 5.0 as the same key of some_dict.\nSecond: return in exception handling  def some_func(): try: return \u0026#39;from_try\u0026#39; finally: return \u0026#39;from_finally\u0026#39; Output:\n\u0026gt;\u0026gt;\u0026gt; some_func() \u0026#39;from_finally\u0026#39; üí° Description:\n  When return, break or continue is executed in the try of the \u0026ldquo;try\u0026hellip;finally\u0026rdquo; statement, the finally clause is still executed.\n  The return value of the function is determined by the last executed return statement. Since the finally clause will always be executed, the return in the finally clause will always be the last statement executed.\n  Third: Determination of identical objects  class WTF: pass Output:\n\u0026gt;\u0026gt;\u0026gt; WTF() == WTF() # Two different objects should not be equal False \u0026gt;\u0026gt;\u0026gt; WTF() is WTF() # also not the same False \u0026gt;\u0026gt;\u0026gt; hash(WTF()) == hash(WTF()) # The hash values should also be different True \u0026gt;\u0026gt;\u0026gt; id(WTF()) == id(WTF()) True üí° Description:\n  When the id function is called, Python creates an object of class WTF and passes it to the id function. The id function then gets its id value (that is, its memory address), and discards the object. The object is then destroyed.\n  When we do this twice in a row, Python allocates the same memory address to the second object. Because the id function (in CPython) uses the object\u0026rsquo;s memory address as the object\u0026rsquo;s id value, the id values of both objects are the same.\n  In summary, an object\u0026rsquo;s id value is unique only for the life of the object. After the object is destroyed, or before it is created, other objects can have the same id value.\n  So why does the is operation result in False? Let\u0026rsquo;s look at this code.\n  class WTF(object): def __init__(self): print(\u0026#34;I\u0026#34;) def __del__(self): print(\u0026#34;D\u0026#34;) Output:\n\u0026gt;\u0026gt;\u0026gt; WTF() is WTF() I I D D False \u0026gt;\u0026gt;\u0026gt; id(WTF()) == id(WTF()) I D I D True As you can see, the order of object destruction is the reason for all the differences.\nSource: https://github.com/leisurelicht/wtfpython-cn\n","date":"19 Oct, 2021","image":"images/blog/python.png","permalink":"https://codelink.ai/blog/python/there-are-3-incredible-return-functions-in-python/","tags":["learning"],"title":"There are 3 incredible return functions in Python"},{"categories":["web development"],"contents":" There is no doubt: making good use of online resources and tools can speed up development, improve quality, and make life more Chill üòé~.\nThis article brings you 10 great free web resources for front-end developers ‚≠ê üòé (‡πë-ÃÄ„ÖÇ-ÃÅ)Ÿà‚úß\n1. Undraw  If you need free SVG illustrations for your website, don\u0026rsquo;t miss Undraw!\nSVG illustration resources are huge, with search function available; and, you can also customize the color scheme of the illustration, simply too NICE ~\nA large number of resources, support search üîç Feel free to change the color scheme üåà\n2. Error 404  I don\u0026rsquo;t know where you would normally go to find 404 page material ~\nNow you have one more option: Error 404\nCool, cool, cool!\n3. Squoosh  Compressed images!\nCompared to tinypng has better compression effect.\ntinypng compression\nSquoosh compression\nCompression effect: the former is 80%, the latter is 95%; the final result is also good ~üëç\nWhy not try ?\n4. DevDocs  DevDocs, as the name suggests, is the technical documentation for web development and is a very good learning manual!\nOther than that, I like the UI! Also supports adding common technical documents, changing the theme, etc. ~\n5. iHateRegex  If you hate regular expressions, then do not miss this site (Àâ‚ñΩÀâ;)\u0026hellip;\nNot only that, but there are also detailed illustrations! Damn, it\u0026rsquo;s so well done ‚ïÆ(‚ïØ‚ñΩ‚ñΩ)‚ï≠\n6. Carbon  People often ask: \u0026ldquo;How do I generate such nice code snippets?\u0026rdquo; and the answer is in Carbon!\nYou can generate code snippets for various themes and languages and export them as images or copy them to other platforms, it\u0026rsquo;s really nice to use üëå üëå üëå comfortable~~\n7. Dribbble  For web design inspiration, look no further than Dribbble!!!\nWhen you see other people\u0026rsquo;s backend designs, you want to go back and rip up your own üê∂\n8. Animista  Css animation, copy the code and you can use it! No installation, doesn\u0026rsquo;t it sound good?\n9. Shape Divider  You can generate all kinds of dividers and export them in SVG format.\nFancy, I like it (‚ù§ œâ ‚ù§)\n10. Notion  If you need a platform for note-taking, we recommend one option: Notion\nQuick Notes, TaskList, Diary, Reading List, all types, everything, recommended~\nSource\n","date":"17 Oct, 2021","image":"images/blog/post-3.webp","permalink":"https://codelink.ai/blog/web-development/recommend-10-very-wow-web-resources-to-the-front-end-developers/","tags":["tools","frontend","web"],"title":"Recommend 10 very 'wow' Web 'resources' to the front-end developers"},{"categories":["devops"],"contents":" ag faster than grep, ack recursive search file content.\n tig Interactive view of git projects in character mode, can replace git command.\n mycli mysql client, support syntax highlighting and command completion, similar to ipython, can replace mysql command.\n jq json file processing and formatting display, support highlighting, can replace python -m json.tool.\n shellcheck shell script static checking tool, can identify syntax errors and irregular writing style.\n fzf command line fuzzy search tool, can interactively and intelligently search and select files or content, with terminal ctrl-r history command search is perfect.\n PathPicker(fpp) Automatically identifies directories and files in the command line output, supports interactive, very useful with git.\nRun the following command.\ngit diff HEAD~8 --stat | fpp   htop Provides a more beautiful and convenient process monitoring tool, replacing the top command.\n glances A more powerful alternative to htop / top.\nhtop replaces top, glances replaces htop: htop replaces top, glances replaces htop.\nInformation is much richer and more complete than htop, isn\u0026rsquo;t it? In addition to the command line view, glances also provides a page service that allows you to view the status of a server from the page at any time.\n axel a multi-threaded download tool that can replace curl and wget when downloading files.\naxel -n 20 http://centos.ustc.edu.cn/centos/7/isos/x86_64/CentOS-7-x86_64-Minimal-1511.iso   sz/rz interactive file transfer, very good for transferring files under multiple jumpers, no need to transfer at one level.\n cloc code statistics tool, can count the number of empty lines of code, comment lines, programming language.\n tmux terminal reuse tool, instead of screen, nohup.\n script/scriptreplay Terminal session recording.\n# recording script -t 2\u0026gt;time.txt session.typescript # your commands # end of recording exit # Playback scriptreplay -t time.txt session.typescript  multitail Often you have more than one log file to monitor, what should you do? It takes up too much space to open multiple tabs in the terminal software, try this tool.\nSource\n","date":"13 Sep, 2021","image":"images/blog/linux.png","permalink":"https://codelink.ai/blog/devops/must-have-linux-tools/","tags":["tools"],"title":"These Linux tools are must-haves! Which one have you used?"},{"categories":["web development"],"contents":" Programmers need to deal with lots of diagrams in their daily life: flowcharts, architecture diagrams, interaction diagrams, functional module diagrams, UML class diagrams, deployment diagrams, various visual diagrams, and so on.\nThrough the form of diagrams, one can better display the system, more clearly express their ideas, easy to understand; also can exercise their own drawing skills, really a multi-benefit thing.\nToday I will share my common diagramming software and a little tips.\n Commonly used diagrams I usually draw more flowcharts, interaction diagrams and architecture diagrams, and I usually use Draw.io, a free online web drawing tool, to get it done.\nThe main reasons why I chose this drawing tool are as follows.\n1. ease of use No need to log in, directly access the web page, you can directly use a large number of templates to create new projects.\nSelect a template Then enter the editing page, select the graphics you need on the left, drag them to the drawing area for editing, and then modify the style on the right.\nDraw.io online drawing You can directly search for the needed graphics, such as the server, and of course, you can also directly paste local or network images.\n2. Beautiful style Draw.io provides several default themes and preset graphic styles, such as my favorite hand-drawn style.\nOf course, you can also customize the graphics with a high degree of flexibility, and if you are familiar with interface development, you can even edit the values of the graphics properties directly.\nProperty editing 3. Rich Export You can export the drawing to image, vector, PDF, HTML document, etc. with one click.\nWhat I like most is that it can generate online web pages directly and share them with others for quick browsing, and it also provides a small toolbar for zooming, screenshotting, printing and quick editing.\nOnline Browsing In addition, you can export your drawings as embedded web pages! This allows us to seamlessly integrate all kinds of drawings directly into the web pages we develop.\nExport to embedded format 4. Easy storage and import You can save your drawing as a local file at any time, or store it in an online space like GitHub; when you need to edit it again, you can import it from the same place.\nFor those of you who are used to using GitHub to store and share your code, this is very useful and means you can collaborate on drawings with other students.\nIn addition to Draw.io, I also like EdrawMax, a local mapping software that is also very powerful.\n ER Diagram Backend development students may come across ER diagrams, which are often used in database design to represent the properties and relationships of data.\nI usually don\u0026rsquo;t draw this stuff manually, I just use database management software (such as Navicat, JetBrains DataGrip, etc.) to generate it based on the existing library tables when needed.\nAutomatic generation of ER diagrams\n UML Class Diagram UML class diagrams are used to represent the relationship between classes and help to quickly understand the design structure of the whole system.\nLike ER diagrams, I don\u0026rsquo;t draw this stuff myself, it\u0026rsquo;s exhausting. Generally, I use an IDE (such as JetBrains IDEA) to automatically generate UML class diagrams based on the code, as shown in the figure.\nAutomatic generation of UML class diagrams\nThis is not better than drawing your own?\n Visual diagram Charts can show data and trends more visually, and play a pivotal role in PPT presentations.\nCommon charts include bar charts, column charts, pie charts, line charts, and so on.\nAlthough Excel and PPT can draw charts, they are relatively ugly, so I recommend Flourish, a website that generates visual charts online.\nIt has a rich set of built-in templates for chart types.\nAfter selecting a chart type, you can configure the data to be displayed and the chart style.\nI like the dynamic charts and URL sharing feature that allows you to quickly create real-time charts with dynamically changing values.\nOnce you\u0026rsquo;re done, you can share the web address with a single click for others to view or embed in your own web page.\nExport chart pages\n Mind Map The most common mind mapping software I use is XMind, which is easy to use and rich in topics.\nXMind\nI usually don\u0026rsquo;t write mind maps directly in XMind, but I write a Markdown document first, and then import the document directly into XMind to automatically generate mind maps based on headings, lists, and other elements.\nImporting Markdown\nOtherwise, it would be really tiring to edit them one by one.\n Postscript Drawing diagrams is something that can be imitated, more reading and more drawing, practice makes perfect.\nWhen you need to draw a diagram, if you can\u0026rsquo;t draw, no ideas, just go online and search for similar diagrams drawn by others, and just draw a tiger from a cat.\nSource\n","date":"31 Aug, 2021","image":"images/blog/uml.jpeg","permalink":"https://codelink.ai/blog/web-development/programmers-commonly-used-drawing-software-and-tips/","tags":["tools","drawing"],"title":"Programmers commonly used drawing software and tips"},{"categories":["python"],"contents":"In the previous article, we briefly introduced Flask, a Python web development framework, and learned how to write a Hello World, but we are still a long way from developing a real project with Flask.\nThe role of templates  What is a template used for? Templates are used to generate the corresponding Html text more efficiently, without templates, you can write it by hand, such as the hello world example before, write a paragraph of html code:\n\u0026lt;h1\u0026gt;Hello world!\u0026lt;/h1\u0026gt; It\u0026rsquo;s okay for simple exercises, but for large scale, highly dynamic projects, it\u0026rsquo;s a bit of a stretch to write this way, i.e., not conducive to project and productization. So what are the benefits of templates.\n Can make presentation logic and business logic Presentation logic, i.e. UI, is what is used to show and operate to users, and business logic is business rules, such as what conditions can be registered and what permissions can be tested. The template encapsulates the presentation logic and the business logic is written in the view function. Makes the project easier to maintain Due to the separation of presentation logic and business logic, they can be maintained by different developers and there will be no code conflicts Makes the project more secure In doing interactive development, there is a principle: Never trust user input because malicious users may inject through input (we can talk about injection separately when we have a chance later), while templates will be anti-injection to some extent, for example, if a user enters a bit of html code as input, by default the template will replace it with web-safe characters to prevent malicious injection. Can improve development efficiency With a template, it is equivalent to a function that displays logic, so it can be reused, and can be used in different view functions, and in different projects   Think about. The presentation logic and business logic mentioned above, why not just say frontend and backend? If you have answers and ideas, feel free to leave a comment to discuss.\n Jinja2 Template Engine Jinja2 is the default template engine supported by the Flask framework, not the only and not the best (varies from person to person, no best) template engine, different Web frameworks, such as Django, Nodejs, etc. have their own template engine, and even some programmers implement their own template engine (I have done so), but the general idea is the same, is to replace data or This technology is not new, in the previous printing templates, such as crystal reports, there is nothing more than the markup and syntax is different, so we need to learn from each other.\nIntroduce rendering functions Like other functions, to use the template engine, first introduce the\nfrom flask import render_template  Note: To place the template file in the templates folder under the root of the project (the path shown in print(__file__))\n For example, the template file hello.html would be.\n{% raw %} \u0026lt;h1\u0026gt;Hello {{ name }} \u0026lt;/h1\u0026gt; {% endraw %} The view function can be written as :\n@app.route(\u0026#39;/user/\u0026lt;name\u0026gt;\u0026#39;) def index(name): return render_template(\u0026#39;hello.html\u0026#39;, name=name) The render_template function provided by Flask integrates the Jinja2 template engine into the application. The first argument to the render_template function is the filename of the template, and the subsequent arguments are key-value pairs that represent the corresponding real values of the variables in the template.\nVariables A template file is just a normal text file, and then the part to be replaced is marked with double curly brackets ( {{ }} ) in which the variable name to be replaced is indicated, and this variable supports basic data types, as well as lists, dictionaries, objects, and tuples. As in the template template.html:\n{% raw %} \u0026lt;p\u0026gt; A value form a string: {{ name }}. \u0026lt;/p\u0026gt; \u0026lt;p\u0026gt; A value form a int: {{ myindex }}. \u0026lt;/p\u0026gt; \u0026lt;p\u0026gt; A value form a list: {{ myindex }}. \u0026lt;p\u0026gt; A value form a list: {{ mylist[3]] }}. \u0026lt;/p\u0026gt; \u0026lt;p\u0026gt; A value form a list: {{ mylist[3] }}. \u0026lt;p\u0026gt; A value form a list, with a variable index: {{ mylist[myindex] }}. \u0026lt;/p\u0026gt; \u0026lt;p \u0026lt;p\u0026gt; A value form a dictionary: {{ mydict[\u0026#39;key\u0026#39;] }}. \u0026lt;/p\u0026gt; \u0026lt;p\u0026gt; A value form a dictionary: {{ mydict[\u0026#39;key\u0026#39;] }}. \u0026lt;p\u0026gt; A value form a tuple: {{ mytuple }}. \u0026lt;/p\u0026gt; \u0026lt;p\u0026gt; A value form a tuple: {{ mytuple }}. \u0026lt;p\u0026gt; A value form a tuple by index: {{ mytuple[myindex] }}. \u0026lt;/p\u0026gt; {% endraw %} View function code:\n@app.route(\u0026#39;/template/\u0026#39;) def template(): name = \u0026#39;Jinja2 template engine\u0026#39; myindex = 1 mylist = [1,2,3,4] mydict = { key: \u0026#39;age\u0026#39;, value: \u0026#39;25\u0026#39; } mytuple = (1,2,3,4) return render_template(\u0026#39;template.html\u0026#39;, name=name, myindex=myindex, mylist=mylist, mydict=mydict, mytuple=mytuple) Filter There are times when you need to do something special with the values you want to replace in the template, such as capitalizing the first letter, removing spaces before and after, etc. One option is to use a filter.\nDescription In the Jinjia2 template engine, filters are similar to pipes in Linux commands, such as capitalizing the first letter of a string variable\n{% raw %} \u0026lt;h1\u0026gt;{{ name | capitalize}}\u0026lt;/h1\u0026gt; {% endraw %} Filters can be spliced, as can the linux pipeline command, e.g., to capitalize values and remove whitespace before and after.\n{% raw %} \u0026lt;h1\u0026gt;{{ name | upper | trim }}\u0026lt;/h1\u0026gt; {% endraw %} As in the code above, the filter and the variable are connected by the pipe symbol |, which is equivalent to further processing of the variable value.\nSome common filters\n   filter description     safe rendering is not escaped   capitalize initial capitalization   lower all letters lowercase   upper all letters uppercase   title Capitalize the first letter of each word in the value   trim removes the first blank character   striptags removes all HTML tags from the value when rendering    Note: safe filter, by default, Jinja2 will escape all variables for security reasons, for example, if a variable has the value \u0026lt;h1\u0026gt;Hello\u0026lt;/h1\u0026gt;, Jinja2 will render it as \u0026amp;lt;h1\u0026amp;gt;Hello\u0026amp;lt;/\u0026amp;gt;, the browser will display the original value, but will not interpret it. If you want the browser to interpret it, you can use the safe filter For example, the template file html.html is:\n{% raw %} \u0026lt;h1\u0026gt;{{ html | safe }}\u0026lt;/h1\u0026gt; {% endraw %} The view function is.\n@app.route(\u0026#39;/html\u0026#39;) def html(): return render_template(\u0026#39;html.html\u0026#39;, html=\u0026#39;\u0026lt;b\u0026gt;bob\u0026lt;/b\u0026gt;\u0026#39;)  **Note: **Never use safe filters on untrustworthy values, such as the text the user enters on a form.\n There are also some useful filters\n default, which provides a default value when the variable is undefined, or false, False and null (none) if you want to treat them as undefined, you need to provide a second argument of true  {% raw %} \u0026lt;! -- Provides default value filter --\u0026gt; \u0026lt;h1\u0026gt;Hello {{ name | default(\u0026#39;world\u0026#39;) }}! \u0026lt;/h1\u0026gt; \u0026lt;! -- Treat false, False and null (none) as undefined default filters --\u0026gt; \u0026lt;h1\u0026gt;Hello {{ name | default(\u0026#39;world\u0026#39;, true)! }}\u0026lt;/h1\u0026gt; {% endraw %} When the variable name is undefined, the top and bottom will be the same, and when the value is none, the top will show Hello none!, and the bottom will show Hello world!.\n List filters min, max, get the minimum or maximum value in the list  Custom Filters Although there are many filters, there are always times when they do not meet the needs, such as indenting the first line of text, converting the amount to Chinese uppercase, and so on. A filter is essentially a function, so first, define a filter function, and second, register it in Jinjia2\u0026rsquo;s filter.\n# Define a filter function def mylen(arg):# implement a function that can find the length return len(arg) def interval(test_str, start, end): # Return the contents of the specified interval in the string return test_str[int(start):int(end)] # Register filters env = app.jinja_env env.filters[\u0026#39;mylen\u0026#39;] = mylen env.filters[\u0026#39;interval\u0026#39;] = interval # View functions @app.route(\u0026#39;/myfilter\u0026#39;) def myfilter(): return render_template(\u0026#39;myfilter.html\u0026#39;, phone=\u0026#39;13300000000\u0026#39;) Template files\n{% raw %} \u0026lt;h1\u0026gt;The phone number is: {{ phone }}, length is: {{ phone | mylen }}, carrier number: {{ phone | interval(0,3) }}\u0026lt;/h1\u0026gt; {% endraw %}  The filter registration code can also be written in the initialization code __init__.py\n Control structure Many times, a smarter template rendering is needed, i.e., the ability to program the rendering, such as a style for boys and the same style for girls, and control structure instructions need to be specified with command markers, and some simple control structures are described below\nConditions i.e. if-else control structure in the template\n{% raw %} {% if gender==\u0026#39;male\u0026#39; %} Hello, Mr {{ name }} {% else %} Hello, Ms {{ name }} {% endif %} {% endraw %} View Functions\n@app.route(\u0026#39;/hello2/\u0026lt;name\u0026gt;/\u0026lt;gender\u0026gt;\u0026#39;) def hello2(name, gender): return render_template(\u0026#39;hello2.html\u0026#39;, name=name, gender=gender) In the control structure, the code syntax is the same as python\nloop Loops are useful for rendering lists, and the loop is marked with for. For example, the contents of the prize list are displayed in ul\n{% raw %} \u0026lt;ul\u0026gt; {% for name in names %} \u0026lt;li\u0026gt;{{ name }} \u0026lt;/li\u0026gt; {% endfor %} \u0026lt;/ul\u0026gt; {% endraw %} For example, given a list of students, display it as an unordered list ul\nMacros - functions in templates A macro can be defined in the template, which is equivalent to defining a function that can be reused to make the logic clearer. First, define a macro :\nmymacro.html\n{% raw %} {% macro render_name(name) %} \u0026lt;li\u0026gt;{{ name }}\u0026lt;/li\u0026gt; {% endmacro %} {% endraw %} Then use a macro, for example, in the example of the loop structure, where the name is displayed, to call the macro\n{% raw %} \u0026lt;ul\u0026gt; {% for name in names %} {{ render_name(name) }} {% endfor %} \u0026lt;/ul\u0026gt; {% endraw %} Calling a macro is the same as calling a function, but the code is written inside {{}} double curly brackets. Generally we keep the macros in a separate file for reuse, and refer to them where we need to use them\n{% raw %} {% import \u0026#39;mymarco.html\u0026#39; as macros %} \u0026lt;ul\u0026gt; {% for name in names %} {{ macros.render_name(name) }} {% endfor%} \u0026lt;/ul\u0026gt; {% endraw %} As mentioned above, introducing macro definition files with improt, specifying aliases via as, is the same as introducing modules with python. Specifying an alias is a good programming convention to visualize a complex thing while acting like a namespace and effectively avoiding conflicts.\ninclude Alternatively, multiple template fragments can be written to a single file and then included ( include ) in all templates to improve development efficiency:\n{% raw %} {% include \u0026#39;common.html\u0026#39; %} {% endraw %} include into the file, which is equivalent to copying the contents of the file to the include location, so you need to consider carefully before using it\nTemplate inheritance If you think include is too dumb and inflexible, Jinja2 template engine has a more advanced feature - inheritance. Similar to the inheritance of classes in Python code, let\u0026rsquo;s take a look. First define a base class, base.html:\n{% raw %} \u0026lt;html\u0026gt; \u0026lt;head\u0026gt; {% block head %} \u0026lt;title\u0026gt;{% block title %}{% endblock%} - My Application\u0026lt;/title\u0026gt; {% endblock %} \u0026lt;/head\u0026gt; {% endblock %} \u0026lt;body\u0026gt; {% block body %} {% block body %} \u0026lt;h3\u0026gt;This is the content of the base class\u0026lt;/h3\u0026gt; {% endblock %} \u0026lt;/body\u0026gt; \u0026lt;/html\u0026gt; {% endraw %} Each blcok tag needs to specify a special name, such as head, title, etc., so that the subclass can be refactored with a specific name. In addition, the block tag needs to have an end tag endblock, similar to the curly brackets in C-like language, but of course the block tag can be nested. Next, define a subclass template hello3.html.\n{% raw %} {% extends \u0026#34;base.html\u0026#34; %} {% block title %}Index{% endblock %} {% block head %} {{ super() }} \u0026lt;style\u0026gt;\u0026lt;/style\u0026gt; {% endblock %} {% block body %} {{ super() }} \u0026lt;h3\u0026gt;This is the content of the subclass Hello world!\u0026lt;/h\u0026gt; {% endblock %} {% endraw %} Use the extends tag to specify the base class to be inherited, and then use the block tag to set the subclass to replace the contents of the base class, as long as the name specified by block is the same. Alternatively, if you don\u0026rsquo;t need to replace the base class completely, you can call the super method in the subclass block to get the contents of the base class under this name, which allows more flexibility.\nSummary  Today, we introduce the basic usage and features of Jinja2 template engine, and hope that through the different features, you can understand the basic usage of templates, so that you can use it faster and learn more in-depth content. In addition, I want to illustrate the basic features of templates through the Jinja2 template engine, so that you can learn other good templates by analogy and by example, and also want to show that templates can be used not only in web development, but also in automated coding, testing and many other areas.\nFinally, at the beginning of this chapter, I left a question for you: why not refer to presentation logic and business logic as frontend and backend? If you have an answer, feel free to share it in the comments.\n Reference\n https://jinja.palletsprojects.com/en/2.10.x/api/#the-context https://www.cnblogs.com/mauricewei/p/10056379.html https://github.com/JustDoPython/python-100-day/tree/master/day-021  ","date":"19 Jul, 2021","image":"images/blog/python.png","permalink":"https://codelink.ai/blog/python/python101-21-web-development-jinja2-template-engine/","tags":["learning","python101"],"title":"Python101: 21. Web Development Jinja2 Template Engine"},{"categories":["python"],"contents":" 1. Introduction to the concept  decorator, also known as a \u0026ldquo;decorator function\u0026rdquo;, is a function that returns a value that is also a function, and can be called a \u0026ldquo;function of functions\u0026rdquo;. Its purpose is to implement additional functionality without modifying existing functions. The most basic idea comes from a design pattern called the \u0026ldquo;decoration pattern\u0026rdquo;.\nIn Python, decorators are pure \u0026ldquo;syntactic sugar\u0026rdquo;, and it\u0026rsquo;s okay not to use them, but they can greatly simplify code and make it more readable - for those who know what\u0026rsquo;s going on, of course.\nYou\u0026rsquo;ve probably seen the @ symbol in Python code after studying it for a while. Yes, this symbol is the marker for using decorators, and it\u0026rsquo;s proper Python syntax.\n Syntactic sugar: A syntax added to a computer language that has no effect on the functionality of the language, but is more convenient for the programmer to use. Generally speaking the use of syntactic sugar can increase the readability of a program, thus reducing the chance of errors in the program code.\n 2. operation mechanism  In short, the following two pieces of code are semantically equivalent (although there is a slight difference in the exact process).\ndef IAmDecorator(foo): \u0026#39;\u0026#39;\u0026#39;I\u0026#39;m a decorator function\u0026#39;\u0026#39;\u0026#39; pass @IAmDecorator def tobeDecorated(): \u0026#39;\u0026#39;\u0026#39;I am the decorated function\u0026#39;\u0026#39;\u0026#39; pass With.\ndef IAmDecorator(foo): \u0026#39;\u0026#39;\u0026#39;I\u0026#39;m a decorator function\u0026#39;\u0026#39;\u0026#39; pass def tobeDecorated() : \u0026#39;\u0026#39;\u0026#39;I am the decorated function\u0026#39;\u0026#39;\u0026#39; pass tobeDecorated = IAmDecorator(tobeDecorated) As you can see, using the @ syntax of the decorator is equivalent to passing the concrete defined function as an argument to the decorator function, which in turn goes through a series of operations to return a new function, and then assigning this new function to the original function name.\nWhat we end up with is a new function that is same name as the function we explicitly defined in the code and heterogeneous.\nThe decorated function is like a shell for the original function. As shown in the figure, the resulting combined function is the new function generated by applying the decorator.\nIt is important to note that there is a slight difference in the execution of the above two pieces of code. In the second code, the function name tobeDecorated actually points to the original function first, and only after the decorator modification, it points to the new function; but in the first code, there is no such intermediate process, and the new function named tobeDecorated is obtained directly.\nIn addition, the decorated function **has and can have only one argument, the original function to be decorated.\n3. Usage  In Python, there are two types of decorators, \u0026ldquo;function decorators\u0026rdquo; and \u0026ldquo;class decorators\u0026rdquo;, with \u0026ldquo;function decorators\u0026rdquo; being the most common and \u0026ldquo;class decorators\u0026rdquo; being the least used. \u0026ldquo;class decorators\u0026rdquo; are rarely used.\n3.1 Function decorators 3.1.1 General structure The definition of a decorative function can be roughly summarized in the template shown below, i.e.\n   Illustration     Decorating func   Internal func   Return statement    Since the return value of the decorated function is also required to be a function, in order to expand the function on top of the original function and make the expanded function return as a function, it is necessary to define an internal function in the definition of the decorated function and further manipulate it in this internal function. The final return object should be this internal function object, and only then can a function with new functions be returned correctly.\nThe decorator function is like a \u0026ldquo;wrapper\u0026rdquo; that fits the original function inside the decorator function, thus extending the original function by adding functions to it, and the decorator function returns the new whole. At the same time, the original function itself will not be affected. This is also the meaning of the word \u0026ldquo;decorate\u0026rdquo;.\nWould it be okay if we didn\u0026rsquo;t define \u0026ldquo;internal functions\u0026rdquo; in this place?\nThe answer is \u0026ldquo;no\u0026rdquo;.\n3.1.2 Explanation of the structure Let\u0026rsquo;s take a look at the following code.\ndef IAmFakeDecorator(fun): print(\u0026#34;I\u0026#39;m a fake decorator\u0026#34;) return fun @IAmFakeDecorator def func(): print(\u0026#34;I am the original function\u0026#34;) # I\u0026#39;m a fake decorator It\u0026rsquo;s a bit strange how the operation of the decorator extension is executed just as soon as it is defined.\nTo call the new function again.\nfunc() # I am the original function Eeyo strange, where is the extended function ah?\nDon\u0026rsquo;t be anxious, let\u0026rsquo;s analyze the above code. In the definition of the decorated function, we do not define a separate internal function, the extended operation is directly placed in the function body of the decorated function, and the return value is the original function passed in.\nWhen defining a new function, the following two pieces of code are again equivalent.\n@IAmFakeDecorator def func(): print(\u0026#34;I am the original function\u0026#34;) # I\u0026#39;m a fake decorator and\ndef func(): print(\u0026#34;I am the original function\u0026#34;) func = IAmFakeDecorator(func) # I am a false decorator Looking at the latter code, we can see that the decorator is only called once while defining the new function, after that the object referenced by the new function name is the return value of the decorator, which has nothing to do with the decorator.\nIn other words, the operations in the function body of the decorator itself are **executed once when and only when **the function is defined, and when the function is called later with the new function name, the operations performed will only be those of the internal function. So by the time the new function is actually called, the result obtained is no different from the original function.\nSimply returning the incoming original function without defining an inner function is certainly possible and meets the requirements of a decorator; however, it does not get the result we expect, and the functionality extended to the original function is not reusable and is only one-off. Therefore such behavior does not make any sense.\nThe function defined inside the decorated function for extending the function can be named as you like, but the general convention is to name it wrapper, which means wrapping.\nThe correct definition of a decorator should look like the following.\ndef IAmDecorator(fun): def wrapper(*args, **kw): print(\u0026#34;I\u0026#39;m really a decorator\u0026#34;) return fun(*args, **kw) return wrapper 3.1.3 Problems with parameter settings The purpose of setting internal function parameters to (*args, **kw) is to be able to receive arbitrary arguments. The content of how to receive arbitrary arguments is described in the previous function parameters section has been described.\nThe reason why we want wrapper to be able to take arbitrary arguments is that when we define the decorator we don\u0026rsquo;t know what function it will be used to decorate and what the arguments of the specific function will be; defining it as \u0026ldquo;can take arbitrary arguments\u0026rdquo; can greatly enhance the adaptability of the code.\nAlso, note the location of the given parameters.\nTo clarify the concept: once the function parameters are given elsewhere than in the function header, the meaning of the expression is no longer \u0026ldquo;a function object\u0026rdquo;, but \u0026ldquo;one function call\u0026rdquo;.\nTherefore, the purpose of our decorator is to return a function object, the object of the return statement must be the name of the function without arguments; in the internal function, we are required to call the original function, so we need to bring function parameters, otherwise, if the return value of the internal function is still a function object, you still need to give another set of parameters to be able to call the original function. show code.\ndef IAmDecorator(fun): def wrapper(*args, **kw): print(\u0026#34;I\u0026#39;m really a decorator\u0026#34;) return fun return wrapper @IAmDecorator def func(h): print(\u0026#34;I am the original function\u0026#34;) func() # I\u0026#39;m really a decorator # \u0026lt;function func at 0x000001FF32E66950\u0026gt; The original function is not called successfully, but only the function object corresponding to the original function is obtained. The correct call can occur only if the next set of parameters is given further (to demonstrate the effect of the parameters, an additional parameter h is added to the definition of the function func).\nfunc()(h=1) # I\u0026#39;m really a decorator # I am the original function As long as you understand the difference between with and without arguments, and know exactly what you want, you won\u0026rsquo;t make mistakes with arguments. And there is no need to stick to the above rules at all, maybe you want an uncalled function object?\nWith this in mind, nested decorators and nested inner functions are no longer a problem.\n3.1.4 Function Properties It should also be noted that after the decorator modification, the properties of the original function are also changed.\ndef func(): print(\u0026#34;I am the original function\u0026#34;) func.__name__ # \u0026#39;func\u0026#39; Normally, to define a function, its function name and the corresponding variable should be the same, so that unnecessary problems can be avoided when some need to identify and index the function object by the variable name. But things do not go so smoothly.\n@IAmDecorator def func(): print(\u0026#34;I am the original function\u0026#34;) func.__name__ # \u0026#39;wrapper\u0026#39; The variable name is still the same, the original function is still the same, but the function name becomes the name of the internal function in the decorator.\nHere we can use the wraps tool in Python\u0026rsquo;s built-in module functools for the purpose of \u0026ldquo;extending functions with decorators while preserving the properties of the original function\u0026rdquo;. Here functools.wraps is itself a decorator. The result is as follows.\nimport functools # Define decorators that preserve the properties of the original function def IAmDecorator(fun): @functools.wraps(fun) def wrapper(*args, **kw): print(\u0026#34;I\u0026#39;m really a decorator\u0026#34;) return fun(*args, **kw) return wrapper @IAmDecorator def func(): print(\u0026#34;I am the original function\u0026#34;) func.__name__ # \u0026#39;func\u0026#39; Great job!\n3.2 Class decorators The concept of a class decorator is similar to that of a function decorator, and the syntax is similar in its use.\n@ClassDecorator class Foo: pass Equivalent to\nclass Foo: pass Foo = ClassDecorator(Foo) When defining a class decorator, ensure that both __init__ and __call__ methods exist in the class. The __init__ method is used to receive the original function or class, and the __call__ method is used to implement the decoration logic.\nIn short, the __init__ method is responsible for binding the incoming function or class to the class instance when it is initialized, while the __call__ method is pretty much the same as a normal function decorator, even the construction is not much different, so you can think of the __call__ method as a function decorator, so I won\u0026rsquo;t go into it again.\n3.3 The case of multiple decorators Multiple decorators can be nested, and the specifics can be understood as a composite function combined from the bottom up; or it can also be understood as the value of the next decorator is the argument of the previous decorator.\nAs an example, the following two pieces of code are equivalent.\n@f1(arg) @f2 def func(): pass and\ndef func(): pass func = f1(arg)(f2(func)) This situation is also easy to grasp once you understand the previous sections.\n4. Summary  This article introduces the decorator feature in Python, explaining in detail how it works and how to use it, which can greatly help learners master the knowledge of decorators, reduce the resistance to reading Python code, and write more pythonic code.\n Reference\n[1] Python3 Glossary - Decorators\n[2] Python3 Documentation - Compound Statements - Function Definitions\n[3] Python3 Documentation - Compound Statements - Class Definitions\n[4] Syntactic Sugar\n[5] Xuefeng Liao\u0026rsquo;s official website-Python-Tutorial-Functional-Programming-Decorator\n[6] Python-100-days-day022\n","date":"18 Jul, 2021","image":"images/blog/python.png","permalink":"https://codelink.ai/blog/python/python101-20-decorators/","tags":["learning","python101"],"title":"Python101: 20. Decorators"},{"categories":["python"],"contents":" 1 Concept introduction  In previous tutorials, we\u0026rsquo;ve touched on some typical for statements, such as.\nlist_example = [0, 1, 2, 3, 4] for i in list_example: print(i) # 0 # 1 # 2 # 3 # 4 By simply using the for and in keywords, we can easily implement the tedious traversal operations in C. By contrast, to achieve the same functionality in C, one would write (assuming the existence of the integer array list_example)\nint i; for(i = 0; i \u0026lt; list_length; i++) printf(\u0026#34;%d\\n\u0026#34;, list_example[i]); It is clear that Python is much more intuitive, elegant, and concise when it comes to iterating over elements; this is because Python uses the concept of \u0026ldquo;iterators\u0026rdquo; just right when implementing the for statement.\nIterators are found everywhere in Python and have a uniform standard. By using iterators, Python can access each element of the list list_example one by one.\nLet\u0026rsquo;s further discuss the relevant mechanisms below.\n2 Definition and Principle  2.1 Definition of an iterator  An iterator is an interface that can be traversed in a container, encapsulating the internal logic for the user.\n The above is a broad definition of \u0026ldquo;iterator\u0026rdquo; as far as we can find.\nSpecifically in Python, iterators are one of the built-in standard classes, and are on the same level as the \u0026ldquo;sequences\u0026rdquo; we\u0026rsquo;ve studied before.\nFor the iterator object itself, it needs to have __iter__() and [__next__()](https://docs.python.org/3/ library/stdtypes.html#iterator.next), which are collectively called the \u0026ldquo;iterator protocol\u0026rdquo;. That is, if both methods are present, the Python interpreter considers the object to be an iterator; conversely, if only one or neither method is present, the interpreter considers the object not to be an iterator.\nThe above assertion can be verified by the following code (which requires the built-in function isinstance() to determine whether an object is an instance of a class; this usage is inspired by [Xuefeng Liao\u0026rsquo;s official website]]).\nfrom collections import Iterable, Iterator, Container class bothIterAndNext: def __iter__(self): pass def __next__(self): pass isinstance(bothIterAndNext(), Iterable) # objects that both methods have are iterable # True isinstance(bothIterAndNext(), Iterator) # The object that both methods have is an iterator # True class onlyNext: def __next__(self): pass isinstance(onlyNext(), Iterable) # Only method __next__() is not iterable # False isinstance(onlyNext(), Iterator) # Only method __next__() is not an iterator # False class onlyIter: def __iter__(self): pass isinstance(onlyIter(), Iterable) # Only method __iter__() is iterable # True isinstance(onlyIter(), Iterator) # Only method __iter__() is not an iterator # False As you can see from lines 8-11, for Python, the only criterion for determining whether an object is an iterator is \u0026ldquo;whether it has both __iter__() and __next__() methods\u0026rdquo;.\nAnd the above inference can also be verified from lines 17-20: the method __next__() is neither iterable nor an iterator.\nSomething interesting happens on lines 26 and 27 of the code: the output of the code shows that only the object of method __iter__() is actually iterable! (explained later)\n2.2 The essence of iterators The iterator object essentially represents a stream of data, and by repeatedly calling its method __next__() or passing it as an argument to the next() function, each item in the stream is returned one by one in order; until there are no more items in the stream, which throws a StopIteration exception and terminates the iteration.\nThere are two built-in functions in Python: iter() and next(), which are used to \u0026ldquo;convert argument objects to iterator objects\u0026rdquo; and \u0026ldquo;take the next item from the iterator\u0026rdquo; respectively.\nIn fact, all objects with method __iter__() are treated as \u0026ldquo;iterable\u0026rdquo;. Because the operation performed by method __iter__() actually returns an iterator corresponding to that object, that is, the real meaning of \u0026ldquo;iterable\u0026rdquo; is actually \u0026ldquo;iterator that can be converted to \u0026ldquo;. The built-in function iter() also calls the __iter__() method of the object itself to convert a particular object to an iterator.\nAccordingly, the built-in function next() actually calls the object\u0026rsquo;s own method __next__(), which performs the operation of taking the next item from the object\u0026rsquo;s corresponding data stream.\nSo calling the object\u0026rsquo;s __iter__() and __next__() methods directly is equivalent to passing the object as an argument to the built-in functions iter() and next().\nOne thing to note is that calling the __iter__() method on an iterator will result in the iterator itself, and all the state associated with that iterator will be preserved, including the current iteration state of that iterator. See the following code.\nli = [1, 2, 3] li_iterator = iter(li) isinstance(li, Iterator) # False isinstance(li_iterator, Iterator) # True Obviously, the list li itself is not an iterator, and passing it into the built-in function iter() yields the corresponding iterator li_iterator for the list li. We call the next() function to iterate over it.\nnext(li_iterator) # 1 next(li_iterator) # 2 Everything is as expected. Let\u0026rsquo;s again pass itself as an argument to the built-in function iter().\nli_iterator = iter(li_iterator) next(li_iterator) # 3 Here\u0026rsquo;s where it gets a little different than we\u0026rsquo;d like. When using such a statement, the goal is usually to get a new iterator, not the same object as the original iterator.\nFurther, we can see that the object obtained by calling the iter() function on the iterator not only has the same state as the original iterator, but they actually point to the same object.\nid(li_iterator) # 2195581916440 li_iterator = iter(li_iterator) id(li_iterator) # 2195581916440 li_iterator2 = iter(li_iterator) id(li_iterator2) # 2195581916440 That is, in the case of an object that is itself an iterator, Python does not perform additional operations on the corresponding iterator when it is generated, but returns the iterator itself as the result.\n3 Implement an iterator class   The code to build the classes in this section is from [Python3 Documentation - Classes - 9.8 Iterators]\n With the above discussion in mind, we can implement a simple iterator ourselves. Just make sure that this simple iterator has a behavior that matches the definition of the iterator.\nIn human terms: to define a data type that has a __iter__() method and that method returns an object with a __next__() method, or itself when the class already has a __next__() method. The sample code is as follows.\nclass Reverse: \u0026#34;\u0026#34;\u0026#34;Iterator that iterates over sequence objects in reverse.\u0026#34;\u0026#34;\u0026#34; def __init__(self, data): self.data = data self.index = len(data) def __iter__(self): return self def __next__(self): if self.index == 0: raise StopIteration self.index = self.index - 1 return self.data[self.index] Validate.\nrev = Reverse(\u0026#39;justdopython.com\u0026#39;) next(rev) # \u0026#39;m\u0026#39; next(rev) # \u0026#39;o\u0026#39; next(rev) # \u0026#39;c\u0026#39; next(rev) # \u0026#39;.\u0026#39; (o„Çú‚ñΩ„Çú)o‚òÜ\nMission accomplished!\n4 for statements and iterators  Going back to the for loop example we used as an introduction at the beginning of the article, Python actually silently calls the built-in function iter() when executing the for statement, and passes in the container object from the for statement as an argument; and the function iter() returns an iterator object. statement; and the function iter() returns an iterator object.\nThus, the for statement is called after converting the container object to an iterator object, and the __next__() method is called, accessing each object in the original container one by one until all elements have been traversed, throwing a StopIteration exception, and terminating the for loop.\n5 Summary   An iterator must first be iterable; that is, an iterator must be iterable, but an iterable is not necessarily an iterator An iterable object means that it can be converted to an iterator Iterators need to have both methods __iter__() and __next__() Calling the iter() function on an iterator gives you the iterator itself for loops actually use iterators and generally use the exception StopIteration as a loop termination condition  This article explores iterators in Python, gaining an in-depth understanding of their properties and behavior, and learning two important methods, __iter__() and __next__(). Also figured out the internal mechanism of Python\u0026rsquo;s implementation of for loops.\n Reference\n[1] Python3 documentation - built-in types\n[2] Liao Xuefeng\u0026rsquo;s official website\n[3] Python3 Documentation - Classes - 9.8 Iterators\n[4] Python-100-days-day019\n","date":"17 Jul, 2021","image":"images/blog/python.png","permalink":"https://codelink.ai/blog/python/python101-19-iterators/","tags":["learning","python101"],"title":"Python101: 19. Iterators"},{"categories":["python"],"contents":" Functional programming is now gradually accepted by the majority of the development community, more and more developers have begun to use this elegant development model, and we use functional programming is the main need to be clear:\n what are higher-order functions (Higher-order Functions)? what are the higher-order functions in Python? How to use them?   Higher order function concepts  In functional programming, we can freely use functions as if they were variables. A function that receives another function as an argument is called a higher-order function.\nAs an example.\ndef high_func(f, arr): return [f(x) for x in arr] In the above example, high_func is a high-order function. The first argument f is a function, the second argument arr is an array, and the returned value is a list of all the values in the array after being computed by the f function. For example.\nfrom math import factorial def high_func(f, arr): return [f(x) for x in arr] def square(n): return n ** 2 # Use python\u0026#39;s own math functions print(high_func(factorial, list(range(10)))) # print out: [1, 1, 2, 6, 24, 120, 720, 5040, 40320, 362880] # Use custom functions print(high_func(square, list(range(10)))) # print out: [0, 1, 4, 9, 16, 25, 36, 49, 64, 81] Python Commonly Used Higher Order Functions  As with java, scala and other languages, many of our commonly used higher-order functions are basically the same. In development we often use the most basic higher-order functions are actually a few, and we can also be based on these functions to carry out appropriate extensions, then the following begins to introduce several commonly used higher-order functions.\nmap  Make an iterator that computes the function using arguments from each of the iterables. Stops when the shortest iterable is exhausted.\n Mapping the specified sequence according to the provided function, and return the mapped sequence, defined as\nmap(func, *iterables) --\u0026gt; map object  function # the operation to be performed for each element of the sequence, can be an anonymous function *iterables # One or more sequences  As in the previous example of the high_func function, the map function is a higher-order version of the high_func function that can be passed in a function and multiple sequences.\nfrom math import factorial def square(n): return n ** 2 # Use python\u0026#39;s own math functions facMap = map(factorial, list(range(10))) print(list(facMap)) # print out: [1, 1, 2, 6, 24, 120, 720, 5040, 40320, 362880] # Use custom function squareMap = map(square, list(range(10))) print(list(squareMap)) # print out: [0, 1, 4, 9, 16, 25, 36, 49, 64, 81] You can see that the output is the same, except that unlike python2.X, which returns the map class, `python3. while the former returns a list directly.\nWe use anonymous functions, which can also be passed in multiple sequences, as follows\n# Use anonymous functions lamMap = map(lambda x: x * 2, list(range(10))) print(list(lamMap)) # print out: [0, 2, 4, 6, 8, 10, 12, 14, 16, 18] # Pass in multiple sequences mutiMap = map(lambda x, y: x+y, list(range(10)), list(range(11, 15))) print(list(mutiMap)) # print out: [11, 13, 15, 17] reduce  Apply a function of two arguments cumulatively to the items of a sequence, from left to right, so as to reduce the sequence to a single value.\n Roughly speaking, the reduce function is passed a function with two arguments, which is then used to iterate through the sequence from left to right and generate the result, as defined below.\nreduce(function, sequence[, initial]) -\u0026gt; value  function # function, the operation to be performed on each element of the sequence, can be an anonymous function sequence # The sequence of operations to be performed initial # optional, initial argument  Finally, the result of the function is returned, with the same initial argument type\nAs a brief example.\n# Note that the reduce() function has now been put into the functools package. from functools import reduce result = reduce(lambda x, y: x + y, [1, 2, 3, 4, 5]) print(result) # print out 15 We can see that the sequence [1, 2, 3, 4, 5] is cumulated by the anonymous function.\nSet initial value.\n# Set initial parameters. s = reduce(lambda x, y: x + y, [\u0026#39;1\u0026#39;, \u0026#39;2\u0026#39;, \u0026#39;3\u0026#39;, \u0026#39;4\u0026#39;, \u0026#39;5\u0026#39;], \u0026#34;number = \u0026#34;) print(s) # print out: number = 12345 Note that the sequence data type needs to be the same as the initial parameters.\nfilter  Return an iterator yielding those items of iterable for which function(item) is true. If function is None, return the items that are true.\n The filter() function is used to filter the sequence for unqualified values, returning an iterator that generates those iterable items whose function (item) is true. If the function is None, then it returns the items that are true. The definition is as follows.\nfilter(function or None, iterable) --\u0026gt; filter object  function or None # The function that the filter operation performs iterable # The sequence to be filtered  As an example.\ndef boy(n): if n % 2 == 0: return True return False # Custom functions filterList = filter(boy, list(range(20))) print(list(filterList)) # print out: [0, 2, 4, 6, 8, 10, 12, 14, 16, 18] # Custom functions filterList2 = filter(lambda n: n % 2 == 0, list(range(20))) print(list(filterList2)) # print out: [0, 2, 4, 6, 8, 10, 12, 14, 16, 18] Above we can see that the data in the list that are not divisible by 2 are excluded.\nsorted  Return a new list containing all items from the iterable in ascending order.\n  A custom key function can be supplied to customize the sort order, and the reverse flag can be set to request the result in descending order.\n The sorted function returns a new list after sorting the sequence in ascending order by default, but you can also customize the key function to sort, and set the reverse parameter to determine whether it is in ascending or descending order, if reverse = True then it is in descending order. The function definition is as follows.\ndef sorted(iterable: Iterable[_T], *, key: Optional[Callable[[_T], Any]] = ... , reverse: bool = ...) -\u0026gt; List[_T]: ...  iterable # Sequence key # Sorting function that can be used to compute. reverse # Sorting rule, reverse = True descending, reverse = False ascending (default).  As a simple example.\nlist01 = [5, -1, 3, 6, -7, 8, -11, 2] list02 = [\u0026#39;apple\u0026#39;, \u0026#39;pig\u0026#39;, \u0026#39;monkey\u0026#39;, \u0026#39;money\u0026#39;] print(sorted(list01)) # print out: [-11, -7, -1, 2, 3, 5, 6, 8] print(sorted(list01, key=abs)) # print out: [-1, 2, 3, 5, 6, -7, 8, -11] # Default ascending order print(sorted(list02)) # print out: [\u0026#39;apple\u0026#39;, \u0026#39;money\u0026#39;, \u0026#39;monkey\u0026#39;, \u0026#39;pig\u0026#39;] # Descending order print(sorted(list02, reverse=True)) # print out: [\u0026#39;pig\u0026#39;, \u0026#39;monkey\u0026#39;, \u0026#39;money\u0026#39;, \u0026#39;apple\u0026#39;] # Anonymous function sorting print(sorted(list02, key=lambda x: len(x), reverse=True)) # print out: [\u0026#39;monkey\u0026#39;, \u0026#39;apple\u0026#39;, \u0026#39;money\u0026#39;, \u0026#39;pig\u0026#39;] Summary  Above we have briefly introduced the use of several common higher-order functions, of course, there are many higher-order functions we can study, such as the zip function, etc. I hope the introduction of this section will be helpful to you.\n Reference\nhttps://github.com/JustDoPython/python-100-day/tree/master/day-018\n","date":"16 Jul, 2021","image":"images/blog/python.png","permalink":"https://codelink.ai/blog/python/python101-18-higher-order-functions/","tags":["learning","python101"],"title":"Python101: 18. Higher Order Functions"},{"categories":["python"],"contents":" Defining a function is very simple, but how to define a function, what parameters are needed, and how to call it is a question we need to think about.\nLike most languages (e.g., Java), Python provides a variety of parameters (e.g., default value parameters, keyword parameters, formal parameters, etc.). The code defined using these parameters allows us to adapt to different open scenarios and also simplifies our code development work.\n Default Value Parameters  After we create a function that defines one or more of its parameters with default values, we can call this function with fewer parameters than allowed, as an example (Note: the following code uses python version 3.7).\ndef def_param_fun(prompt, retries=4, reminder=\u0026#39;Please try again!\u0026#39;): while True: ok = input(prompt) if ok in (\u0026#39;y\u0026#39;, \u0026#39;ye\u0026#39;, \u0026#39;yes\u0026#39;): return True if ok in (\u0026#39;n\u0026#39;, \u0026#39;no\u0026#39;, \u0026#39;nop\u0026#39;, \u0026#39;nope\u0026#39;): return False retries = retries - 1 if retries \u0026lt; 0: raise ValueError(\u0026#39;invalid user response\u0026#39;) print(reminder) # We can call it as follows def_param_fun(\u0026#39;Do you really want to quit?\u0026#39;) def_param_fun(\u0026#39;Do you really want to quit?\u0026#39;, 2) def_param_fun(\u0026#39;Do you really want to quit?\u0026#39;, 2, \u0026#39;Please, yes or no!\u0026#39;) As shown above, we can use one or more parameters to call this function, we actually produce, in many cases will give the function parameters default value of the situation, so the reasonable use of such parameters can simplify our workload a lot.\n Important: When using default value arguments, we may call functions with results that do not match our expectations if our default value is a mutable object. As follows.\n def f(a, l=[]): l.append(a) return l # At this point, call the function print(f(1)) print(f(2)) print(f(3)) # Return value # [1] # [1, 2] # [1, 2, 3]  This is due to the fact that the default value is only executed once when the function is initialized, so where the default value is a mutable object (lists, dictionaries, and most class instances), we can do the following.\n def f(a, l=None): if l is None: l = [] l.append(a) return l # Call the function again print(f(1)) print(f(2)) print(f(3)) # Return value # [1] # [2] # [3] Variable parameters Variable parameters means that the parameters defined in the function can be one or more variable, where *args means that a list or tuple can be passed in, and *args means that a dict can be passed in.\ndef variable_fun(kind, *arguments, **keywords): print(\u0026#34;friend : \u0026#34;, kind, \u0026#34;;\u0026#34;) print(\u0026#34;-\u0026#34; * 40) for arg in arguments: print(arg) print(\u0026#34;-\u0026#34; * 40) for kw in keywords: print(kw, \u0026#34;:\u0026#34;, keywords[kw]) # function calls variable_fun(\u0026#34;xiaoming\u0026#34;, \u0026#34;hello xiaoming\u0026#34;, \u0026#34;nice to meet you!\u0026#34;, mother=\u0026#34;xiaoma\u0026#34;, father=\u0026#34;xiaoba\u0026#34;, son=\u0026#34;see you\u0026#34;) # Output results # first arg: xiaoming ... # ---------------------------------------- # hello # nice to meet you! # ---------------------------------------- # mother : xiaoma # father : xiaoba # son : see you We can also make a call using the following to get the same result as above.\nlist01 = [\u0026#34;hello xiaoming\u0026#34;, \u0026#34;nice to meet you!\u0026#34;] dict01 = {\u0026#39;mother\u0026#39;: \u0026#39;xiaoma\u0026#39;, \u0026#39;father\u0026#39;: \u0026#39;xiaoba\u0026#39;, \u0026#39;son\u0026#39;: \u0026#39;see you\u0026#39;} variable_fun(\u0026#34;xiaoming\u0026#34;, *list01, **dict01) The above is actually a python unpacking operation, similar to java.\nKeyword Parameters  Keyword arguments allow you to call a function with zero or any number of arguments with parameter names, which gives us the flexibility to make parameter calls. As an example.\n# Borrowed example from official website def key_fun(voltage, state=\u0026#39;a stiff\u0026#39;, action=\u0026#39;voom\u0026#39;, type=\u0026#39;Norwegian Blue\u0026#39;): print(\u0026#34;-- This key_fun wouldn\u0026#39;t\u0026#34;, action, end=\u0026#39; \u0026#39;) print(\u0026#34;if you put\u0026#34;, voltage, \u0026#34;volts through it.\u0026#34;) print(\u0026#34;-- Lovely plumage, the\u0026#34;, type) print(\u0026#34;-- It\u0026#39;s\u0026#34;, state, \u0026#34;!\u0026#34;) # function calls key_fun(1000) # 1 positional argument key_fun(voltage=1000) # 1 keyword argument key_fun(voltage=1000000, action=\u0026#39;VOOOOOM\u0026#39;) # 2 keyword arguments key_fun(action=\u0026#39;VOOOOOM\u0026#39;, voltage=1000000) # 2 keyword arguments key_fun(\u0026#39;a million\u0026#39;, \u0026#39;bereft of life\u0026#39;, \u0026#39;jump\u0026#39;) # 3 positional arguments key_fun(\u0026#39;a thousand\u0026#39;, state=\u0026#39;pushing up the daisies\u0026#39;) # 1 positional, 1 keyword  Note that you cannot pass the value repeatedly, otherwise the following error will be reported:\n # TypeError: key_fun() got multiple values for argument \u0026#39;voltage\u0026#39; key_fun(100, voltage=1000) # error Summary  This section briefly introduced the use of function arguments in python. The settings can be used in conjunction with each other, but don\u0026rsquo;t over-design them, otherwise they will cause the readability of the function to become poor.\n Reference\nhttps://github.com/JustDoPython/python-100-day/tree/master/day-017\n","date":"15 Jul, 2021","image":"images/blog/python.png","permalink":"https://codelink.ai/blog/python/python101-17-functions-and-arguments/","tags":["learning","python101"],"title":"Python101: 17. Functions and Arguments"},{"categories":["python"],"contents":" As a Python beginner, when you first learn Python programming, you will often see error messages, which are the errors and exceptions we\u0026rsquo;ll talk about next.\nWhen we execute program statements, we often see error messages reported on the command line output, such as\n\u0026gt;\u0026gt;\u0026gt; while True print(\u0026#39;Hello world\u0026#39;) File \u0026#34;\u0026lt;stdin\u0026gt;\u0026#34;, line 1, in ? while True print(\u0026#39;Hello world\u0026#39;) ^ SyntaxError: invalid syntax Such error messages prevent the program from running properly, which are the errors and exceptions we will introduce.\nError  By errors we mean Python syntax errors, e.g.\n\u0026gt;\u0026gt;\u0026gt; if 1=1: print(\u0026#39;always\u0026#39;) File \u0026#34;\u0026lt;stdin\u0026gt;\u0026#34;, line 1 if 1=1: print(\u0026#39;always\u0026#39;) ^ SyntaxError: invalid syntax In the above example, \u0026lsquo;'==\u0026rsquo; should be used instead of \u0026lsquo;=\u0026rsquo; when determining equality. When executed, the syntax parser checks that there is an error, the program statement terminates execution and the error is pointed out with an up arrow.\nSyntax errors are easily solved by checking the syntax and correcting it according to the location of the error prompted on the command line.\nExceptions  In Python, even if your code has no syntax errors, there is no guarantee that the program will finish running the way you want it to, because there will be errors during program execution as well. Errors detected during program execution are called exceptions, e.g.\n\u0026gt;\u0026gt; \u0026#39;1\u0026#39; + 2 Traceback (most recent call last): File \u0026#34;\u0026lt;stdin\u0026gt;\u0026#34;, line 1, in ? TypeError: Can\u0026#39;t convert \u0026#39;int\u0026#39; object to str implicitly Most of the exceptions are not handled by the program and are displayed as error messages, as shown in the example above, where the prompt tells us that the int type cannot be added to the str type.\nThe error message will tell us the context in which the exception occurred and display the specific information in the form of a call stack. The last line of the message will start with the name of the error type, in the above example, the error type is \u0026lsquo;TypeError\u0026rsquo;, indicating a type exception.\nWhat is an exception An exception is an event that occurs during program execution and thus affects the normal execution of the program. When Python encounters a program that it cannot handle, it raises an exception. In Python, an exception is an object that represents an error that we need to catch and handle when an exception occurs in a Python script, otherwise the program will terminate execution.\nHandling exceptions Python provides try/except statements to catch and handle exceptions. try statements are used to detect errors in blocks of statements, except statements are used to catch exceptions in try statements and handle them, and additional else statements can be executed when there are no exceptions in try statements.\nSyntax The following is the simplest try\u0026hellip; .except\u0026hellip; .else as an example.\ntry: statement(s) # Block of statements to test except exception. deal_exception_code # If an \u0026#39;exception\u0026#39; is raised in the try section except exception2, e: deal_exception2_code # If the \u0026#39;exception2\u0026#39; exception was raised else: no_exception_happend_code # if no exception was raised The execution logic of the try statement is as follows.\n First, the try clause (the (multi-line) statement between the try and except keywords) is executed. If no exceptions occur, the except clause is skipped and the execution of the try statement is completed. If an exception occurs during the execution of the try clause, the rest of the clause is skipped. Then, if the type of the exception matches the exception following the except keyword, the except clause is executed, and the code continues after the try statement. If an exception occurs that does not match the exception specified in the except clause, it is passed to the outer try statement; if no handler is found, it is an unhandled exception and execution stops with an error message. If the try statement executes without an exception, the statement after the else statement (if there is an else) is executed, and then control flows through the entire try statement.  base class An exception is compatible with the class in the except clause if the class in which it occurs and the class in the except clause are the same class or its base class (but the converse is not true - the except clause listing the derived class is compatible with the base class).\nExample class BException(Exception): #Inherit Exception base class pass class CException(BException): #Inherit BException base class pass class DException(CException): #Inherit CException base class pass for cls in [BException, CException, DException]: try: raise cls() #Throw exception except DException: print(\u0026#34;D\u0026#34;) except CException: print(\u0026#34;C\u0026#34;) except BException: print(\u0026#34;B\u0026#34;) # output # B # C # D Note that if the except clause is reversed (putting except BException first), it will print B, B, B \u0026mdash; since the DException class inherits from the CException class and the CException class inherits from the BException class, putting except BException first will match the three exceptions, and the following excepts will not be executed.\nwithout exception type except Python can end all excepts with an except clause, which can omit the exception name to be used as a wildcard. It can catch all exceptions that are not caught by any of the preceding excepts (if any).\ntry: statement(s) # Block of statements to test except exception. deal_exception_code # If an \u0026#39;exception\u0026#39; is raised in the try section except : deal_all_other_exception2_code # deal with all other exceptions else: no_exception_happend_code # if no exceptions are raised Example try: raise BException() #Throw exception except DException: print(\u0026#34;D\u0026#34;) except: print(\u0026#34;Handling all other exceptions\u0026#34;) #Handle all other exceptions # Output # Handle all other exceptions except statement catches multiple exception types A try statement may have multiple except clauses to specify handlers for different exceptions, and at most one handler will be executed. Handlers handle only the exceptions that occur in the corresponding try clause, not the exceptions in other handlers within the same try statement. An except clause can name multiple exceptions as a tuple with parentheses.\ntry: statement(s) # Block of statements to test except exception. deal_exception_code # If an \u0026#39;exception\u0026#39; is raised in the try section except (Exception1[, Exception2[,... . ExceptionN]]]) : deal_all_other_exception2_code # Handle multiple exceptions else: no_exception_happend_code # if no exceptions occur Example try: raise BException() #Throw exception except (BException, DException): print(\u0026#34;D\u0026#34;) except: print(\u0026#34;Handling all other exceptions\u0026#34;) #Handle all other exceptions else: print(\u0026#34;No exceptions occurred\u0026#34;) # No exceptions occurred #output # D try - finally statements The finally statement is used to execute the final code regardless of whether an exception occurs.\ntry: # \u0026lt;statement\u0026gt; finally: # \u0026lt;statement\u0026gt; # always executed when exiting try Example try: raise BException() #Throw exception except (BException, DException): print(\u0026#34;D\u0026#34;) except: print(\u0026#34;Handling all other exceptions\u0026#34;) #Handle all other exceptions else: print(\u0026#34;No exceptions occurred\u0026#34;) # No exceptions occurred finally: print(\u0026#34;You can\u0026#39;t get around me, you have to execute\u0026#34;) #Code that must be executed #output # D # You can\u0026#39;t get around me, you have to execute Note the difference between finally and else. Finally is executed regardless of exceptions, while else is executed only if there are no exceptions. That is, if there is no exception, then both finally and else will be executed.\nParameters of the #### exception\nThe except clause can specify a variable after the exception name. This variable is bound to an exception instance, whose arguments are a tuple, usually containing the error string, error number, and error location, stored in .args. For convenience, the exception instance defines str(), so that the arguments can be printed directly without referring to .args.\ntry: # Normal operation ...... except ExceptionType as inst: # You can output the value of inst here ..... Example try: x = 1 / 0 # Divide by 0 except ZeroDivisionError as err: # Specify the variable err for the exception print(\u0026#34;Exception\u0026#34;) print(err.args) # Print the tuple of arguments for the exception print(err) # print the arguments, since __str__() is defined #output # Exception # (\u0026#39;division by zero\u0026#39;,) # division by zero Trigger exception Python provides the raise statement to manually raise an exception.\nSyntax raise [Exception [, args [, traceback]]] Parameter Description Exception: type of the exception, e.g. ZeroDivisionError args: the value of the exception argument, optional, default value \u0026quot;None\u0026quot; traceback: optional, used to set whether to trace the exception object The exception parameter value can be a string, class or object\nExample def diyException(level): if level \u0026gt; 0: raise Exception(\u0026#34;raise exception\u0026#34;, level) #Throw an exception proactively and with arguments print(\u0026#39;I am not going to execute\u0026#39;) #This line of code will not be executed try: diyException(2) #Execute the exception method except Exception as err: #Catch the exception print(err) #Print the exception parameter # Output # (\u0026#39;raise exception\u0026#39;, 2) In order to catch an exception, the \u0026ldquo;except\u0026rdquo; statement must throw a class object or string with the same exception. To catch the exception thrown by the above code, the except statement should look like this.\n#Define the function def diyException(level): if level \u0026gt; 0: raise Exception(\u0026#34;error level\u0026#34;, level) #Throw an active exception with arguments print(\u0026#39;I am not going to execute\u0026#39;) #This line of code will not be executed try: diyException(2) #Execute the exception method except \u0026#39;error level\u0026#39; as err: #Catch the exception print(err) #Print the exception parameter #output # Traceback (most recent call last): # File \u0026#34;/Users/cxhuan/Documents/python_workspace/stock/test.py\u0026#34;, line 51, in \u0026lt;module\u0026gt; # diyException(2) #Execute the exception method # File \u0026#34;/Users/cxhuan/Documents/python_workspace/stock/test.py\u0026#34;, line 47, in diyException # raise Exception(\u0026#34;error level\u0026#34;, level) #Throw an active exception with parameters # Exception: (\u0026#39;error level\u0026#39;, 2) Of course, we can also catch exceptions via traceback: the\nimport traceback #Define the function def diyException(level): if level \u0026gt; 0: raise Exception(\u0026#34;error level\u0026#34;, level) #Throw an active exception with arguments print(\u0026#39;I am not going to execute\u0026#39;) #This line of code will not be executed try: diyException(2) #Execute the exception method except Exception: #Catch the exception traceback.print_exc() #output # Traceback (most recent call last): # File \u0026#34;/Users/cxhuan/Documents/python_workspace/stock/test.py\u0026#34;, line 51, in \u0026lt;module\u0026gt; # diyException(2) #Execute the exception method # File \u0026#34;/Users/cxhuan/Documents/python_workspace/stock/test.py\u0026#34;, line 47, in diyException # raise Exception(\u0026#34;error level\u0026#34;, level) #Throw an active exception with parameters # Exception: (\u0026#39;error level\u0026#39;, 2) User-defined exceptions In addition to using Python\u0026rsquo;s built-in exceptions, we can create our own exception types. Creating your own exceptions is as simple as creating a class and inheriting from the Exception class or its subclasses.\nThe following code creates an exception DiyError inherits from Python\u0026rsquo;s built-in RuntimeError and is used to output more information when an exception is raised.\n#CustomException class DiyError(RuntimeError): def __init__(self, arg): self.args = arg try: raise DiyError(\u0026#34;my diy exception\u0026#34;) # Trigger exception except DiyError as e: print(e) Once defined, we can use the DiyError exception after the except statement, where the variable e is used to create an instance of the DiyError class. We can also trigger this exception manually with a raise statement.\nPredefined cleanup actions Some objects define a standard cleanup behavior that is executed once it is no longer needed, regardless of whether the system has successfully used it.\nfor line in open(\u0026#34;myfile.txt\u0026#34;): print(line, end=\u0026#34;\u0026#34;) The above example tries to open a file and then print out the contents. But there is a problem: when the execution is finished, the program does not close the file stream and the file stays open.\nThe keyword with statement ensures that an object such as a file will be cleaned up correctly after it is used.\nwith open(\u0026#34;myfile.txt\u0026#34;) as f: for line in f: print(line, end=\u0026#34;\u0026#34;) After the above code is executed, the file f will always be closed even if something goes wrong during processing. The principle here is the use of the finally mechanism, so if you are interested, you can go deeper into it.\nSummary  This section gives an introduction to the use of Python errors and exceptions. Mastering error and exception handling can greatly improve the robustness of your program and provide a guarantee that your program will continue to run completely.\n Reference\nhttps://github.com/JustDoPython/python-100-day/tree/master/day-011\n","date":"14 Jul, 2021","image":"images/blog/python.png","permalink":"https://codelink.ai/blog/python/python101-16-errors-and-exceptions/","tags":["learning","python101"],"title":"Python101: 16. Errors and Exceptions"},{"categories":["devops"],"contents":" The ls command is the most commonly used command in Linux. ls is short for list, and by default ls is used to print out a list of the current directory.\nIf ls specifies another directory, then it will display a list of files and folders in the specified directory. The ls command allows you to view not only the files contained in a Linux folder but also the file permissions (including directory, folder, and file permissions), directory information, and more.\nThe ls command is used a lot in daily Linux operations!\n1. Command format  ls [option] [directory name] 2. Command function  List all the subdirectories and files in the target directory. 3.\n3. Common parameters  -a, -all List all the files in the directory, including the implicit files starting with . including the implied files starting with . -A is the same as -a, but does not list \u0026quot;.\u0026quot; (for the current directory) and \u0026quot;...\u0026quot; (for the parent of the current directory). -c with -lt: sort by ctime and show ctime (when the file status was last changed) with -l: show ctime but sort by name otherwise: sort by ctime -C List items from top to bottom in each column -WHEN can be 'never', 'always' or 'auto ' either -d, -directory Displays directories as files, instead of showing the files under them. -D, -dired produces results suitable for use in Emacs' dired mode -f does not sort the output files, the -aU option takes effect and the -lst option fails -g is similar to -l, but does not list the owner -G, -no-group does not list any information about groups -h, -human-readable lists the file size in an easy to understand format (e.g. 1K 234M 2G) -si is similar to -h, but the file size is taken to the power of 1000 instead of 1024 -H, -dereference-command-line Use the real destination indicated by the symbolic link in the command line -indicator-style=style Specify that each item name is followed by the indicator \u0026lt;style\u0026gt;: none (default), classify (-F), file-type (-p) -i, -inode prints out the inode number of each file -I, -ignore=style Do not print out any items that match the shell's universal character \u0026lt;style -k i.e. -block-size=1K, indicates the size of the file in k bytes. -l lists the file permissions, owner, file size, and other information in detail, in addition to the file name. -L, -dereference When displaying information about files with symbolic links, display information about the object indicated by the symbolic link instead of the symbolic link itself -m All items are separated by commas and fill the entire line width -o is similar to -l, showing detailed information about the file except for group information. -r, -reverse in reverse order -R, -recursive lists all subdirectory levels simultaneously -s, -size list all files in block size -S Sort by file size -sort=WORD The following WORDs are available and the corresponding options they represent. extension -X status -c none -U time -t size -S atime -u time -t access -u version -v use -u -t Sort by file modification time -u with -lt: Show access time and sort by access time with -l: show access time but sort by name otherwise: sort by access time -U no sorting; list items in the original order of the file system -v: Sort by version -w, -width=COLS specify your own screen width instead of using the current value -x list items line by line instead of column by column -X Sort by extension -1 List only one file per line -help Display this help message and leave -version Displays version information and leaves 4. Common examples Example 1 List the details of all files and directories under the /home/codelinkai folder\nCommand: ls -l -R /home/codelinkai\nWhen you use ls command, you should pay attention to the format of the command: after the command prompt, the keyword of the command is first, followed by the command parameters, and there is a short horizontal line \u0026ldquo;-\u0026rdquo; before the command parameters, all the command parameters have specific functions, and you can choose one or more parameters according to your needs.\nIn the above command ls -l -R /home/codelinkai, ls is the command keyword, -l -R is the parameter, and /home/codelinkai is the parameter. \u0026ldquo;/home/codelinkai\u0026rdquo; is the object of the command. In this command, two parameters are used, \u0026ldquo;l\u0026rdquo; and \u0026ldquo;R\u0026rdquo;, but you can also use them together as follows.\nCommand: ls -lR /home/codelinkai\nThe result of this form is exactly the same as the above command. In addition, if the operation object of the command is located in the current directory, you can operate on the operation object directly; if it is not in the current directory then you need to give the full path of the operation object, for example, in the above example, my current folder is the codelinkai folder, and I want to operate on the codelinkai file under the home folder, I can directly type ls -lR codelinkai, or I can use ls -lR /home/codelinkai.\nExample 2 To list the details of all the directories starting with \u0026ldquo;t\u0026rdquo; in the current directory, you can use the following command.\nCommand: ls -l t*\nYou can view the information of all the files in the current directory whose file name starts with \u0026ldquo;t\u0026rdquo;. In fact, in the command format, the contents inside the square brackets can be omitted. For the command ls, if you omit the command parameters and operation objects and type \u0026ldquo;ls\u0026rdquo; directly, the contents of the current working directory will be listed.\nExample 3 List only the subdirectories under the file\nCommand: ls -F /opt/soft |grep /$\nList the subdirectories under the /opt/soft file\nOutput:\n[root@localhost opt]# ls -F /opt/soft |grep /$ jdk1.6.0_16/ subversion-1.6.1/ tomcat6.0.32/ Command: ls -l /opt/soft | grep \u0026quot;^d\u0026quot;\nList the details of the subdirectories under the /opt/soft file\nOutput:\n[root@localhost opt]# ls -l /opt/soft | grep \u0026#34;^d\u0026#34; drwxr-xr-x 10 root root 4096 09-17 18:17 jdk1.6.0_16 drwxr-xr-x 16 1016 1016 4096 10-11 03:25 subversion-1.6.1 drwxr-xr-x 9 root root 4096 2011-11-01 tomcat6.0.32 Example 4 List all the files in the current working directory whose names start with s. The newer the file, the later it is, you can use the following command.\nCommand: ls -ltr s**\nOutput:\n[root@localhost opt]# ls -ltr s* src: Total 0 script: Total 0 soft: Total 350644 drwxr-xr-x 9 root root 4096 2011-11-01 tomcat6.0.32 -rwxr-xr-x 1 root root 81871260 09-17 18:15 jdk-6u16-linux-x64.bin drwxr-xr-x 10 root root 4096 09-17 18:17 jdk1.6.0_16 -rw-r--r-- 1 root root 205831281 09-17 18:33 apache-tomcat-6.0.32.tar.gz -rw-r--r-- 1 root root 5457684 09-21 00:23 tomcat6.0.32.tar.gz -rw-r--r-- 1 root root 4726179 10-10 11:08 subversion-deps-1.6.1.tar.gz -rw-r--r-- 1 root root 7501026 10-10 11:08 subversion-1.6.1.tar.gz drwxr-xr-x 16 1016 1016 4096 10-11 03:25 subversion-1.6.1 Example 5 List all files and directories in the current working directory; add \u0026ldquo;/\u0026rdquo; after the directory name, and add \u0026ldquo;\u0026quot; after the executable file name\nCommand: ls -AF\nOutput:\n[root@localhost opt]# ls -AF log/ script/ soft/ src/ svndata/ web/ Example 6 Calculate the number of files and directories in the current directory\nCommand:\nls -l * |grep \u0026#34;^-\u0026#34;|wc -l -number of files ls -l * |grep \u0026#34;^d\u0026#34;|wc -l -number of directories Example 7 List the absolute path of a file in ls\nCommand: ls | sed \u0026quot;s:^:pwd/:\u0026quot;\nOutput:\n[root@localhost opt]# ls | sed \u0026#34;s:^:`pwd`/:\u0026#34;  /opt/log /opt/script /opt/soft /opt/src /opt/svndata /opt/web Example 8 List the absolute paths of all files (including hidden files) in the current directory, without recursion for directories\nCommand: find $PWD -maxdepth 1 | xargs ls -ld\nOutput:\n[root@localhost opt]# find $PWD -maxdepth 1 | xargs `ls` -ld drwxr-xr-x 8 root root 4096 10-11 03:43 /opt drwxr-xr-x 2 root root 4096 2012-03-08 /opt/log drwxr-xr-x 2 root root 4096 2012-03-08 /opt/script drwxr-xr-x 5 root root 4096 10-11 03:21 /opt/soft drwxr-xr-x 2 root root 4096 2012-03-08 /opt/src drwxr-xr-x 4 root root 4096 10-11 05:22 /opt/svndata drwxr-xr-x 4 root root 4096 10-09 00:45 /opt/web Example 9 Recursively list the absolute paths of all files (including hidden files) in the current directory\nCommand: find $PWD | xargs ls -ld\nExample 10 Specify the file time output format**\nCommand: ls -tl -time-style=full-iso\nOutput:\n[root@localhost soft]# `ls` -tl --time-style=full-iso  Total 350644 drwxr-xr-x 16 1016 1016 4096 2012-10-11 03:25:58.000000000 +0800 subversion-1.6.1 Command: ls -ctl -time-style=long-iso\nOutput:\n[root@localhost soft]# `ls` -ctl --time-style=long-iso Total 350644 drwxr-xr-x 16 1016 1016 4096 2012-10-11 03:25 subversion-1.6.1 Extensions  Open /etc/bashrc and add the following line:\nalias ls=\u0026#34;ls --color\u0026#34; The next time you start bash, you will be able to display a colored list of directories like in Slackware, where the colors mean the following:\n  blue\u0026ndash;\u0026gt;directories\n  green\u0026ndash;\u0026gt;executable files\n  red\u0026ndash;\u0026gt;compressed files\n  light blue\u0026ndash;\u0026gt;linked files\n  gray\u0026ndash;\u0026gt;other files\n  Source\n","date":"13 Jul, 2021","image":"images/blog/linux.png","permalink":"https://codelink.ai/blog/devops/a-linux-command-a-day-1-ls-command/","tags":["learning","linux"],"title":"A Linux command a day (1): ls command"},{"categories":["python"],"contents":" Python also contains a set type. A set is an unordered set of non-repeating elements. Its basic usage includes member detection and elimination of duplicate elements. Set objects also support mathematical operations like unions, intersections, difference sets, symmetric differences, and so on.\nThe set structure is as follows:\n set1 = {\u0026#39;hello\u0026#39;, \u0026#39;hello\u0026#39;, \u0026#39;word\u0026#39;, \u0026#39;word\u0026#39;} set1 # The output is automatically de-duplicated # {\u0026#39;hello\u0026#39;, \u0026#39;word\u0026#39; 1. Collection creation  Collections can be created using curly braces { } or set() functions.\nCreate format:\nparame = {value01, value02, ...} or set(value) Note: You must use set() instead of { } to create an empty set, because { } is used to create an empty dictionary.\n# Create an empty set empty_set = set() type(empty_set) # \u0026lt;class \u0026#39;set\u0026#39;\u0026gt; # Create an empty dictionary empty_dict = {} type(empty_dict) # \u0026lt;class \u0026#39;dict\u0026#39;\u0026gt; 2. Basic operations of the collection  2.1 Adding elements Syntax format:\ns.add(x) Adds an element x to the set s. If the element already exists, then no operation is performed.\ns = set((\u0026#39;hello\u0026#39;,\u0026#39;world\u0026#39;)) print(s) # Add an element to the set s s.add(\u0026#39;!\u0026#39;) print(\u0026#39;The set after adding elements is: %s\u0026#39; % s) # The output is. # The set after adding the elements is: {\u0026#39;world\u0026#39;, \u0026#39;!\u0026#39; , \u0026#39;hello\u0026#39;} In addition to the add() method, which adds elements, there is a method that also adds elements, and the arguments can be lists, tuples, dictionaries, etc. The syntax format is as follows.\ns.update( x ) The parameter x can be one or more than one, with a comma separating the multiple parameters\n# 1) Add a list s.update([1,3],[2,4]) print(\u0026#39;The set after adding elements is: %s\u0026#39; % s) # 2) Add a tuple s.update((\u0026#39;h\u0026#39;, \u0026#39;j\u0026#39;)) print(\u0026#39;The set after adding elements is: %s\u0026#39; % s) 2.2 Removing elements The ** syntax format is as follows:**\ns.remove( x ) Remove the element x from the set s. If the element does not exist, an error will occur.\n# Remove element 2 from the set s.remove(2) print(\u0026#39;The set after removing element 2 is: %s\u0026#39; % s) # Exceptions are thrown if you remove an element that does not exist in the collection # Remove a collection that does not exist in the set s.remove(\u0026#39;hi\u0026#39;) print(\u0026#39;The set after removing elements is: %s\u0026#39; % s) # Exception messages # Traceback (most recent call last): # File \u0026#34;test.py\u0026#34;, line 20, in \u0026lt;module\u0026gt; # s.remove(\u0026#39;hi\u0026#39;) # KeyError: \u0026#39;hi\u0026#39; There is also a method to remove an element from a collection and no error occurs if the element does not exist. The format is shown below.\ns.discard( x ) thisset = set((\u0026#34;Google\u0026#34;, \u0026#34;Runoob\u0026#34;, \u0026#34;Taobao\u0026#34;)) thisset.discard(\u0026#34;Facebook\u0026#34;) # No error will occur if it doesn\u0026#39;t exist print(thisset) # {\u0026#39;Taobao\u0026#39;, \u0026#39;Google\u0026#39;, \u0026#39;Runoob\u0026#39;} We can also set up the random deletion of an element in a collection with the following syntax format.\ns.pop() # Randomly delete an element of the set print(s) s.pop() print(\u0026#39;The set after removing elements is: %s\u0026#39; % s) # Output results. # {1, 3, 4, \u0026#39;world\u0026#39;, \u0026#39;!\u0026#39; , \u0026#39;hello\u0026#39;, \u0026#39;h\u0026#39;, \u0026#39;j\u0026#39;} # The set after removing the elements is: {3, 4, \u0026#39;world\u0026#39;, \u0026#39;! , \u0026#39;hello\u0026#39;, \u0026#39;h\u0026#39;, \u0026#39;j\u0026#39;} Note: In interactive mode, pop is to delete the first element of the set (the first element of the sorted set).\n2.3 Calculating the number of elements of a set The syntax format is as follows:\nlen(s) Computes the number of elements of the set s.\nprint(\u0026#39;The length of the set s is: %s\u0026#39; % len(s)) # Output results The length of the set s is: 7 2.4 Emptying a collection The syntax format is as follows:\ns.clear() Empty the set s\ns.clear() print(\u0026#39;The result after the collection is cleared is: %s\u0026#39; % s) # Output results. # The result after the set is cleared is: set() 2.5 Determining whether an element exists The syntax format is as follows:\nx in s Determine if element x is in the set s. Returns True if it exists, and False if it does not.\n# Determine if the element exists s = {\u0026#39;hello\u0026#39;, \u0026#39;word\u0026#39;} # Determine if the element hello is in the set s print(hello\u0026#39; in s) # Output result: True 2.6 Set operations The operators between sets are \u0026lsquo;-\u0026rsquo;, \u0026lsquo;|\u0026rsquo;, \u0026lsquo;\u0026amp;', \u0026lsquo;^'; the following is an example of the operation between two sets The following is an example of an operation between two sets.\n \u0026lsquo;-': represents that the former contains elements not contained in the latter \u0026lsquo;|': represents the result of the result of the de-weighting of all the elements in the two sets together \u0026lsquo;\u0026amp;': the elements contained in both \u0026lsquo;^': elements that are not contained in both sets  a = set(\u0026#39;afqwbracadaagfgbrafg\u0026#39;) b = set(\u0026#39;rfgfgfalacazamddg\u0026#39;) a # {\u0026#39;r\u0026#39;, \u0026#39;q\u0026#39;, \u0026#39;d\u0026#39;, \u0026#39;b\u0026#39;, \u0026#39;w\u0026#39;, \u0026#39;g\u0026#39;, \u0026#39;f\u0026#39;, \u0026#39;c\u0026#39;, \u0026#39;a\u0026#39;} b # {\u0026#39;r\u0026#39;, \u0026#39;d\u0026#39;, \u0026#39;g\u0026#39;, \u0026#39;f\u0026#39;, \u0026#39;l\u0026#39;, \u0026#39;z\u0026#39;, \u0026#39;c\u0026#39;, \u0026#39;m\u0026#39;, \u0026#39;a\u0026#39;} # The elements contained in set a but not in set b a - b # {\u0026#39;b\u0026#39;, \u0026#39;w\u0026#39;, \u0026#39;q\u0026#39;} # All elements contained in set a or b a | b # {\u0026#39;d\u0026#39;, \u0026#39;g\u0026#39;, \u0026#39;l\u0026#39;, \u0026#39;c\u0026#39;, \u0026#39;r\u0026#39;, \u0026#39;q\u0026#39;, \u0026#39;b\u0026#39;, \u0026#39;w\u0026#39;, \u0026#39;f\u0026#39;, \u0026#39;z\u0026#39;, \u0026#39;m\u0026#39;, \u0026#39;a\u0026#39;} # The elements contained in both sets a and b a \u0026amp; b # {\u0026#39;r\u0026#39;, \u0026#39;d\u0026#39;, \u0026#39;g\u0026#39;, \u0026#39;f\u0026#39;, \u0026#39;c\u0026#39;, \u0026#39;a\u0026#39;} # Elements not contained in both a and b a ^ b # {\u0026#39;l\u0026#39;, \u0026#39;q\u0026#39;, \u0026#39;b\u0026#39;, \u0026#39;w\u0026#39;, \u0026#39;z\u0026#39;, \u0026#39;m\u0026#39;} 3. Set Derivative  Like lists, collections support derivatives\n# Determine if an element exists a = {x for x in \u0026#39;abracadabra\u0026#39; if x not in \u0026#39;abc\u0026#39;} a # {\u0026#39;r\u0026#39;, \u0026#39;d\u0026#39;} 4. Collection built-in methods  4.1 difference() The difference() method is used to return the difference set of a collection, i.e., the elements of the returned collection are contained in the first collection but not in the second collection (the method\u0026rsquo;s argument), returning a new collection. difference()` method syntax:\nset.difference(set) Example:\nThe difference between two sets returns a set whose elements are contained in set x, but not in set y.\n# Find the difference between two sets whose elements are in x but not in y x = {\u0026#34;apple\u0026#34;, \u0026#34;banana\u0026#34;, \u0026#34;cherry\u0026#34;} y = {\u0026#34;google\u0026#34;, \u0026#34;microsoft\u0026#34;, \u0026#34;apple\u0026#34;} z = x.difference(y) print(\u0026#39;The difference set of the two sets is: %s\u0026#39; % z) # The output is. # {\u0026#39;cherry\u0026#39;, \u0026#39;banana\u0026#39;} 4.2 difference_update()  The difference_update() method is used to remove elements that exist in both collections. The difference_update() method differs from the difference() method in that the difference() method returns a new collection with the same elements removed, while the difference_update() method removes elements directly from the original collection with no return value.  x = {\u0026#34;apple\u0026#34;, \u0026#34;banana\u0026#34;, \u0026#34;cherry\u0026#34;} y = {\u0026#34;google\u0026#34;, \u0026#34;microsoft\u0026#34;, \u0026#34;apple\u0026#34;} x.difference_update(y) print(x) # The result is. # {\u0026#39;banana\u0026#39;, \u0026#39;cherry\u0026#39;} x1 = {1,2,3,4} y1 = {1,2,3} x1.difference_update(y1) print(x1) # The result is. # {4} 4.3 intersection() The intersection() method is used to return the elements contained in two or more collections, i.e., the intersection, returning a new collection.\nintersection() method syntax:\nset.intersection(set1, set2 ... etc) # **Parameters:** # set1 -- required, the set to find the same elements # set2 -- optional, other sets to find the same elements, can be more than one, more than one use comma , separated by Example:\n# Returns the intersection of two or more sets x = {\u0026#34;apple\u0026#34;, \u0026#34;banana\u0026#34;, \u0026#34;cherry\u0026#34;} y = {\u0026#34;google\u0026#34;, \u0026#34;runoob\u0026#34;, \u0026#34;apple\u0026#34;} z = x.intersection(y) print(z) # Returns the intersection of three sets x = {\u0026#34;a\u0026#34;, \u0026#34;b\u0026#34;, \u0026#34;c\u0026#34;} y = {\u0026#34;c\u0026#34;, \u0026#34;d\u0026#34;, \u0026#34;e\u0026#34;} z = {\u0026#34;f\u0026#34;, \u0026#34;g\u0026#34;, \u0026#34;c\u0026#34;} result = x.intersection(y, z) print(\u0026#39;The difference set of the three sets is: %s\u0026#39; % result) # Output results. # {\u0026#39;apple\u0026#39;} # The difference set of the two sets is: {\u0026#39;c\u0026#39;} 4.4 intersection_update()  The intersection_update() method is used to get the elements of two or more collections that overlap, i.e. to compute the intersection. The intersection_update() method differs from the intersection() method in that the intersection() method returns a new set, while the intersection_update() method removes the non-overlapping elements from the original set.  intersection_update() method syntax:\nset.intersection_update(set1, set2 ... etc) # **Parameters** # set1 -- required, the set to find the same elements # set2 -- optional, other sets to find the same elements, multiple sets can be used, multiple sets are separated by a comma \u0026#39;,\u0026#39; Example:\n# Returns the intersection of a set with no return value x = {\u0026#34;apple\u0026#34;, \u0026#34;banana\u0026#34;, \u0026#34;cherry\u0026#34;} y = {\u0026#34;google\u0026#34;, \u0026#34;runoob\u0026#34;, \u0026#34;apple\u0026#34;} x.intersection_update(y) print(x) x = {\u0026#34;a\u0026#34;, \u0026#34;b\u0026#34;, \u0026#34;c\u0026#34;} y = {\u0026#34;c\u0026#34;, \u0026#34;d\u0026#34;, \u0026#34;e\u0026#34;} z = {\u0026#34;f\u0026#34;, \u0026#34;g\u0026#34;, \u0026#34;c\u0026#34;} x.intersection_update(y, z) print(x) # Output results. # {\u0026#39;apple\u0026#39;} # {\u0026#39;c\u0026#39;} 4.5 union() The union() method returns the union of two collections, i.e. all the elements of the collection are included, the duplicate elements will only appear once, and the return value returns a new collection\nSyntax:\n# Syntax of the `union()` method. set.union(set1, set2...) # Parameters # set1 -- required, the target set to be merged # set2 -- optional, other sets to be merged, can be multiple, multiple separated by commas. Examples:\n# Merge two sets where duplicate elements will only appear once. x = {\u0026#34;apple\u0026#34;, \u0026#34;banana\u0026#34;, \u0026#34;cherry\u0026#34;} y = {\u0026#34;google\u0026#34;, \u0026#34;runoob\u0026#34;, \u0026#34;apple\u0026#34;} z = x.union(y) print(z) # The output is. # {\u0026#39;cherry\u0026#39;, \u0026#39;runoob\u0026#39;, \u0026#39;google\u0026#39;, \u0026#39;banana\u0026#39;, \u0026#39;apple\u0026#39;} # Merge multiple collections. # Example 1 x = {\u0026#34;a\u0026#34;, \u0026#34;b\u0026#34;, \u0026#34;c\u0026#34;} y = {\u0026#34;f\u0026#34;, \u0026#34;d\u0026#34;, \u0026#34;a\u0026#34;} z = {\u0026#34;c\u0026#34;, \u0026#34;d\u0026#34;, \u0026#34;e\u0026#34;} result = x.union(y, z) print(result) # The output results are. # {\u0026#39;c\u0026#39;, \u0026#39;d\u0026#39;, \u0026#39;f\u0026#39;, \u0026#39;e\u0026#39;, \u0026#39;b\u0026#39;, \u0026#39;a\u0026#39;} 4.6 isdisjoint() The isdisjoint() method is used to determine if two collections contain the same elements, == returns True if they do not, False otherwise. == The isdisjoint() method is used to determine if two collections contain the same elements, == returns True if they do not, otherwise returns False.\nSyntax:\n# isdisjoint() method syntax. set.isdisjoint(set) Example:\nx = {\u0026#34;apple\u0026#34;, \u0026#34;banana\u0026#34;, \u0026#34;cherry\u0026#34;} y = {\u0026#34;google\u0026#34;, \u0026#34;runoob\u0026#34;, \u0026#34;apple\u0026#34;} # Determine if the set y contains elements of the set x. If not, return True, if yes, return False z = x.isdisjoint(y) # The result returns False, that the set y has the same elements as x print(z) x = {\u0026#34;apple\u0026#34;, \u0026#34;banana\u0026#34;, \u0026#34;cherry\u0026#34;} y = {\u0026#34;google\u0026#34;, \u0026#34;runoob\u0026#34;, \u0026#34;baidu\u0026#34;} # Determine if the set y contains elements of the set x. If not, return True, if yes, return False z = x.isdisjoint(y) # The result returns True, that is, the set y does not have the same elements as x print(z) # Output results. # False # True 4.7 issubset() The issubset() method is used to determine if all elements of a set are contained in the specified set, and returns True if they are, otherwise returns False.\nSyntax:\nissubset() method syntax. set.issubset(set) # **parameters** # set -- required, to be more than the found set # Return Value # Returns a boolean value, True if both are included, False otherwise. Example:\n# Determine if all elements of set x are contained in set y. x = {\u0026#34;a\u0026#34;, \u0026#34;b\u0026#34;, \u0026#34;c\u0026#34;} y = {\u0026#34;f\u0026#34;, \u0026#34;e\u0026#34;, \u0026#34;d\u0026#34;, \u0026#34;c\u0026#34;, \u0026#34;b\u0026#34;, \u0026#34;a\u0026#34;} z = x.issubset(y) print(z) # Output results # Description The elements of the set x are contained in y # True Note: All elements in the set must be included, otherwise the result is False\n# The set y contains only elements b and c, and the result is False x = {\u0026#34;a\u0026#34;, \u0026#34;b\u0026#34;, \u0026#34;c\u0026#34;} y = {\u0026#34;f\u0026#34;, \u0026#34;e\u0026#34;, \u0026#34;d\u0026#34;, \u0026#34;c\u0026#34;, \u0026#34;b\u0026#34;, \u0026#34;y\u0026#34;} z = x.issubset(y) print(z) # The output of the result. # False 4.8 issuperset() The issuperset() method is used to determine if all elements of the specified set are contained in the original set, and returns True if they are, otherwise returns False.\nSyntax:\nset.issuperset(set) Example:\n# Determine if all elements of the set y are contained in the set x. x = {\u0026#34;f\u0026#34;, \u0026#34;e\u0026#34;, \u0026#34;d\u0026#34;, \u0026#34;c\u0026#34;, \u0026#34;b\u0026#34;, \u0026#34;a\u0026#34;} y = {\u0026#34;a\u0026#34;, \u0026#34;b\u0026#34;, \u0026#34;c\u0026#34;} z = x.issuperset(y) print(z) # The output is. # True # Return False if not all are included. # Example 1 x = {\u0026#34;f\u0026#34;, \u0026#34;e\u0026#34;, \u0026#34;d\u0026#34;, \u0026#34;c\u0026#34;, \u0026#34;b\u0026#34;} y = {\u0026#34;a\u0026#34;, \u0026#34;b\u0026#34;, \u0026#34;c\u0026#34;} z = x.issuperset(y) print(z) # The output is. # False 4.9 symmetric_difference() The symmetric_difference() method returns the set of non-duplicate elements in the two collections, i.e., it removes the elements that exist in both collections and returns a new collection as a result.\nSyntax:\nset.symmetric_difference(set) Example:\n# Returns a new set of two collections, but removes the duplicate elements of the two collections. x = {\u0026#34;apple\u0026#34;, \u0026#34;banana\u0026#34;, \u0026#34;cherry\u0026#34;} y = {\u0026#34;google\u0026#34;, \u0026#34;runoob\u0026#34;, \u0026#34;apple\u0026#34;} z = x.symmetric_difference(y) print(z) # Output results. # {\u0026#39;banana\u0026#39;, \u0026#39;google\u0026#39;, \u0026#39;cherry\u0026#39;, \u0026#39;runoob\u0026#39;} 4.10 symmetric_difference_update() The symmetric_difference_update() method removes the elements of the current collection that are identical in another specified collection and inserts the elements of another specified collection that are different into the current collection.\nSyntax:\nset.symmetric_difference_update(set) Example:\n# Remove the duplicate elements in the original set x from the set y and insert the non-duplicate elements into the set x. x = {\u0026#34;apple\u0026#34;, \u0026#34;banana\u0026#34;, \u0026#34;cherry\u0026#34;} y = {\u0026#34;google\u0026#34;, \u0026#34;runoob\u0026#34;, \u0026#34;apple\u0026#34;} x.symmetric_difference_update(y) print(x) # Output results. # {\u0026#39;runoob\u0026#39;, \u0026#39;cherry\u0026#39;, \u0026#39;banana\u0026#39;, \u0026#39;google\u0026#39;} Postscript: Several other methods are to add, delete, and check the collection, such as: add() clear() copy() update() pop() remove() discard() and other methods, these methods are detailed in the basic operation of the collection chapter, we will use as needed.\nSummary  This section introduces you to the manipulation and use of collections in Python data structures, and provides some basic knowledge and practical support for Python engineers working with collections.\n Reference.\nhttp://www.pythondoc.com/pythontutorial3 https://www.runoob.com/python3/python3-set.html https://github.com/JustDoPython/python-100-day/tree/master/day-015\n","date":"13 Jul, 2021","image":"images/blog/python.png","permalink":"https://codelink.ai/blog/python/python101-15-set/","tags":["learning","python101"],"title":"Python101: 15. Set"},{"categories":["python"],"contents":" Web development is a must-have skill for programs nowadays, as most software is provided in web form, and you need to understand the concepts and features of web development in order to produce backend development or just frontend development.\nSince Python is an interpreted scripting language, it\u0026rsquo;s perfect for Web development, and Python has hundreds of Web development frameworks and mature templating technology, making Web development as easy as possible. Today, we\u0026rsquo;ll borrow the Flask framework to quickly learn about Web development in Python.\n Flask framework  Flask is designed to be easy to use and extend. It was originally intended to build a solid foundation for all kinds of complex web applications. Feel free to plug in any extensions. Flask is suitable for all kinds of projects. It is especially useful for prototyping.Flask relies on two external libraries: the Jinja2 template engine and the Werkzeug WSGI toolkit.\nFlask is one of the most polished and feature-rich microframeworks. flask is still young, with a thriving community, first-class extensions and a beautiful API. flask has the advantages of fast templates, powerful WSGI features, full unit testability at the web application and library level, and extensive documentation.\nThe Flask framework was also chosen because it is easy to get started, has a simple structure, zero configuration, and is a great tool for learning Python web development.\nInstall Flask  Like the other modules, Flask is easy to install with the following package manager via pip\npip install flask To check if the installation is correct, type python at the command line to enter command line mode. Introduce the flask module, enter\nimport flask If there is no error alert, it means the installation is successful\nHello world  The following is the simplest web application you can write hello.py\nfrom flask import Flask # Introduce the Flask module app = Flask(__name__) # Create an application @app.route(\u0026#39;/\u0026#39;) def index(): # Define the root handler return \u0026#39;\u0026lt;h1\u0026gt;Hello World!\u0026lt;/h1\u0026gt;\u0026#39; if __name__ == \u0026#39;__main__\u0026#39;: app.run() # Start the service Open a terminal, jump to the folder where the hello.py file is located, enter python command line mode, and start the service\npython hello.py If they work together normally there will be feedback like the following\n* Serving Flask app \u0026#34;hello\u0026#34; (lazy loading) * Environment: production WARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead. Use a production WSGI server instead. * Debug mode: off * Running on http://127.0.0.1:5000/ (Press CTRL+C to quit)  Since the service is started by app.run(), there will be an error reminding you that you cannot deploy this web application in a production environment, so you can ignore it for now\n At this point, open your browser and type 127.0.0.1:5000/ or localhost:5000/, and you will see the words Hello World!\nRouting  Routing is a very important concept in web development, used to map different requests, to response processing methods, this method is called view function. For example, the Hello application just mapped the root request to the index handler.\nFlask uses modifiers (similar to Java\u0026rsquo;s annotations) to establish route mapping relationships, and has seen the modifier app.rotue()\nSimple Routing For example, visit /hello\n@app.route(\u0026#39;/hello\u0026#39;) def hello(): return \u0026#39;Hello!\u0026#39; Dynamic routing For example, accessing /user/bob or /user/lily will map to the same view function\n@app.route(\u0026#39;/user/\u0026lt;name\u0026gt;\u0026#39;) def user(name): return \u0026#39;\u0026lt;h1\u0026gt;Hello, %s! \u0026lt;/h1\u0026gt;\u0026#39; % name The dynamic part of the dynamic domain name can be used as a parameter of the view function, which also supports multiple dynamic parameters, such as accessing /user/bob/23\n@app.route(\u0026#39;/user/\u0026lt;name\u0026gt;/\u0026lt;age\u0026gt;\u0026#39;) def user(name, age): return \u0026#34;\u0026lt;h1\u0026gt; Hello, %s, you\u0026#39;re %syears old\u0026#34; % (name, age) It is also possible to specify the data type of the dynamic part, such as\n@app.route(\u0026#39;/post/\u0026lt;int:post_id\u0026gt;\u0026#39;) def show_post(post_id): # show the post with the given id, the id is an integer return \u0026#39;Post %d\u0026#39; % post_id @app.route(\u0026#39;/path/\u0026lt;path:subpath\u0026gt;\u0026#39;) def show_subpath(subpath): # show the subpath after /path/ return \u0026#39;Subpath %s\u0026#39; % escape(subpath) Supported Data Types\n   Type Description     string (default) Any text that does not contain a slash   int positive integer   float positive floating point   path is similar to string, but can contain slashes   uuid accepts the UUID string    Specify the HTTP method HTTP protocol, supports a variety of HTTP methods, such as HEAD, OPTIONS, and the common GET, POST, etc. Flask automatically handles HEAD and OPTIONS, the default method accepted by the route is GET, if you want to match other request methods, you can specify in the methods parameter of the route method to specify\n@app.route(\u0026#39;/login\u0026#39;, methods=[\u0026#39;GET\u0026#39;, \u0026#39;POST\u0026#39;]) def login(): if request.method == \u0026#39;POST\u0026#39;: return do_the_login() else: return show_the_login_form() Composite Routing You can also use multiple routing rules for a single view function, e.g. accessing /job/ and accessing /work/ has the same effect\n@app.route(\u0026#39;/job/\u0026#39;) @app.route(\u0026#39;/work/\u0026#39;) def show_works(): return \u0026#39;This is works page\u0026#39; A more complex example\n@app.route(\u0026#39;/users/\u0026#39;, defaults={\u0026#39;page\u0026#39;: 1}) @app.route(\u0026#39;/users/page/\u0026lt;int:page\u0026gt;\u0026#39;) def show_users(page): pass The above code means that the show_users view function handles access to either /user/ or /user/page/\u0026lt;pageindex\u0026gt;, and also provides a default value for /user/, i.e. accessing /user/ is equivalent to accessing /user/page/1\nRequest and Response  The Flask framework provides a request object request and a response object response that can be easily used in the view function.\nRequest Flask wraps the HTTP request sent by the client into a request request object and temporarily makes request globally accessible using a context, so it can be used directly in the view.\n Note: request is not really a global variable! Imagine a multi-threaded server where multiple threads are processing different requests from different clients at the same time, each thread will see a different request object.\n Flask has two contexts, the program context and the request context, and the global variables corresponding to each are listed below:\n   Variable name Context type Remarks     current_app program_context Indicates the current instance of the running program   g program_context Used as a temporary storage object while the request is being processed, and will be reset for each request   request Request context The request object from the client   session  The session information carried by the request     Before you can use the request object, you need to introduce the\nfrom flash import request The request object provides a rich set of properties and methods, as an example here. The current request method can be manipulated by using the method property, and form data (data transferred in a POST or PUT request) can be handled by using the form property. Here is an example of using the above two properties:\n@app.route(\u0026#39;/login\u0026#39;, methods=[\u0026#39;POST\u0026#39;, \u0026#39;GET\u0026#39;]) def login(): error = None if request.method == \u0026#39;POST\u0026#39;: if valid_login(request.form[\u0026#39;username\u0026#39;], request.form[\u0026#39;password\u0026#39;]): return log_the_user_in(request.form[\u0026#39;username\u0026#39;]) else: error = \u0026#39;Invalid username/password\u0026#39; # the code below is executed if the request method # was GET or the credentials were invalid return render_template(\u0026#39;login.html\u0026#39;, error=error)  Note: What happens when the key does not exist in the form property? A KeyError is raised. If this error is not handled, an HTTP 400 Bad Request error page will be displayed.\n If you want to manipulate the parameters submitted in the URL (e.g. ?key=value) you can use the args property, e.g. : searchword = request.args.get('key', '')\nRequest hooks Sometimes it can be useful to execute code before or after the request is processed. For example, at the beginning of a request, it may be necessary to create a database connection or authenticate the user who initiated the request. To avoid using duplicate code in every view function, Flask provides the ability to register generic functions that can be called before or after the request is distributed to the view function. Request hooks are implemented using modifiers. flask supports the following 4 types of hooks:\n before_first_request: Register a function to be run before the first request is processed. before_request: register a function to be run before each request. after_request: Register a function to run after each request if no unhandled exceptions are thrown. teardown_request: register a function to be run after each request even if there are unhandled exceptions thrown.  Example: On receiving the first request, print the sentence.\n@app.before_first_request def first_quest(): print(\u0026#34;run before first request\u0026#34;) Sharing data between request hook functions and view functions generally uses the context global variable g.. For example, the before_request handler may load the logged-in user from the database and save it to g.user. When the view function is subsequently called, the view function then uses g.user to get the user.\nResponse A response is a response from the web server to a request, and in Flask, there are several forms of responses. The return value of a view function is automatically converted into a response object.\nIf the return value is a string, it is converted to a response object containing a string as the response body, a 200 OK error code, and a text/html type response object.\nIf the return value is a dictionary, then jsonify() is called to generate a response. The following are the rules for conversion.\n If the view returns a response object, then it is returned directly. If a string is returned, then a response object is generated for return based on the string and default parameters. If a dictionary is returned, then call jsonify to create a response object. If a tuple is returned, then the items in the tuple can provide additional information. The tuple must contain at least one item, and the item should consist of (response, status), (response, headers), or (response, status, headers). The value of status overloads the status code, and headers is a list or dictionary of additional header values. If none of the above, then Flask assumes that the return value is a valid WSGI application and converts it to a response object.  In addition to that, you can also create responsive objects to do more personalized things with the make_response() function.\nBefore you can use make_response(), you need to introduce\nfrom flask import make_response Example.\n The response has a tuple composition  @app.errorhandler(404) def not_found(error): return render_template(\u0026#39;error.html\u0026#39;), 404  The @app.errorhandler modifier maps a response code to a view function, in this case a 404 (page not found) code, into a personalized error page\nIn addition, render_template is a Flask template function, which is simply formatted as a dynamic html string, and the detailed usage of the template is described in the Templates section\n  Use make_response() to wrap the return expression, get the response object, modify it, and then return it:  @app.errorhandler(404) def not_found(error): resp = make_response(render_template(\u0026#39;error.html\u0026#39;), 404) resp.headers[\u0026#39;X-Something\u0026#39;] = \u0026#39;A value\u0026#39; return resp Summary  This article provides a brief introduction to the basics of Python web development with the help of the Flask framework, which will hopefully help you get started quickly and get you started on the road to Python. Stay tuned for more on web development topics, templates, databases, and extensions!\n Reference\n Book: Flask Web Development Flask Quick Start: https://dormousehole.readthedocs.io/en/latest/quickstart.html quickstart.html) Flask Getting Started to Mastery (II): https://www.cnblogs.com/java-wgm/p/6602900.html Web Server Gateway Interface sample code  ","date":"12 Jul, 2021","image":"images/blog/python.png","permalink":"https://codelink.ai/blog/python/python101-14-introduction-to-flask-for-web-development/","tags":["learning","python101"],"title":"Python101: 14. Introduction to Flask for Web Development"},{"categories":["python"],"contents":"We\u0026rsquo;ve actually touched on Python\u0026rsquo;s input and output features in previous articles, so let\u0026rsquo;s learn more about them in this article.\n 1 Formatted output  Python outputs values in two ways: expression statements and print functions (the write method is used for output from file objects; for standard file output, see sys.stdout , detailed documentation).\nIf we want to convert the output value to a string, we can do so using the repr() or str() functions, where the repr() function produces an interpreter-readable expression and the str() function returns a user-readable expression.\nIf we don\u0026rsquo;t just want to print space-separated values, but want to control the formatting of the output, there are two ways to do it: one is to process the whole string yourself, and the other is to use str.format(), and the following describes the use of str.\n1ÔºâBasic use\nprint(\u0026#39;{}URL: \u0026#34;{}!\u0026#34;\u0026#39; .format(\u0026#39;Python technology\u0026#39;, \u0026#39;codelink.ai\u0026#39;)) # Python technology URL: \u0026#34;codelink.ai\u0026#34; The brackets and the characters inside them (called formatting fields) will be replaced by the arguments in format()\nThe number in the parentheses is used to point to the position of the incoming object in format()  print(\u0026#39;{0}and {1}\u0026#39;.format(\u0026#39;Hello\u0026#39;, \u0026#39;Python\u0026#39;)) # Hello and Python print(\u0026#39;{0}{1}\u0026#39;.format(\u0026#39;Hello\u0026#39;, \u0026#39;Python\u0026#39;)) # Hello Python print(\u0026#39;{1}{0}\u0026#39;.format(\u0026#39;Hello\u0026#39;, \u0026#39;Python\u0026#39;)) # Python Hello If keyword arguments are used in format(), then their values will point to the arguments that use that name  print(\u0026#39;{name}URL: {site}\u0026#39;.format(name=\u0026#39;Python Technologies\u0026#39;, site=\u0026#39;codelink.ai\u0026#39;)) # Python technology URL: codelink.ai Location and keyword parameters can be arbitrarily combined  print(\u0026#39;E-commerce sites {0}, {1}, {other}.\u0026#39; .format(\u0026#39;taobao\u0026#39;, \u0026#39;jingdong\u0026#39;, other=\u0026#39;Pinduoduo\u0026#39;)) # e-commerce sites Taobao, Jingdong, Pinduoduo. Pass the dictionary in as a keyword parameter with the ** flag  \u0026quot;repr() shows quotes: {!a}; str() doesn't: {!s}\u0026quot;.format('test1', 'test2') \u0026quot;repr() shows quotes: 'test1'; str() doesn't: test2\u0026quot; Optional : and format directives are allowed after the field name  # Convert PI to 3-digit precision import math print(\u0026#39;The value of PI is approximately {0:.3f}.\u0026#39; .format(math.pi)) # The value of PI is approximately 3.142. Adding an integer to the : after the field will limit the minimum width of the field  table = {\u0026#39;Sjoerd\u0026#39;: 123, \u0026#39;Jack\u0026#39;: 456, \u0026#39;Dcab\u0026#39;: 789} for name, phone in table.items(): print(\u0026#39;{0:10}== {1:10d}\u0026#39;.format(name, phone)) # Jack == 456 # Dcab == 789 # Sjoerd == 123 If there is a long formatted string and you do not want to split it you can pass in a dictionary and access its keys using the brackets ( [] ).  table = {\u0026#39;Sjoerd\u0026#39;: 123, \u0026#39;Jack\u0026#39;: 456, \u0026#39;Dcab\u0026#39;: 789789789789} print(\u0026#39;Jack: {0[Jack]:d}; Sjoerd: {0[Sjoerd]:d}; \u0026#39; \u0026#39;Dcab: {0[Dcab]:d}\u0026#39;.format(table)) # Jack: 456; Sjoerd: 123; Dcab: 789789789789 It is also possible to pass this dictionary as a keyword parameter with the ** flag.\ntable = {\u0026#39;Sjoerd\u0026#39;: 123, \u0026#39;Jack\u0026#39;: 456, \u0026#39;Dcab\u0026#39;: 789789789789} print(\u0026#39;Jack: {Jack:d}; Sjoerd: {Sjoerd:d}; Dcab: {Dcab:d}\u0026#39;.format(**table)) # Jack: 456; Sjoerd: 123; Dcab: 789789789789 2 Read keyboard input  Python provides the input() built-in function to read a line of text from standard input, which by default is the keyboard. input() takes a Python expression as input and returns the result of the operation. Examples are as follows.\ns = input(\u0026#34;Please enter:\u0026#34;) print (\u0026#34;The input is: \u0026#34;, str) # Please enter: Hello Python # You entered: Hello Python 3 File reading and writing  The open() function returns a file object, the usual usage takes two arguments: open(filename, mode).\nThe first parameter filename is the name of the file to be accessed, the second parameter mode describes how to use the file (the possible values are mainly: \u0026lsquo;r\u0026rsquo; reads the file; \u0026lsquo;w\u0026rsquo; just writes the file, already existing files with the same name will be deleted; \u0026lsquo;a\u0026rsquo; opens the file for appending, automatically adding to the end; \u0026lsquo;r+\u0026rsquo; opens the file for reading and writing; \u0026lsquo;rb+\u0026rsquo; opens a file in binary format (opens a file for reading and writing\u0026hellip;) The mode parameter is optional and defaults to \u0026lsquo;r\u0026rsquo;.\n3.1 File object methods  read()  To read the contents of the file, call read(size), with size as an optional parameter.\nf = open(\u0026#39;tmp.txt\u0026#39;, \u0026#39;r\u0026#39;) s = f.read(5) print(s) f.close() # Hello  readline()  Reads a line with a line break of \\n.\nf = open(\u0026#39;tmp.txt\u0026#39;, \u0026#39;r\u0026#39;) s = f.readline() print(s) f.close()  readlines()  Reads all lines contained in the file, with the optional parameter size.\nf = open(\u0026#39;tmp.txt\u0026#39;, \u0026#39;r\u0026#39;) s = f.readlines(1) print(s) f.close() # [\u0026#39;Hello Python\u0026#39;]  write()  write(string) Writes the contents of a string to a file.\nf = open(\u0026#39;tmp.txt\u0026#39;, \u0026#39;w\u0026#39;) num = f.write(\u0026#39;Hello Python\u0026#39;) print(num) f.close() # 12  seek()  seek(offset, from_what) change the current position of the file. offset move distance; from_what start position, 0 means the beginning, 1 means the current position, 2 means the end, the default value is 0, that is, the beginning.\nf = open(\u0026#39;tmp.txt\u0026#39;, \u0026#39;rb+\u0026#39;) f.write(b\u0026#39;0123456789abcdef\u0026#39;) # Move to the 6th byte of the file f.seek(5) print(f.read()) # b\u0026#39;56789abcdef\u0026#39;  tell()  tell() returns the current position of the file object, which is the number of bytes counted from the beginning of the file.\nf = open('tmp.txt', 'r') f.seek(5) print(f.tell()) 5  close()  When you are done with a file, call close() to close the file and free up the system\u0026rsquo;s resources. You can also use the with keyword to handle file objects to automatically close files when they are used up.\nwith open(\u0026#39;tmp.txt\u0026#39;, \u0026#39;r\u0026#39;) as f: read_data = f.read() print(f.closed) # True 3.2 Manipulating json format data   json.dumps(obj) Serialization, conversion of obj to a string in json format.\n  json.dump(obj, fp) serialization, converting obj to a json formatted string, writing the string to a file.\n  json.loads(s) deserializes a json formatted string into a Python object.\n  json.load(fp) Deserialize, reads data from a file containing json format and deserializes it to a Python object.\n  import json data = {\u0026#39;id\u0026#39;:\u0026#39;1\u0026#39;, \u0026#39;name\u0026#39;:\u0026#39;jhon\u0026#39;, \u0026#39;age\u0026#39;:12} with open(\u0026#39;t.json\u0026#39;, \u0026#39;w\u0026#39;) as f: json.dump(data, f) with open(\u0026#34;t.json\u0026#34;, \u0026#39;r\u0026#39;) as f: d = json.load( f) print(d) # {\u0026#39;id\u0026#39;: \u0026#39;1\u0026#39;, \u0026#39;name\u0026#39;: \u0026#39;jhon\u0026#39;, \u0026#39;age\u0026#39;: 12} Summary  This section gives you an introduction to Python input and output, and provides support for Python engineers to be able to choose the right input and output method for the actual situation.\n Reference.\nhttps://docs.python.org/zh-cn/3/library/string.html#formatspec\nhttps://docs.pythontab.com/python/python3.5/inputoutput.html#tut-files\nPython-100-days-day013\n","date":"11 Jul, 2021","image":"images/blog/python.png","permalink":"https://codelink.ai/blog/python/python101-13-output-and-input/","tags":["learning","python101"],"title":"Python101: 13. Output and Input"},{"categories":["python"],"contents":" 1. Introduction of references and tools  The treatment of variables in Python is very different from that of C. Variables in Python have a special property: identity, or \u0026ldquo;identity\u0026rdquo;. This special property is also known in many places as a \u0026ldquo;reference\u0026rdquo;.\nTo illustrate reference-related issues more clearly, we will first introduce two tools: a built-in Python function: id(); an operator: is; and also a function within the sys module: getrefcount().\n1.1 Built-in function id() id(object)\n This is an integer which is guaranteed to be unique and constant for this object during its Two objects with non-overlapping lifetimes may have the same [id()](https://docs.python.org/3.7/library/functions.html?highlight =id#id) value.\nThe return value is the \u0026ldquo;identifier\u0026rdquo; of the incoming object. This identifier is a unique constant that corresponds to the incoming object during its lifetime. Two objects whose lifecycles do not overlap may have the same id() return value.\n  CPython implementation detail: This is the address of the object in memory.\nCPython implementation detail: \u0026ldquo;identity\u0026rdquo; is actually the address of the object in memory.\n\u0026ndash; quoted from \u0026ldquo;Python 3.7.4 Documentation-Built-In-Functions-id()\n In other words, an object\u0026rsquo;s id can be treated as its virtual memory address, regardless of whether it is a CPython implementation or not.\n1.2 The operator is    Operations Meaning     is object identity     i.e., the role of is is to compare the identity of objects. \u0026ndash; quoted from \u0026ldquo;Python 3.7.4 Documentation-Built-In Types\n 1.3 sys module function getrefcount() function sys.getrefcount(object)\n Return the reference count of the object. The count returned is generally one higher than you might expect, because it includes the (temporary) reference as an argument to getrefcount().\nThe return value is the reference count of the passed-in object. Since a temporary reference is generated when getrefcount() is passed as an argument, the returned count value is generally 1 more than expected.\n\u0026ndash; Cited in [Python 3.7.4 Documentation - sys Module - System-Related Parameters and Functions](https://docs.python.org/3.7/library/sys. html#sys.getrefcount)\n The \u0026ldquo;reference count\u0026rdquo; in this case is defined in the Python documentation as \u0026ldquo;the number of times an object referenced\u0026rdquo;. Once the reference count goes to zero, the memory where the object is located is freed. This is a mechanism for automatic memory management within Python.\n2. Example questions  In C, a variable represents a fixed piece of memory, and the value assigned to it is the data that exists at that address; in Python, however, a variable is no longer a fixed address, but rather a label attached to each object in Python. Understanding this is important for understanding many of Python\u0026rsquo;s features.\n2.1 Assigning values to the same variable For example, for the following C code.\nint c_variable = 10000; printf(\u0026#34;original address: %p\\n\u0026#34;, \u0026amp;a); // original address: 0060FEFC c_variable = 12345; printf(\u0026#34;second address: %p\\n\u0026#34;, \u0026amp;a); // second address: 0060FEFC To anyone with experience in C programming, the above result is obvious: the address of the variable c_variable does not change just because the value assigned to it has changed. For the C compiler, the variable c_variable is simply an identifier that assists it in distinguishing individual memory addresses and is directly bound to a specific memory address, as shown in the figure.\nBut Python is different. Consider the following code.\npython_variable = 10000 id(python_variable) # 1823863879824 python_variable = 12345 id(python_variable) # 1823863880176 What is even more amazing is that even when the same constant is assigned to a variable, the resulting id can be different.\npython_variable = 10000 id(python_variable) # 1823863880304 python_variable = 10000 id(python_variable) # 1823863879408 If the data type corresponding to python_variable is a list, then.\npython_variable = [1,2] id(python_variable) # 2161457994952 python_variable = [1,2] id(python_variable) # 2161458037448 The id value obtained is also different.\nAs mentioned earlier, in Python, a variable is a brick that is moved wherever it is needed. Every time you assign a new object to a variable, you recreate an object in memory that has a new reference value. As a \u0026ldquo;tag\u0026rdquo;, variables are also applied wherever they\u0026rsquo;re needed, without any sense of propriety.\n But note that there is another problem here: the reason why \u0026ldquo;even if the same constant is assigned to a variable, the id obtained may be different\u0026rdquo; is that this is not the case for all constants. If we take the constant 1 as an example, we have the following result.\nlittleConst = 1 # integer objects with small values id(littleConst) # 140734357607232 littleConst = 1 id(littleConst) # 140734357607232 id(1) # 140734357607232 As you can see, the id corresponding to the constant 1 is always the same and has not changed, so the id of the variable littleConst has not changed either.\nThis is because Python maintains a pool of a specific number of constants in memory, and no new objects are created for any value within a certain range, but are allocated directly in this pool of constants. In fact, using the following code on my machine, I can get this pool of constants in the range [0, 256], which is exactly the number of values that can be represented in a single byte of binary code.\nfor constant in range(300): if constant is not range(300)[constant]: print(\u0026#34;The maximum value of the constant pool is:\u0026#34;, (constant - 1)) break # The maximum value of the constant pool is: 256  Accordingly, adding, subtracting, multiplying and dividing values and assigning the results to the original variables will change the corresponding reference values of the variables.\nchange_ref = 10000 id(change_ref) # 2161457772304 change_ref = change_ref + 1 change_ref # 10001 id(change_ref) # √•2161457772880 Comparing the output of lines 3 and 8 of the code block, you can see that adding and assigning a value to a numeric variable changes the reference value of the corresponding variable. This should be easier to understand. Because according to Python operator precedence, change_ref = change_ref + 1 is actually change_ref = (change_ref + 1), and adding 1 to the value of the variable change_ref gives a new value, which is then assigned to change_ref ref, and the reference to change_ref is changed. The same is true for lists.\nlist_change_ref = [1,2] id(list_change_ref) # 2161458326920 list_change_ref = list_change_ref + [4] list_change_ref # [1, 2, 4] id(list_change_ref) # 2161458342792 2.2 The case of no change Unlike numeric values, operations on list objects in Python exhibit another characteristic. Consider the following code.\nlist_nonchange = [1, 2, 3] id(list_nonchange) # 2161458355400 list_nonchange[2] = 5 list_nonchange # [1, 2, 5] id(list_nonchange) # 2161458355400 list_nonchange.append(3) list_nonchange # [1, 2, 5, 3] id(list_nonchange) # 2161458355400 Observe lines 3, 8, and 13 of the code block and the output is the same. That is, for a list, it is possible to change the referenced value without changing its reference by directly manipulating the variable itself.\nFurther, in the case of two variables referring to the same list at the same time, a direct operation on one of the variables itself will also affect the value of the other variable.\nlist_example = [1, 2, 3] list_same_ref = list_example id(list_example) # 1823864610120 id(list_same_ref) # 1823864610120 Obviously the variables list_example and id of list_same_ref are the same at this point. Now change the value of the list referenced by list_example.\nlist_example[2] = 5 list_same_ref # [1, 2, 5] You can see that the value of the list referenced by list_same_ref has also changed. And look at the corresponding id.\nid(list_example) # 1823864610120 id(list_same_ref) # 1823864610120 The id of both variables does not change. Calling the append() method again.\nlist_example.append(3) list_example # [1, 2, 5, 3] list_same_ref # [1, 2, 5, 3] id(list_example) # 1823864610120 id(list_same_ref) # 1823864610120 Delete element.\ndel list_example[3] list_example # [1, 2, 5] list_same_ref # [1, 2, 5] id(list_example) # 1823864610120 id(list_same_ref) # 1823864610120 In all the above operations on the list, the references to the corresponding elements are not changed.\nThat is, operations on the variables themselves do not create new objects, but directly change the value of the original object.\n2.3 A special place  This subsection example is inspired by [About references in Python]\n There is also a special difference between numeric data and lists. Consider the following code.\nnum = 10000 id(num) # 2161457772336 num += 1 id(num) # 2161457774512 With the preceding padding, such a result seems natural. Apparently when the variable num is incremented by 1, the new value is still calculated and then assigned, so the reference changes.\nBut the list is not. See the following code.\nli = [1, 2, 3] id(li) # 2161458469960 li += [4] id(li) # 2161458469960 li # [1, 2, 3, 4] Note line 4. Why is the result different from the previous one when it is obvious that the operation is \u0026ldquo;add and assign\u0026rdquo;? Checking the value of the variable li, we find that the value of the variable has indeed changed, but the reference has not changed.\nIn fact, this is because the addition operator is overloaded in Python; the underlying implementation of the addition operation is completely different for list objects and numeric objects; in simple addition, the list operation still creates a new list object; but in the abbreviated implementation of the addition operation +=, it does not create a new list object. This is something to be very careful about.\n3. Explanation of Principle  As we mentioned earlier [Python Variables and Data Types], the six standard data types in Python are actually divided into two main categories: variable data and **immutable data **. Lists, dictionaries, and collections are \u0026ldquo;mutable objects\u0026rdquo;, while numbers, strings, and tuples are \u0026ldquo;immutable objects\u0026rdquo;. In fact, the difference between numeric data (i.e., numbers) and lists as demonstrated above is the result of these two different data types.\nSince numbers are immutable objects, we can\u0026rsquo;t do anything to the values themselves that would change the value of the data. So in Python, each occurrence of a value means that a new memory space needs to be allocated (with the exception of values in the constant pool).\nconst_ref = 10000 # const_ref == 10000 # True const_ref is 10000 # False id(const_ref) # 2161457773424 id(10000) # 2161457773136 from sys import getrefcount getrefcount(const_ref) # 2 getrefcount(10000) # 3 The first 9 lines of code are easy to understand: even the same value may have a different reference value. The key is whether the value comes from the same object.\nThe code in line 12 shows that except for the reference of the getrefcount() function, the object referenced by the variable const_ref has only one reference, which is the variable const_ref. Once the variable const_ref is freed, the corresponding object reference count is zeroed and freed; and only then is the memory space corresponding to this object truly \u0026ldquo;freed\u0026rdquo;.\nAs a mutable object, the value of the list can be changed without creating a new object, so it is possible to operate directly on the list object itself for the purpose of \u0026ldquo;changing the value of a variable without changing the reference\u0026rdquo;.\n4. Summary  For variable objects such as lists, dictionaries, and collections, you can change the value of a variable without changing the reference of the variable by operating on the object itself; however, for immutable objects such as numbers, strings, and tuples, the object itself cannot be changed. However, for numbers, strings and tuples, which are \u0026ldquo;immutable objects\u0026rdquo;, the object itself is not capable of variable value operation, so in order to change the value of the corresponding variable, you must create a new object and then assign the new object to the variable.\nThrough such exploration, the profound meaning of \u0026ldquo;everything is an object\u0026rdquo; can also be understood more vividly. 0\n5. References  Python 3.7.4 Documentation-Built-In Functions-id()\nPython 3.7.4 Documentation - Built-in Types\nPython 3.7.4 Documentation - sys module - system related parameters and functions\nPython 3.7.4 Documentation - Glossary\nAbout references in Python\nPython-100-days-day012\n","date":"10 Jul, 2021","image":"images/blog/python.png","permalink":"https://codelink.ai/blog/python/python101-12-references/","tags":["learning","python101"],"title":"Python101: 12. References"},{"categories":["python"],"contents":"The dictionary in Python provides a flexible way to access and organize data\n A dictionary is a collection of many values The index of a dictionary can be of different data types, again not only integers, but also strings The index of a dictionary is called a \u0026ldquo;key\u0026rdquo;, and the key and the value associated with the key are called a key-value pair (similar to a Map collection in Java) Dictionaries are another mutable container model and can store objects of any type. Each key-value key =\u0026gt; value pair of the dictionary is separated by a colon : and each key-value pair is separated by a comma , and the whole dictionary is enclosed in parentheses {} in the following format.  dictionary = {\u0026#39;url1\u0026#39;:\u0026#39;baidu\u0026#39;, \u0026#39;url\u0026#39;:\u0026#39;google\u0026#39;, \u0026#39;num1\u0026#39;:12, \u0026#39;num2\u0026#39;:34}; Keys are generally unique, and if a key is duplicated, the last key-value pair replaces the previous key-value pair, and there is no uniqueness requirement for the value, as follows.\ndic1 = {\u0026#39;name\u0026#39;:\u0026#39;zhangsan\u0026#39;,\u0026#39;age\u0026#39;:23,\u0026#39;address\u0026#39;:\u0026#39;BeiJing\u0026#39;,\u0026#39;name\u0026#39;:\u0026#39;lisi\u0026#39;} # Check the dictionary values to find duplicate keys and replace the previous ones with the later ones dic1 # {\u0026#39;name\u0026#39;: \u0026#39;lisi\u0026#39;, \u0026#39;age\u0026#39;: 23, \u0026#39;address\u0026#39;: \u0026#39;BeiJing\u0026#39;} dic1[\u0026#39;name\u0026#39;] # \u0026#39;lisi\u0026#39; The value can take any data type, but the key must be immutable, such as a string, number or tuple, as follows.\ndic = {\u0026#39;Alice\u0026#39;: \u0026#39;2341\u0026#39;, \u0026#39;Beth\u0026#39;: \u0026#39;9102\u0026#39;, \u0026#39;Cecil\u0026#39;: \u0026#39;3258\u0026#39;,(\u0026#39;a\u0026#39;,\u0026#39;b\u0026#39;):(12,43)} 1. Access to dictionary data  Create a dictionary and access the contents of the data dictionary. The following dictionary keys are \u0026lsquo;size\u0026rsquo;, \u0026lsquo;color\u0026rsquo;, \u0026lsquo;character\u0026rsquo;, and the values corresponding to these keys are \u0026lsquo;big\u0026rsquo;, \u0026lsquo;white\u0026rsquo;, and \u0026lsquo;gentle\u0026rsquo;. Accessing dictionary values can be done directly by adding keys inside square brackets, e.g.\nmy_dog = {\u0026#39;size\u0026#39;:\u0026#39;big\u0026#39;,\u0026#39;color\u0026#39;:\u0026#39;white\u0026#39;,\u0026#39;character\u0026#39;:\u0026#39;gentle\u0026#39;} # Dictionary values are accessed by [\u0026#39;key\u0026#39;] print(my_dog[\u0026#39;size\u0026#39;]) # big # Output the result print(\u0026#39;My Dog has \u0026#39; + my_dog[\u0026#39;color\u0026#39;]+\u0026#39; fur.\u0026#39; + \u0026#39; and it has a \u0026#39; + my_dog[\u0026#39;character\u0026#39;]+\u0026#39; character\u0026#39;) # My Dog has white fur. and it has a gentle character # output result Similarly, dictionaries can use integers as keys, similar to the indexing of lists, except that the dictionary values can be of any integer type and need not start from 0, since the data type of the keys is arbitrary, as follows.\ndic = {12:\u0026#39;big\u0026#39;,0:\u0026#39;white\u0026#39;,354:\u0026#39;gentle\u0026#39;,1:\u0026#39;good\u0026#39;} # Access the dictionary value with key 12 dic[12] 3 \u0026#39;big\u0026#39; # Access the dictionary with key 0 dic[0] 3 \u0026#39;white\u0026#39; Because dictionaries are not sorted, they cannot be sliced like lists. If you access a key that does not exist in the dictionary, you will get a KeyError error message. This is much like the \u0026ldquo;out-of-bounds\u0026rdquo; for lists IndexError error message.\nEnter the following code in the interactive environment and note the error message displayed because for the absence of the \u0026lsquo;color\u0026rsquo; key.\ndic1 = {\u0026#39;name\u0026#39;:\u0026#39;zhangsan\u0026#39;,\u0026#39;age\u0026#39;:23,\u0026#39;address\u0026#39;:\u0026#39;BeiJing\u0026#39;} #Find the value in the dictionary with the key \u0026#39;color\u0026#39; dic1[\u0026#39;color\u0026#39;] # Traceback (most recent call last): # File \u0026#34;\u0026lt;input\u0026gt;\u0026#34;, line 1, in \u0026lt;module\u0026gt; # KeyError: \u0026#39;color\u0026#39; 2. Modify dictionary elements  2.1 Adding and updating dictionary data Adding new content to the dictionary is done by adding new key/value pairs, modifying or deleting existing key/value pairs as shown in the following examples:\ndic = {\u0026#39;Name\u0026#39;: \u0026#39;Fiona\u0026#39;, \u0026#39;Age\u0026#39;: 10, \u0026#39;Class\u0026#39;: \u0026#39;Three\u0026#39;} # Update dic[\u0026#39;Age\u0026#39;] = 8 # Add dic[\u0026#39;School\u0026#39;] = \u0026#34;Middle School\u0026#34; # View dictionary data dic # {\u0026#39;Name\u0026#39;: \u0026#39;Fiona\u0026#39;, \u0026#39;Age\u0026#39;: 8, \u0026#39;Class\u0026#39;: \u0026#39;Three\u0026#39;, \u0026#39;School\u0026#39;: \u0026#39;Middle School\u0026#39;} 2.2 Deleting dictionary elements Deletion of a dictionary element can be done either singly or by emptying the entire dictionary, as shown by deleting a dictionary using the del command \u0026quot;\ndic = {\u0026#39;Name\u0026#39;: \u0026#39;Fiona\u0026#39;, \u0026#39;Age\u0026#39;: 10, \u0026#39;Class\u0026#39;: \u0026#39;Three\u0026#39;} # Delete the entry whose key is \u0026#39;Name\u0026#39; del dic[\u0026#39;Name\u0026#39;] # Clear all entries of the dictionary dic.clear() # Delete the entire dictionary element del dic print (\u0026#34;dic[\u0026#39;Age\u0026#39;]: \u0026#34;, dic[\u0026#39;Age\u0026#39;]) print (\u0026#34;dic[\u0026#39;School\u0026#39;]: \u0026#34;, dic[\u0026#39;School\u0026#39;]) The above print statement raises an exception because the dictionary no longer exists after using del.\nTraceback (most recent call last): File \u0026#34;test.py\u0026#34;, line 12, in \u0026lt;module\u0026gt; print(\u0026#34;dic [\u0026#39;Age\u0026#39;]: \u0026#34;, dic [\u0026#39;Age\u0026#39;]) TypeError: \u0026#39;type\u0026#39; object is not subscriptable 3. Characteristics of dictionary keys  Dictionary values can take any python object without restriction, either standard or user-defined, but not keys.\nTwo important points to remember.\n1) The same key is not allowed to appear twice. When creating if the same key is assigned twice, the latter value will be remembered, as in the following example:\nExample\ndic = {\u0026#39;Name\u0026#39;: \u0026#39;Fiona\u0026#39;, \u0026#39;Age\u0026#39;: 10, \u0026#39;Name\u0026#39;: \u0026#39;Manni\u0026#39;} print(\u0026#34;dic[\u0026#39;Name\u0026#39;]: \u0026#34;, dic[\u0026#39;Name\u0026#39;]) # The output of the above example results in. # dic[\u0026#39;Name\u0026#39;]: Manni 2) The key must be immutable, so it can be filled with a number, string or tuple, so it won\u0026rsquo;t work with a list, as in the following example:\ndic = {[\u0026#39;Name\u0026#39;]: \u0026#39;Fiona\u0026#39;, \u0026#39;Age\u0026#39;: 10} print(\u0026#34;dic[\u0026#39;Name\u0026#39;]: \u0026#34;, dic[\u0026#39;Name\u0026#39;]) # The output of the above example results in. # Traceback (most recent call last): # File \u0026#34;test.py\u0026#34;, line 3, in \u0026lt;module\u0026gt; # dic # = {[\u0026#39;Name\u0026#39;]: \u0026#39;Zara\u0026#39;, \u0026#39;Age\u0026#39;: 7} # TypeError: list objects are unhashable 4. Functions of the dictionary  4.1 len() The len() method calculates the number of dictionary elements (the total number of keys)\n\u0026gt;dic = {\u0026#39;Name\u0026#39;: \u0026#39;Fiona\u0026#39;, \u0026#39;Age\u0026#39;: 10, \u0026#39;class\u0026#39;: \u0026#39;Three\u0026#39;} \u0026gt;len(dic ) 3 4.2 str() The str() method outputs the printable string identifiers in the dictionary\ndic = {\u0026#39;Name\u0026#39;: \u0026#39;Runoob\u0026#39;, \u0026#39;Age\u0026#39;: 10, \u0026#39;Class\u0026#39;: \u0026#39;Three\u0026#39;} str(dic) # \u0026#34;{\u0026#39;Name\u0026#39;: \u0026#39;Runoob\u0026#39;, \u0026#39;Age\u0026#39;: 10, \u0026#39;Class\u0026#39;: \u0026#39;Three\u0026#39;}\u0026#34; 4.3 type() The type() method returns the type of the variable entered, or the dictionary type if the variable is a dictionary\ndic = {\u0026#39;Name\u0026#39;: \u0026#39;Runoob\u0026#39;, \u0026#39;Age\u0026#39;: 10, \u0026#39;Class\u0026#39;: \u0026#39;Three\u0026#39;} type(dic) # \u0026lt;class \u0026#39;dic\u0026#39;\u0026gt; 5. The dictionary approach  5.1 dic.clear() Delete all elements of the dictionary, the clear() method does not return any value, the example is as follows.\ndic = {\u0026#39;Name\u0026#39;: \u0026#39;Fiona\u0026#39;, \u0026#39;Age\u0026#39;: 10} print(\u0026#34;dictionary length : %d\u0026#34; % len(dic)) dic.clear() print(\u0026#34;Length of dictionary after deletion : %d\u0026#34; % len(dic)) # The output results are. # Dictionary length : 2 # Length after dictionary deletion : 0 5.2 dic.copy() The copy() method makes a copy of the dictionary\ndic = {\u0026#39;Name\u0026#39;: \u0026#39;Runoob\u0026#39;, \u0026#39;Age\u0026#39;: 7, \u0026#39;Class\u0026#39;: \u0026#39;First\u0026#39;} dict11 = dic.copy() print(dict11) print(\u0026#34;The newly copied dictionary is : \u0026#34;, dict11) dict1 = {\u0026#39;user\u0026#39;: \u0026#39;runoob\u0026#39;, \u0026#39;num\u0026#39;: [1, 2, 3]} # Shallow copy: reference object assignment dict2 = dict1 # Copy dict3 = dict1.copy() # Modify data data dict1[\u0026#39;user\u0026#39;] = \u0026#39;root\u0026#39; dict1[\u0026#39;num\u0026#39;].remove(1) # Output results print(dict1) print(dict2) print(dict3) Example dict2 is actually a reference to dict1, i.e., alias, so the output is consistent, dict3 deep copy of the parent object, the deep copy will not be modified with dict1, the child object is a shallow copy so modified with dict1, ** that is, the assignment will be modified with the parent object, the copy will not be modified with the parent object **, the above results The output is as follows.\n{\u0026#39;Name\u0026#39;: \u0026#39;Runoob\u0026#39;, \u0026#39;Age\u0026#39;: 7, \u0026#39;Class\u0026#39;: \u0026#39;First\u0026#39;} The newly copied dictionary is : {\u0026#39;Name\u0026#39;: \u0026#39;Runoob\u0026#39;, \u0026#39;Age\u0026#39;: 7, \u0026#39;Class\u0026#39;: \u0026#39;First\u0026#39;} {\u0026#39;user\u0026#39;: \u0026#39;root\u0026#39;, \u0026#39;num\u0026#39;: [2, 3]} {\u0026#39;user\u0026#39;: \u0026#39;root\u0026#39;, \u0026#39;num\u0026#39;: [2, 3]} {\u0026#39;user\u0026#39;: \u0026#39;runoob\u0026#39;, \u0026#39;num\u0026#39;: [2, 3]} 5.3 dic.fromkeys() Create a new dictionary, using the elements of the sequence seq as keys of the dictionary, val is the initial value of all keys of the dictionary, the method returns a new dictionary\nfromkeys() method syntax\ndic.fromkeys(seq[, value]) # Parameters seq -- The list of dictionary keys. value -- Optional parameter, set the value corresponding to the key sequence (seq), default is None. Example:\n# dic.fromkeys(seq[, value]) seq = (\u0026#39;name\u0026#39;, \u0026#39;age\u0026#39;, \u0026#39;class\u0026#39;) # No value specified dic = dic.fromkeys(seq) print(\u0026#34;The new dictionary is : %s\u0026#34; % str(dic)) # assign 10 dic = dic.fromkeys(seq, 10) print(\u0026#34;The new dictionary is : %s\u0026#34; % str(dic)) # Assign a tuple dic = dic.fromkeys(seq,(\u0026#39;zs\u0026#39;,8,\u0026#39;Two\u0026#39;)) print(\u0026#34;The new dictionary is : %s\u0026#34; % str(dic)) The result of the execution returns a new dictionary, if no value is specified the default is None, the output of the above result is\nThe new dictionary is : {\u0026#39;name\u0026#39;: None, \u0026#39;age\u0026#39;: None, \u0026#39;class\u0026#39;: None} New dictionary is : {\u0026#39;name\u0026#39;: 10, \u0026#39;age\u0026#39;: 10, \u0026#39;class\u0026#39;: 10} The new dictionary is : {\u0026#39;name\u0026#39;: (\u0026#39;zs\u0026#39;, 8, \u0026#39;Two\u0026#39;), \u0026#39;age\u0026#39;: (\u0026#39;zs\u0026#39;, 8, \u0026#39;Two\u0026#39;), \u0026#39;class\u0026#39;: (\u0026#39;zs\u0026#39;, 8, \u0026#39;Two\u0026#39;)} 5.4 dic.get(key, default=None) Returns the value of the specified key, or the default value if the value is not in the dictionary\nget() method syntax\ndic.get(key, default=None) # Parameters key -- The key to look for in the dictionary. default -- The default value to return if the value of the specified key does not exist. Example:\n# Example of application of get () method dic = {\u0026#39;Name\u0026#39;: \u0026#39;Mary\u0026#39;, \u0026#39;Age\u0026#39;: 20} print(\u0026#34;Age value is : %s\u0026#34; % dic.get(\u0026#39;Age\u0026#39;)) print(\u0026#34;Name value is : %s\u0026#34; % dic.get(\u0026#39;Name\u0026#39;)) print(\u0026#34;Sex value is : %s\u0026#34; % dic.get(\u0026#39;Sex\u0026#39;, \u0026#34;NA\u0026#34;)) The above result is output as:\nAge value is : 20 Name value is : Mary Sex value is : NA 5.5 key in dic Returns true if the key is in the dictionary dic, otherwise false\ndic = {\u0026#39;Name\u0026#39;: \u0026#39;Mary\u0026#39;, \u0026#39;Age\u0026#39;: 20,\u0026#39;Address\u0026#39;:\u0026#39;BeiJing\u0026#39;} # Check if the key Age exists if \u0026#39;Age\u0026#39; in dic: print(\u0026#34;Key Age exists\u0026#34;) else: print(\u0026#34;Key Age does not exist\u0026#34;) # Check if the key Sex exists if \u0026#39;Sex\u0026#39; in dic: print(\u0026#34;Key Sex exists\u0026#34;) else: print(\u0026#34;Key Sex does not exist\u0026#34;) # not in # Check if the key Name exists if \u0026#39;Name\u0026#39; is not in dic: print(\u0026#34;Key Name does not exist\u0026#34;) else: print(\u0026#34;Key Name exists\u0026#34;) The above result is output as:\nKey Age exists Key Sex does not exist Key Name exists 5.6 dic.items() The item() method returns an array of traversable (key, value) tuples as a list\ndic = {\u0026#39;Name\u0026#39;: \u0026#39;Mary\u0026#39;, \u0026#39;Age\u0026#39;: 17} print (\u0026#34;Value : %s\u0026#34; % dic.items()) # The output is. Value : dict_items([(\u0026#39;Age\u0026#39;, 17), (\u0026#39;Name\u0026#39;, \u0026#39;Mary\u0026#39;)]) Examples of traversable tuple arrays:\ndict1 = {\u0026#39;oldest\u0026#39;:\u0026#39;25 years old\u0026#39;, \u0026#39;second\u0026#39;:\u0026#39;20 years old\u0026#39;, \u0026#39;third\u0026#39;:\u0026#39;12\u0026#39;, } print(dict1.items()) for key,values in dict1.items(): print(key + \u0026#39;already\u0026#39; + values + \u0026#39;up\u0026#39;) The above result is output as:\nThe oldest is 25 years old The second is 20 years old The third is 12 years old Process finished with exit code 0 5.7 dic.keys() Returns an iterator, which can be converted to a list using list()\nkeys() method syntax:\ndic.keys() Example:\ndic = {\u0026#39;Name\u0026#39;: \u0026#39;Mary\u0026#39;, \u0026#39;Age\u0026#39;: 17} print(dic.keys()) The above result is output as:\ndict_keys([\u0026#39;Name\u0026#39;, \u0026#39;Age\u0026#39;]) From the result, we see that the result returns an iterative object, which we can then convert to a list using the list.\nlist1 = list(dic.keys()) print (\u0026#34;The result of the conversion is : %s\u0026#34; % list1) # The output is a list, which can be subsequently manipulated accordingly. # The result after conversion is : [\u0026#39;Name\u0026#39;, \u0026#39;Age\u0026#39;] 5.8 dic.setdefault(key, default=None) The Python dictionary setdefault() method is similar to the get() method in that if the key is in the dictionary, it returns the corresponding value. If it\u0026rsquo;s not in the dictionary, it inserts the key and the set default value, and returns default, which defaults to None.\nsetdefault() method syntax:\ndic.setdefault(key, default=None) # Parameters key -- The key value to look up. default -- The default key value to set if the key does not exist. Example:\ndic = {\u0026#39;Name\u0026#39;: \u0026#39;Mary\u0026#39;, \u0026#39;Age\u0026#39;: 17} print (\u0026#34;Age key value is : %s\u0026#34; % dic.setdefault(\u0026#39;Age\u0026#39;, None)) print (\u0026#34;The value of the Sex key is : %s\u0026#34; % dic.setdefault(\u0026#39;Sex\u0026#39;, None)) print (\u0026#34;The new dictionary is:\u0026#34;, dic) The above result is output as:\nThe value of the Age key is : 17 The value of the Sex key is : None The new dictionary is: {\u0026#39;Age\u0026#39;: 17, \u0026#39;Name\u0026#39;: \u0026#39;Mary\u0026#39;, \u0026#39;Sex\u0026#39;: None} 5.9 dic.update(dict2) The Python dictionary update() function updates the key/value pairs of the dictionary argument dict2 to the dictionary dic.\nSyntax:\ndic.update(dict2) # Parameters dict2 -- The dictionary to add to the specified dictionary dic . Example:\ndic = {\u0026#39;Name\u0026#39;: \u0026#39;Mary\u0026#39;, \u0026#39;Age\u0026#39;: 17} dict2 = {\u0026#39;Sex\u0026#39;: \u0026#39;female\u0026#39; } # Add the result from dict2 to the dictionary dic dic.update(dict2) print(\u0026#34;Update dictionary dic : \u0026#34;, dic) The above result is output as:\nUpdate dictionary dic : {\u0026#39;Name\u0026#39;: \u0026#39;Mary\u0026#39;, \u0026#39;Age\u0026#39;: 17, \u0026#39;Sex\u0026#39;: \u0026#39;female\u0026#39;} 5.10 dic.values() The Python dictionary values() method returns an iterator, which can be converted to a list using list(), which is a list of all the values in the dictionary.\ndic = { \u0026#39;Name\u0026#39;: \u0026#39;Mary\u0026#39;, \u0026#39;Sex\u0026#39;: \u0026#39;male\u0026#39;, \u0026#39;Age\u0026#39;: 7} print(\u0026#34;All values of dictionary are : \u0026#34;, list(dic.values())) The output of the above result is:\nAll values of the dictionary are : [\u0026#39;Mary\u0026#39;, \u0026#39;male\u0026#39;, 7] 5.11 dic.pop(key[,default]) The Python dictionary pop() method deletes the value corresponding to a given key key of the dictionary, returning the value that was deleted. key value must be given. Otherwise, the default value is returned.\npop() method syntax:\npop(key[,default]) #Parameters key: the key value to be deleted default: If there is no key, return the default value # Return Value Returns the value that was deleted. Example:\ndic = {\u0026#39;Name\u0026#39;: \u0026#39;Mary\u0026#39;, \u0026#39;Age\u0026#39;: 17} result = dic.pop(\u0026#39;Age\u0026#39;) # delete print(result) The above result is output as:\n17 Process finished with exit code 0 5.12 dic.popitem() The Python dictionary popitem() method returns a random key-value pair (key,value) in the form of a LIFO (Last In First Out) order, i.e., the last key-value pair. If the dictionary is empty and this method is called, a KeyError exception is thrown.\nExample:\ndic = {\u0026#39;Name\u0026#39;: \u0026#39;Mary\u0026#39;, \u0026#39;Age\u0026#39;: 17} pop_obj = dic.popitem() print(pop_obj) print(dic) The above result is output as:\n(\u0026#39;Age\u0026#39;, 17) {\u0026#39;Name\u0026#39;: \u0026#39;Mary\u0026#39;} Empty the dictionary of.\ndic = {\u0026#39;Name\u0026#39;: \u0026#39;Mary\u0026#39;, \u0026#39;Age\u0026#39;: 17} del dic print(dic.popitem()) The result output is:\nTraceback (most recent call last): File \u0026#34;test.py\u0026#34;, line 4, in \u0026lt;module\u0026gt; print(dic .popitem()) TypeError: descriptor \u0026#39;popitem\u0026#39; of \u0026#39;dic\u0026#39; object needs an argument 6. Dictionaries and lists  6.1 Dictionary and list differences The elements of a list are ordered because the elements are stored incrementally from 0 through the sequence, while the contents of a dictionary are not ordered, as the following example illustrates well.\nlist1 = [\u0026#39;zhangsan\u0026#39;,23,\u0026#39;BeiJing\u0026#39;] list2 = [\u0026#39;BeiJing\u0026#39;,\u0026#39;zhangsan\u0026#39;,23] list1 == list2 # False dic1 = {\u0026#39;name\u0026#39;:\u0026#39;zhangsan\u0026#39;,\u0026#39;age\u0026#39;:23,\u0026#39;address\u0026#39;:\u0026#39;BeiJing\u0026#39;} dic2 = { \u0026#39;age\u0026#39;:23,\u0026#39;name\u0026#39;:\u0026#39;zhangsan\u0026#39;,\u0026#39;address\u0026#39;:\u0026#39;BeiJing\u0026#39;} dic1 == dic2 # True From the above example, we can see that when the contents of the list elements are the same, the order is different and then compare the contents when the matching is not successful, the same way the dictionary values match successfully, indicating that the contents of the elements in the dictionary are not stored in order.\nSummary  This section gives an introduction to the operation and use of Python data structures with dictionaries, and provides support for some of the basics of using dictionaries for Python engineers.\n Reference\nhttp://www.pythondoc.com/pythontutorial3 https://www.runoob.com/python3/python3-dictionary.html https://github.com/JustDoPython/python-100-day/tree/master/day-011\n","date":"09 Jul, 2021","image":"images/blog/python.png","permalink":"https://codelink.ai/blog/python/python101-11-dictionary/","tags":["learning","python101"],"title":"Python101: 11. Dictionary"},{"categories":["python"],"contents":" If you\u0026rsquo;ve ever learned about object-oriented thinking, you know that object-oriented thinking consists of two basic concepts: classes and objects, and let\u0026rsquo;s learn more about Python classes and objects.\n 1 Basic concepts  1.1 Object-Orientation Object-oriented is an abstraction, a way of looking at things in a categorical way, in Java programming terms: everything is an object; object-oriented has three main features: encapsulation, inheritance, and polymorphism.\n1.2 Classes As mentioned above, object-oriented is a way to see the problem in a categorical way, a category is a class, you can see the class as an abstract template, such as: Car class.\n1.3 Objects An object is an instance created from a class.\n2 Basic usage 2.1 Definition of classes ### Class definition class Car: pass 2.2 Object creation ### Create an instance object of Car c class Car: pass c = Car() 2.3 Defining properties in a class ### Define the attributes of the Car class name class Car: name = \u0026#39;BMW\u0026#39; 3 Methods in the class  3.1 Built-in Methods When Python creates any class, it will contain some built-in methods, mainly including the following.\n   methods description     __init__ Constructor, called when an object is created   __del__ destructor, used when releasing the object   __repr__ print, convert   __setitem__ Assign a value by index   __getitem__ Get the value by index   __len__ get length   __cmp__ compare operations   __call__ function call   __add__ addition   __sub__ subtraction   __mul__ multiplication   __div__ divide   __mod__ the remainder operation   __pow__ multiplication    3.2 Custom Methods Python has three common methods: instance methods, class methods, and static methods, all of which are defined in classes.\n3.2.1 Class Methods A class method is a method that operates on the class itself as an object.\nDefinition and Usage\n\u0026#39;\u0026#39;\u0026#39; Class methods (adjustable class variables, callable by instances, callable by classes) 1. class methods are implemented through the @classmethod decorator and can only access class variables, not instance variables. 2„ÄÅPass the current class object through the cls parameter, no instantiation required. \u0026#39;\u0026#39;\u0026#39; class Car(object): name = \u0026#39;BMW\u0026#39; def __init__(self, name): self.name = name @classmethod def run(cls,speed): print(cls.name,speed,\u0026#39;driving\u0026#39;) # Access method 1 c = Car(\u0026#34;BMW\u0026#34;) c.run(\u0026#34;100mph\u0026#34;) # Access method 2 Car.run(\u0026#34;100mph\u0026#34;) 3.2.2 Static methods Static methods are functions in a class that do not require an instance.\nDefinition and use\n\u0026#39;\u0026#39;\u0026#39; Static methods (adjustable class variables, callable by instance, callable by class) 1. a method without a self argument decorated with @staticmethod. 2. static methods are nominally managed by the class, but in practice they cannot access any properties of the class or the instance in the static method. 3, the call does not need to pass the class or instance. \u0026#39;\u0026#39;\u0026#39; class Car(object): name = \u0026#39;BMW\u0026#39; def __init__(self, name): self.name = name @staticmethod def run(speed): print(Car.name,speed,\u0026#39;driving\u0026#39;) # Access method 1 c = Car(\u0026#34;BMW\u0026#34;) c.run(\u0026#34;100mph\u0026#34;) # Access method 2 Car.run(\u0026#34;100mph\u0026#34;) 3.2.3 Instance methods Instance methods are the methods that can be used by instances of a class.\nDefinition and use\n# Instance methods (adjustable class variables, adjustable instance variables, callable by instances) # The first argument is forced to be the instance object self. class Car(object): name = \u0026#39;BMW\u0026#39; def __init__(self, name): self.name = name def run(self, speed): print(self.name,speed,\u0026#39;driving\u0026#39;) # Access c = Car(\u0026#34;BMW\u0026#34;) c.run(\u0026#34;100 mph\u0026#34;) 4 Class inheritance Definition and use\n# Basic syntax: class ClassName(BaseClassName) # Parent class class Car(object): name = \u0026#39;BMW\u0026#39; def __init__(self, name): self.name = name def run(self,speed): print(self.name,speed,\u0026#39;driving\u0026#39;) # Subclasses class BMWCar(Car): conf = \u0026#34;Affordable\u0026#34; pass # Call the run method of the parent class Car bc = BMWCar(\u0026#34;BMW Affordable Car\u0026#34;) bc.run(\u0026#34;100mph\u0026#34;) 5 Polymorphism of classes Definition and use\n# Parent class class Car(object): name = \u0026#39;BMW\u0026#39; def __init__(self, name): self.name = name def run(self,speed): print(\u0026#39;Car--\u0026gt;\u0026#39;,self.name,speed,\u0026#39;driving\u0026#39;) # Subclass 1 class BMWCar(Car): def run(self,speed): print(\u0026#39;BMWCar--\u0026gt;\u0026#39;,self.name,speed,\u0026#39;driving\u0026#39;) # Subclass 2 class SVWCar(Car): def run(self,speed): print(\u0026#39;SVWCar--\u0026gt;\u0026#39;,self.name,speed,\u0026#39;driving\u0026#39;) # Call the run method c = Car(\u0026#34;Car\u0026#34;) c.run(\u0026#34;120mph\u0026#34;) bc = BMWCar(\u0026#34;BMW\u0026#34;) bc.run(\u0026#34;100mph\u0026#34;) sc = SVWCar(\u0026#34;Volkswagen\u0026#34;) sc.run(\u0026#34;80 mph\u0026#34;) # Output results \u0026#39;\u0026#39;\u0026#39; Car--\u0026gt; Car 120 mph Run BMWCar--\u0026gt; BMW 100 mph Driving SVWCar--\u0026gt; Volkswagen 80mph driving \u0026#39;\u0026#39;\u0026#39; In the above example, we can see that: c, bc and sc are different types of objects, but when they call the run method, they all call the methods of their respective classes, which is polymorphism.\nSummary  This section has introduced you to the definition and use of Python classes and objects, and has provided Python engineers with the support to use different types of methods in their projects as they see fit.\n Reference.\nhttps://www.readwithu.com/Article/python9/Preface.html https://github.com/JustDoPython/python-100-day/tree/master/day-010\n","date":"08 Jul, 2021","image":"images/blog/python.png","permalink":"https://codelink.ai/blog/python/python101-10-classes-and-objects/","tags":["learning","python101"],"title":"Python101: 10. Classes and Objects"},{"categories":["python"],"contents":"A data structure in Python is a collection of data elements that are organized in some way, and these data elements can be numbers, characters, or even other data structures.\nIn Python, the most basic data structures are sequences (lists and tuples), where each element in the sequence has a number (the specific location of the element), which is called an index, and the index subscript starts at 0 and so on \u0026hellip;\u0026hellip;\n  Python\u0026rsquo;s tuples are similar to lists, except that the elements of a tuple cannot be modified.\n  Use parentheses () for tuples and square brackets [] for lists.\n  1. basic tuple operations  1.1 Creating a tuple Tuple creation is simple, just add elements in parentheses (without parentheses is fine) and separate them with commas.\ntup1 = (\u0026#39;baidu\u0026#39;, \u0026#39;google\u0026#39;, 12, 34) tup2 = (1, 2, 3, 4, 5 ) tup3 = \u0026#34;a\u0026#34;, \u0026#34;b\u0026#34;, \u0026#34;c\u0026#34;, \u0026#34;d\u0026#34; # Create an empty tuple tup4 = () # View the type of tup4 and tup3 type(tup4) # \u0026lt;class \u0026#39;tuple\u0026#39;\u0026gt; type(tup3) # \u0026lt;class \u0026#39;tuple\u0026#39;\u0026gt; Note: When the tuple contains only one element, you need to add a comma after the element, otherwise the brackets will be used as operators, as follows.\nTupNum = (34) type(TupNum) # integer without comma # \u0026lt;class \u0026#39;int\u0026#39;\u0026gt; TupNum = (34,) type(TupNum) # plus comma to tuple # \u0026lt;class \u0026#39;tuple\u0026#39;\u0026gt; A tuple is similar to a string, with subscript indexes starting at 0. It can be intercepted, combined, etc.\n1.2 Accessing tuples Accessing a tuple is the same as accessing an element in a sequence, and is done through the subscript index\ntup1 = (\u0026#39;baidu\u0026#39;, \u0026#39;google\u0026#39;,1,2) tup2 = (1, 2, 3, 4, 5, 6, 7) tup1[0:2] # (\u0026#39;baidu\u0026#39;, \u0026#39;google\u0026#39;) tup2[1:4] # (2, 3, 4) 1.3 Modifying tuples The values in a tuple cannot be modified once they are defined, but we can modify a tuple by linking it to a tuple, e.g.\ntup1 = (\u0026#39;baidu\u0026#39;, \u0026#39;google\u0026#39;,1,2) tup2 = (1, 2, 3, 4, 5, 6, 7) tup1 + tup2 # (\u0026#39;baidu\u0026#39;, \u0026#39;google\u0026#39;, 1, 2, 1, 2, 3, 4, 5, 6, 7) Note: The following modifications to tuples are illegal because tuples do not support modification by index columns, only copy and join operations can be performed on tuples\n**tup1[0] = 100** (this operation cannot be performed)\n1.4 Deleting a tuple Due to the unmodifiable nature of tuples, the values of the elements in a tuple are not allowed to be deleted, but we can use the del statement to delete the entire tuple, as in the following example:\n#! /usr/bin/python3 tup1 = (\u0026#39;baidu\u0026#39;, \u0026#39;google\u0026#39;,1,2) print(tup) del tup print(\u0026#34;deleted tup tup : \u0026#34;) print(tup) # The following error message proves that the entire tuple has been deleted # The deleted tuple tup1 : # Traceback (most recent call last): # File \u0026#34;tuple.py\u0026#34;, line 29, in \u0026lt;module\u0026gt; # print(tup1) # NameError: name \u0026#39;tup1\u0026#39; is not defined 2 Tuple Operators  As with strings, tuples can operate on each other using the + and * signs. This means that they can be combined and copied, and a new tuple is created after the operation. In short, some operations on the whole tuple result in a new tuple.\n2.1 Tuple length To find the length of a tuple, use the operator len, as follows\n# Find the length of the tup1 tuple tup1 = (\u0026#39;baidu\u0026#39;, \u0026#39;google\u0026#39;,1,2) len(tup1) # 4 2.2 Connecting tuples Two or even pairs of tuples are joined using the + conjunction, e.g.\ntup1 = (1,2,3) tup2 = (4,5,6) tup3 = (7,8,9) tup1 + tup2 + tup3 # (1, 2, 3, 4, 5, 6, 7, 8, 9) 2.3 Duplicate tuples tup1 = (\u0026#39;abc\u0026#39;) # The tuple is copied with a separator and the contents copied after it are separated by the separator (tup1,) * 3 # (\u0026#39;abc\u0026#39;, \u0026#39;abc\u0026#39;, \u0026#39;abc\u0026#39;) 2.4 Determining elements Determines whether an element in a tuple exists using the in keyword, and the result returns a Boolean value\ntup1 = \u0026#39;abc\u0026#39; \u0026#39;a\u0026#39; in tup1 # True 2.5 Access to elements at specified positions in a tuple As with sequences, elements in a tuple can likewise be accessed using an index number to access the element at the specified position, e.g.\ncontent = (\u0026#39;hello\u0026#39;,\u0026#39;world\u0026#39;,\u0026#39;!\u0026#39;) content # (\u0026#39;hello\u0026#39;, \u0026#39;world\u0026#39;, \u0026#39;!\u0026#39;) content[1:] # (\u0026#39;world\u0026#39;, \u0026#39;!\u0026#39;) content[:2] # (\u0026#39;hello\u0026#39;, \u0026#39;world\u0026#39;) content[-1] # \u0026#39;!\u0026#39; content[-2] # \u0026#39;world\u0026#39; 3 Tuple Built-In Functions  Like lists, tuples also have some built-in functions to determine the size of the elements in the tuple and to transform the tuple accordingly\n# Count the number of tuple elements. len(tuple) # Return the maximum value of the elements in the tuple. max(tuple) # Return the minimum value of the elements in the tuple. min(tuple) # Convert a list to a tuple. tuple(seq) Summary  This section gives an introduction to the manipulation and use of tuples of Python data structures, and provides support for Python engineers working with lists.\n Reference https://github.com/JustDoPython/python-100-day/tree/master/day-009\n","date":"07 Jul, 2021","image":"images/blog/python.png","permalink":"https://codelink.ai/blog/python/python101-9-tuple/","tags":["learning","python101"],"title":"Python101: 9. Tuple"},{"categories":["python"],"contents":"A data structure in Python is a collection of data elements that are organized in some way, and these data elements can be numbers, characters, or even other data structures.\nIn Python, the most basic data structures are sequences (lists and tuples), where each element in the sequence has a number (the specific location of the element), which is called an index, and the index subscript starts at 0 and so on \u0026hellip;\u0026hellip;\n Lists are commonly known as Python\u0026rsquo;s drudgery, and lists are mutable (you can change the contents of a list) Lists are the most commonly used Python data type, and can appear as a comma-separated value inside square brackets. Data items of a list need not have the same type  To create a list, simply enclose the different data items separated by commas in square brackets. This is shown below.\nlist1 = [\u0026#39;baidu\u0026#39;, \u0026#39;google\u0026#39;, 12, 34] list2 = [1, 2, 3, 4, 5] list3 = [\u0026#34;a\u0026#34;, \u0026#34;b\u0026#34;, \u0026#34;c\u0026#34;, \u0026#34;d\u0026#34; ] 1. list function  1.1 list function If you want to change a value in a string after assigning a value to it, because strings cannot be changed like lists, you can use the list function if you want to change it, as follows.\nll=list(\u0026#39;hello\u0026#39;) ll # [\u0026#39;h\u0026#39;, \u0026#39;e\u0026#39;, \u0026#39;l\u0026#39;, \u0026#39;l\u0026#39;, \u0026#39;o\u0026#39;] ll[2] # \u0026#39;l\u0026#39; ll[2]=\u0026#39;5\u0026#39; ll # [\u0026#39;h\u0026#39;, \u0026#39;e\u0026#39;, \u0026#39;5\u0026#39;, \u0026#39;l\u0026#39;, \u0026#39;o\u0026#39;] Note: The list function works on all types of sequences, not just strings\n1.2 len function The len function returns the number of elements in the list\nlist1 = [\u0026#39;baidu\u0026#39;, \u0026#39;google\u0026#39;, 12, 23] len(list1) # 4 1.3 max function The max function returns the maximum value of the list elements\nlist_num=[2,3,5,6,8,12] max(list_num) # 12 1.4 min function Returns the minimum value of a list element\nlist_num=[2,3,5,6,8,12] min(list_num) # 2 2 List method  The list provides several detailed methods that are used to check or modify the contents of the list\n2.1 append The append method is used to append new content to the end of the list\nlist_append = [1,2,3,4] list_append.append(5) list_append # [1, 2, 3, 4, 5] 2.2 count The count method is used to count the number of times an element appears in the list\nnum = [1, 2, 3, 4, 5, 5, 5, 5, 6] # Count the number of occurrences of 5 in the num list num.count(5) 3 4 # Count the number of times the letter a appears name=[\u0026#39;a\u0026#39;,\u0026#39;a\u0026#39;,\u0026#39;abf\u0026#39;,\u0026#39;ark\u0026#39;,\u0026#39;nhk\u0026#39;] name.count(\u0026#39;a\u0026#39;) # 2 2.3 extend The extend method represents appending, it can append multiple values from another sequence at once at the end of the list, i.e. extending the original list with a new list\na = [1,2,3] b = [4,5,6] # Append list b after list a a.extend(b) a # [1, 2, 3, 4, 5, 6] This operation is the same as the add operation of a list, but the append operation changes the original list, while the add does not change the original list, e.g.\na = [1,2,3] b = [4,5,6] a + b # [1, 2, 3, 4, 5, 6] # The join operation does not change the original list a # [1, 2, 3] 2.4 index The index method is used to find the index position of the first matching position of an element from the list\ncontent = [\u0026#39;where\u0026#39;,\u0026#39;who\u0026#39;,\u0026#39;lisi\u0026#39;,\u0026#39;cntent\u0026#39;,\u0026#39;who\u0026#39;] content.index(\u0026#39;who\u0026#39;) # 1 Note: The above method has \u0026lsquo;who\u0026rsquo; in two positions, but only the first matching index position element is found\n2.5 insert The insert method is used to insert objects into a list\nnum = [1,2,5,6,7] num.insert(2,3) num # [1, 2, 3, 5, 6, 7] num.insert(3,4) num # [1, 2, 3, 4, 5, 6, 7] 2.6 pop The pop method removes an element from the list (the last one by default) and returns the value of that element\nx = [1,2,3] x.pop() # 3 x # [1, 2] x.pop() # 2 x # [1] Note that the pop method is the only method that both modifies the list and returns the element values (except for None), and that the pop and append methods are the stacking and stacking of data structures in Python; if you append the value that just came off the stack (pop), you still get the original list\nx = [1,2,3] x.append(x.pop()) x # [1, 2, 3] 2.7 remove The remove method is used to remove the first matching element from the list\ncontent = [\u0026#39;where\u0026#39;, \u0026#39;who\u0026#39;, \u0026#39;lisi\u0026#39;, \u0026#39;cntent\u0026#39;, \u0026#39;who\u0026#39;, \u0026#39;who\u0026#39;] # Remove the first matching element content.remove(\u0026#39;who\u0026#39;) content # [\u0026#39;where\u0026#39;, \u0026#39;lisi\u0026#39;, \u0026#39;cntent\u0026#39;, \u0026#39;who\u0026#39;, \u0026#39;who\u0026#39;] 2.8 reverse The reverse method reverses the elements of the list\nx = [1, 2, 3] # elements stored in reverse x.reverse() x # [3, 2, 1] 2.9 sort The sort method is used to sort in the original position, \u0026lsquo;sort in original position\u0026rsquo; means to change the original list and let the elements of the list in order\nx = [2,3,5,6,1,4,7] x.sort() x # [1, 2, 3, 4, 5, 6, 7] 2.10 clear The clear method is used to clear the list\nlist1=[\u0026#39;baidu\u0026#39;, \u0026#39;google\u0026#39;, 12, 23] list1 # [\u0026#39;baidu\u0026#39;, \u0026#39;google\u0026#39;, 12, 23] # Clear the contents of the list list1.clear() list1 # [] 2.11 copy The copy method is a copy of the list\nlist1 = [\u0026#39;baidu\u0026#39;, \u0026#39;google\u0026#39;, 12, 23] list1.copy() # [\u0026#39;baidu\u0026#39;, \u0026#39;google\u0026#39;, 12, 23] list2 = list1.copy() list2 # [\u0026#39;baidu\u0026#39;, \u0026#39;google\u0026#39;, 12, 23] 3. List basic operations  Lists can use all the standard operations that apply to sequences, such as indexing, slicing, concatenation, and multiplication that we learned on Day 7. More interestingly, lists can be modified, that is, the contents of the defined list can be changed as needed. This section describes some methods for changing lists: element assignment, element deletion, slice assignment, and list methods (but note that not all list methods can actually change the list)\n3.1 Changing lists: element assignment To assign a value to a specified element in a list, we need to specify a specific index tag to assign a value to a specific, well-positioned element in the list, e.g. x[3]=5\nx=[1,2,3,4,5] x # [1, 2, 3, 4, 5] # Change the content of the fourth element of the list x[3]=5 x # [1, 2, 3, 5, 5] Note: cannot assign a value to an element whose position does not exist, if the length of the list is 2, you cannot assign a value to an element whose index is 10, if you need to assign a value, you need to create a list of length 11.\n3.2 Deleting list elements To delete an element in the list, just use del to delete it\n# Define a list of names of length 4 names=[\u0026#39;zhangsan\u0026#39;,\u0026#39;lisi\u0026#39;,\u0026#39;wangwu\u0026#39;,\u0026#39;zhaoliu\u0026#39;] names # [\u0026#39;zhangsan\u0026#39;, \u0026#39;lisi\u0026#39;, \u0026#39;wangwu\u0026#39;, \u0026#39;zhaoliu\u0026#39;] # Delete the third element del names[2] # Final list length changed from 4 to 3 names # [\u0026#39;zhangsan\u0026#39;, \u0026#39;lisi\u0026#39;, \u0026#39;zhaoliu\u0026#39;] The del statement can also be used to delete other elements and can be used for variable deletion operations.\n3.3 Slice assignment Slicing operations on sequences or lists is a very powerful feature in Python, and slicing assignments can seem even more powerful, e.g.\n# Define a list name = list(\u0026#39;Pyther\u0026#39;) # Change the last two values in the list name[4:]=\u0026#39;on\u0026#39; name # [\u0026#39;p\u0026#39;, \u0026#39;y\u0026#39;, \u0026#39;t\u0026#39;, \u0026#39;h\u0026#39;, \u0026#39;o\u0026#39;, \u0026#39;n\u0026#39;] From the above, it can be seen that the program can assign values to more than one element at a time, and when assigning values in pieces, the pieces can be replaced with sequences that are not equal in length to the original sequence, e.g.\nname_re = list(\u0026#39;perl\u0026#39;) name_re # [\u0026#39;p\u0026#39;, \u0026#39;e\u0026#39;, \u0026#39;r\u0026#39;, \u0026#39;l\u0026#39;] # Piecewise replacement name_re[1:] = list(\u0026#39;ython\u0026#39;) name_re # [\u0026#39;p\u0026#39;, \u0026#39;y\u0026#39;, \u0026#39;t\u0026#39;, \u0026#39;h\u0026#39;, \u0026#39;o\u0026#39;, \u0026#39;n\u0026#39;] Slice assignment also allows new elements to be inserted without changing anything in the original list\nnum = [1,4,5] # Insert a new element after the first one num[1:1]=[2,3] num # [1, 2, 3, 4, 5] Similarly, you can also delete elements in the list by slicing, which also supports negative slicing\nnum = [1, 2, 3, 4, 5] # Assign an empty sequence to the slice between the first and disan element, i.e. delete the element num[1:3] = [] num # [1, 4, 5] # Negative slicing operation num[-1:-1] = [5,5,5] num # [1, 2, 3, 4, 5, 5, 5, 5] Summary  This section introduces you to the manipulation and use of Python data structures, and provides support for Python engineers working with lists.\n Reference\nhttps://github.com/JustDoPython/python-100-day/tree/master/day-008\n","date":"06 Jul, 2021","image":"images/blog/python.png","permalink":"https://codelink.ai/blog/python/python101-8-list/","tags":["learning","python101"],"title":"Python101: 8. List"},{"categories":["python"],"contents":"A data structure in Python is a collection of data elements that are organized in some way, and these data elements can be numbers, characters, or even other data structures.\nIn Python, the most basic data structures are sequences (lists and tuples), where each element in a sequence has a serial number (the specific location of the element), which is called an index, and the index subscript starts at 0, and so on \u0026hellip;\u0026hellip; This article focuses on sequences in Python and their practical applications.\n Sequences Overview   There are six kinds of built-in sequences in Python. Of these, lists and tuples are the most common types. The others include strings, Unicode strings, buffer objects, and xrange objects. The main difference between lists and tuples is that lists can be modified while tuples can\u0026rsquo;t. If you want to add elements on demand, then lists are better suited, but when sequences can\u0026rsquo;t be modified, using tuples is more appropriate, and using tuples is related to the way Python works. Lists can replace tuples in almost all cases in Python, but not in special cases (when using a tuple as an unmodifiable key for a dictionary, the key cannot be modified, so you can\u0026rsquo;t use a list)  For example.\n# Define a sequence of students stuinfo=[\u0026#39;zhangsan\u0026#39;, \u0026#39;lisi\u0026#39;, \u0026#39;wangwu\u0026#39;, 18, 20] Also the sequence can contain sequences, for example database: database\n# Define student name and student age, then define a database of your own to add the two lists to stuname=[\u0026#39;zhangsan\u0026#39;,\u0026#39;lisi\u0026#39;,\u0026#39;wangwu\u0026#39;] stuage=[18,20,16] database=[stuname,stuage] database # [[\u0026#39;zhangsan\u0026#39;, \u0026#39;lisi\u0026#39;, \u0026#39;wangwu\u0026#39;], [18, 20, 16]] Note: Python also has a data structure called a container, which can contain any other object; containers consist of two main categories: sequences and mappings (e.g., dictionaries). Each element of a sequence has its own number, while each element of a map has a name called a \u0026ldquo;key\u0026rdquo;. Collections are another type of container (more on this in a later section).\nGeneral Sequence Operations All sequence types in Python can perform some specific operations, including indexing, slicing, adding, multiplying, and checking whether an element is a member of a sequence \u0026ndash;\u0026gt; membership testing.\nIn addition, Python has built-in functions for calculating the length of a sequence and finding the largest and smallest elements.\n1. Indexing All elements in a sequence are numbered, and these numbers start from 0 and increase in order. Accessing these elements is done by subscripts, and this number is the index, e.g.\ndatabase[0] # [\u0026#39;zhangsan\u0026#39;, \u0026#39;lisi\u0026#39;, \u0026#39;wangwu\u0026#39;] database[1] # [18, 20, 16] # index of string sequence str=\u0026#39;hello\u0026#39; str[0] # \u0026#39;h\u0026#39; str[1] # \u0026#39;e\u0026#39; Note: A string is a sequence of characters with index 0 pointing to the first element This is the index above, all sequences can be indexed by way of element numbering, when using negative indexes, Python will do all from right to left, -1 is from the last element of the sequence, as follows.\n# Start with the last element str[-1] # \u0026#39;o\u0026#39; # Start from the penultimate element str[-2] # \u0026#39;l\u0026#39; 2. Slicing Again similar to indexing, slicing is a colon operation to access elements within a certain range, e.g.\n# Construct a sequence tag containing an element tag=[\u0026#39;https://www.cnblogs.com/yangyuqig/p/10101663.html\u0026#39;] # Get this element and take out a range of values by slicing tag[0][0:24] # \u0026#39;https://www.cnblogs.com/\u0026#39; As known above, the implementation of the slice operation needs to provide two indexes as boundaries, a left-closed-right-open interval, i.e. the 1st index is contained within the slice, while the 2nd index is not contained within this slice, e.g.\nnum=[1,2,3,4,5,6,7,8,9,10] # means from the fourth to the last element num[3:10] # [4, 5, 6, 7, 8, 9, 10] In addition to the above scheme, it is also possible to operate by displaying\n2.1 Slice shortcut operations num[0:3] # Fetch the first 3 data # [1, 2, 3] 2.2 Slicing step operations A slice operation can set a step to an element, specifying the corresponding step to fetch the element at the beginning and end, e.g.\n# return the element between the 1st and 6th by step 2 num[0:6:2] # [1, 3, 5] Another thing to note is that the negative step traverses the entire sequence from the end of the element to the front, so the start index of the negative slice must be greater than the end index\nnum[7:-1] # [8, 9] When the start index and end index are negative start so must be less than the end index.\nnum[-9:-1] # [2, 3, 4, 5, 6, 7, 8, 9] For a positive step, Python will extract the elements from the head of the sequence to the right, straight to the last element, while for a negative step, it will extract the elements from the tail of the sequence to the left, straight to the first, e.g.:\n# Extract the first 6 elements in steps of 2 num[:6:2] # [1, 3, 5] # Extracts the first 8 elements from back to front in steps of 2 num[:2:-2] # [10, 8, 6, 4] 3. Sequence summation Sequence summation performs a concatenation operation between sequences and sequences by means of the plus sign \u0026ldquo;+\u0026rdquo;.\n\u0026#39;hello\u0026#39;+\u0026#39; world ! # \u0026#39;hello world !\u0026#39; [1,2,3]+[\u0026#39;zhangsan\u0026#39;,\u0026#39;lisi\u0026#39;,\u0026#39;wangwu\u0026#39;] # [1, 2, 3, \u0026#39;zhangsan\u0026#39;, \u0026#39;lisi\u0026#39;, \u0026#39;wangwu\u0026#39;] Note: Only sequences of the same type can be concatenated\n4. Sequence multiplication A number x multiplied by a sequence will produce a new sequence, the original sequence will be reset to x times\n[\u0026#39;hello\u0026#39;+\u0026#39; world !\u0026#39;] *3 # [\u0026#39;hello world ! , \u0026#39;hello world ! , \u0026#39;hello world !\u0026#39;] 5. Membership Checking whether an element is in a sequence is done using the operator in. The in operator returns a boolean value that checks for a condition and returns true if it is true, otherwise it returns false, e.g.\nstr=\u0026#39;hello\u0026#39; \u0026#39;h\u0026#39; in str # True \u0026#39;x\u0026#39; in str # False 6. Sequence length, maximum and minimum values The sequence length, maximum and minimum values are checked using the built-in functions len, max and min. len returns the number of elements contained in the sequence, max and min return the maximum and minimum elements of the sequence, respectively\nlen([11,34,23]) # 3 max(11,34,23) # 34 min(11,34,23) # 11 Summary  This section gives you an introduction to the use of Python data structures of sequences, which provides support for Python engineers to use to take out the corresponding elements in practical applications in their projects.\n Reference\nhttps://github.com/JustDoPython/python-100-day/tree/master/day-007\n","date":"05 Jul, 2021","image":"images/blog/python.png","permalink":"https://codelink.ai/blog/python/python101-7-data-structures-and-sequences/","tags":["learning","python101"],"title":"Python101: 7. Data Structures and Sequences"},{"categories":["python"],"contents":"Modules and packages are the core of any large program, and even the Python installer itself is a package.\nFocuses on common programming techniques related to modules and packages, such as how to organize packages, splitting large modules into multiple files, and creating namespace packages. Also gives tips for letting you customize your import statements.\nLet\u0026rsquo;s start by explaining the concept between modules, packages and libraries.\n A module is a py file that defines functions, classes, variables, etc. package is a folder formed by aggregating multiple modules, which can be multiple py files, or nested folders Libraries are a reference to other programming languages, and are collections of code that perform certain functions, which in Python take the form of modules and packages  A module is actually a py file that encapsulates a set of functions; a package is a class of modules grouped together, and is a bit larger than the concept of a module; a library is a group of functions encapsulated by other programmers, and is generally a bit larger than the concept of a package.\nLet\u0026rsquo;s separate the following.\nModule  From the above, we know that a module is a py file, a text file that stores a set of functions that we can use again to improve the reuse of code. We call this a py file a Python module. In other Python scripts, the defined Python module is loaded by import.\nDefine and call Python modules Let\u0026rsquo;s start by looking at how to define a Python module.\nDefine a hello.py module with the following content.\ndef sayhello( ): print(\u0026#34;Hello World!\u0026#34;) Usually we use the import statement to introduce modules with the following syntax.\nimport module1[, module2[,... moduleN]] When the interpreter encounters an import statement, the module will be imported if it is in the current search path. The call is made using module name. function name to make the call\nIn the above example, we create a new do.py file to call the methods in the hello.py module.\nThe do.py file reads as follows.\n# Import modules import hello # The functions included in the module can now be called hello.sayhello()  A module will only be imported once, no matter how many times you import it. this prevents the imported module from being executed over and over again.\n Execute the shortcut ctrl+b on the do.py page and the console outputs: Hello World!\nThis is an example of a module definition and call, is not also very simple.\nfrom \u0026hellip; import \u0026hellip; Modules provide namespace-like restrictions that allow Python to import specified symbols (variables, functions, classes, etc.) from a module into the current module. Once imported, these symbols can be used directly without prefixing the module name.\nThe syntax is as follows.\nfrom modname import name1[, name2[, ... nameN]] For example, to import the sayhello function of the module hello, use the following statement.\n## Direct import method from hello import sayhello sayhello() from \u0026hellip; import * statement\nIt is also possible to import all the content of a module into the current namespace, simply by using the following declaration.\nfrom modname import * This provides an easy way to import all items in a module.\nWe add another world method to hello.py.\ndef world(): print(\u0026#34;Python World!\u0026#34;) Introduce all the methods to be called in the do.py file.\n## Import all methods from hello import * sayhello() world() Output after execution.\nHello World! Python World! This proves that both methods in the hello module can be called directly and are not recommended to be used too much in real projects.\nPackage  A package is a higher-level abstraction of a module in Python. Simply put, Python allows users to treat directories as modules. In this way, the different module files in a directory become submodules within a \u0026ldquo;package\u0026rdquo;. In addition, package directories can have subdirectories under them, and those subdirectories can also be Python packages. This kind of hierarchy is very beneficial for module identification and management.\nIn particular, for some large Python toolkits, there can be hundreds or thousands of modules with different functions inside. In scientific computing, third-party tools such as SciPy, NumPy, Matplotlib, etc., are distributed in packages.\nPackage Definition Common package structures are as follows.\npakageName -------__init__.py -------moduleName1.py -------moduleName2.py ------- ... The __init__.py file must exist under the package path.\nExample.\nWe create a package of cal with a model of the calculator with the following structure.\ncal -------__init__.py -------calculator.py The code for the calculator.py module is as follows.\ndef add(a,b) : return a+b def reduce(a,b) : return a-b def multiply(a,b) : return a*b def divide(a,b) : return a/b Using Python packages The use of Python packages is similar to the use of modules, and the following is the syntax for importing them.\nimport package name. Package name. Module name For example, we import calculator.py in do.py\n# Import package import cal.calculator # Methods for modules that use the package print(cal.calculator.add(1,2)) But the import call has a long registration, so you can use from ... import ...  statement to simplify things a bit.\n# Import package from cal import calculator # Use the methods of the package\u0026#39;s module print(calculator.multiply(3,6)) The effect will also be better when the package name is getting longer.\nSummary  This section introduces you to the use of Python modules and packages, which provide support for Python engineers. The proper use of modules and packages can constantly improve the efficiency of your code and allow for more standardized calls throughout your project.\n Reference\nhttps://liam.page/2017/07/23/modules-and-packages-of-python/ https://github.com/JustDoPython/python-100-day/tree/master/day-006\n","date":"04 Jul, 2021","image":"images/blog/python.png","permalink":"https://codelink.ai/blog/python/python101-6-modules-and-packages/","tags":["learning","python101"],"title":"Python101: 6. Modules and Packages"},{"categories":["python"],"contents":"Functions are organized, reusable segments of code used to implement a single, or associated, function, so I often say that functions are the basis for their use at programmer scale.\nFunctions can improve the modularity of applications, and code reuse. In the program design, often some common functional modules written as a function, placed in the function library for public choice. Good use of functions can reduce the workload of repeatedly writing program segments.\nHow to define a function  There are several steps to define a function as follows\n The function code block starts with the def keyword followed by the function identifier name and parentheses (). Any incoming arguments and independent variables must be placed between the parentheses. Round brackets can be used between them to define parameters. The first line of a function may optionally use a document string - to hold the function description. The content of the function starts with a colon and is indented. return [expression] ends the function, optionally returning a value to the caller. A return without an expression is equivalent to returning None.  Syntax\ndef function name (list of arguments): Function body By default, parameter values and parameter names are matched up in the order they are defined in the function declaration.\nSimple example  An example of the simplest function.\n# Define a function def hello() : print(\u0026#34;Hello World!\u0026#34;) # Call the function hello() One more example of substitution of parameters.\n# Define a function def helloN(name) : print(\u0026#34;Hello World!\u0026#34;, name) # call function helloN(\u0026#39;neo\u0026#39;) Addition, subtraction, multiplication and division examples  We use functions to implement a basic addition, subtraction, multiplication and division operation.\n# Define the function def add(a,b) : return a+b def reduce(a,b) : return a-b def multiply(a,b) : return a*b def divide(a,b) : return a/b # Call the function print(add(1,2)) print(reduce(12,2)) print(multiply(6,3)) print(divide(12,6)) It was found that defining functions allows for multiple reuse of code.\nMultiple return values  In some cases, we need a function to return multiple values, and Python supports that as well.\n# Define multiple return value functions def more(x, y): nx = x + 2 ny = y - 2 return nx, ny # Call the function x, y = more(10, 10) print(x, y) Recursive functions  Sometimes we need to call a function repeatedly to get a final value, and using recursive functions is the best solution.\nProgramming language, the function Func (Type a,\u0026hellip;\u0026hellip;) directly or indirectly call the function itself, then the function is called recursive function. Recursive functions cannot be defined as inline functions\nAs an example, let\u0026rsquo;s calculate the factorial n! = 1 x 2 x 3 x ... x n, expressed as a function fact(n), it can be shown that\nfact(n) = n! = 1 x 2 x 3 x ... x (n-1) x n = (n-1)! x n = fact(n-1) x n Therefore, fact(n) can be expressed as n x fact(n-1), and only n=1 requires special treatment.\nThus, fact(n) is written out recursively as\ndef fact(n): if n==1: return 1 return n * fact(n - 1) This completes the definition of a recursive function.\nLet\u0026rsquo;s try to call what the factorial of 6 is, by calling\nprint(fact(6)) # Output content # 720 Similar needs can be implemented in this way.\nSummary  This section gives you an introduction to using Python functions.\n Reference\nhttps://www.runoob.com/python/python-functions.html https://www.liaoxuefeng.com/wiki/1016959663602400/1017105145133280 https://github.com/JustDoPython/python-100-day/tree/master/day-005\n","date":"03 Jul, 2021","image":"images/blog/python.png","permalink":"https://codelink.ai/blog/python/python101-5-functions/","tags":["learning","python101"],"title":"Python101: 5. Functions"},{"categories":["python"],"contents":" In the world of programming, flow control is the foundation on which programmers operate. Flow control determines the way in which programs are executed, and this section gives you an introduction to Python flow control-related syntax.\nif statement  The if statement indicates how what condition occurs and what logic is executed.\nSyntax\nif Judgment condition. Execute the statement ...... else. Execute the statement ...... Example.\n# x = int(input(\u0026#34;Please enter an integer: \u0026#34;)) x = -5 if x \u0026lt; 0: x = 0 print(\u0026#39;Negative changed to zero\u0026#39;) elif x == 0: print(\u0026#39;Zero\u0026#39;) elif x == 1: print(\u0026#39;Single\u0026#39;) else: print(\u0026#39;More\u0026#39;) There may be zero to multiple elif sections, and else is optional. The keyword \u0026lsquo;elif\u0026rsquo; is an abbreviation for \u0026lsquo;else if\u0026rsquo;, which effectively avoids excessive indentation. if \u0026hellip; elif \u0026hellip; elif \u0026hellip; sequence is used in place of switch or case statements in other languages.\nfor loop  Python for loops can iterate over any sequence of items, such as a list or a string.\nThe syntax format of the for loop is as follows:\n\u0026#39;\u0026#39;\u0026#39; for followed by the variable name, in followed by the sequence, note the colon The for loop takes one value at a time from the sequence and puts it into the variable The sequence here is mainly a list, a tuple, a string, a file \u0026#39;\u0026#39;\u0026#39; for iterating_var in sequence: statements(s) Examples are as follows:\nfor letter in \u0026#39;Python\u0026#39;: # First example print(\u0026#39;Current letter :\u0026#39;, letter) fruits = [\u0026#39;banana\u0026#39;, \u0026#39;apple\u0026#39;, \u0026#39;mango\u0026#39;] for fruit in fruits: # Second instance print(\u0026#39;Current letter :\u0026#39;, fruit) print(\u0026#34;Good bye!\u0026#34;) It is also possible to traverse the content by indexing the address\nfruits = [\u0026#39;banana\u0026#39;, \u0026#39;apple\u0026#39;, \u0026#39;mango\u0026#39;] for index in range(len(fruits)): print(\u0026#39;Current fruit :\u0026#39;, fruits[index]) print(\u0026#34;Good bye!\u0026#34;) while loop  The while statement in Python programming is used to loop through a program, that is, to loop through a program under a certain condition in order to handle the same task that needs to be repeated. Its basic form is.\nSyntax\nwhile Judgment condition. Execute the statement ...... Example.\ncount = 0 while (count \u0026lt; 9): print( \u0026#39;The count is:\u0026#39;, count) count = count + 1 print(\u0026#34;Good bye!\u0026#34;) You can also add judgment logic to the while loop\ncount = 0 while count \u0026lt; 5: print(count, \u0026#34; is less than 6\u0026#34;) count = count + 1 else: print(count, \u0026#34; is not less than 6\u0026#34;) range() function  If you need a sequence of values, the built-in range() function comes in handy, which generates a chain of equivalence series:\nSyntax\nrange (start, end, scan): Meaning of parameters.\n start: Count starts from start. The default is to start from 0. For example, range(5) is equivalent to range(0, 5); end: The count ends at end, but not including end. e.g. range(0, 5) is [0, 1, 2, 3, 4] without 5 scan: The spacing of each jump, default is 1. e.g. range(0, 5) is equivalent to range(0, 5, 1)  Example\nfor i in range(6): print(i) print(range(6),\u0026#39;finish\u0026#39;) for i in range(6,10): print(i) print(range(6,10),\u0026#39;finish\u0026#39;) for i in range(6,12,2): print(i) print(range(6,12,2),\u0026#39;finish\u0026#39;) If you need to iterate over the chain index, use a combination of range() and len() as shown below:\na = [\u0026#39;i\u0026#39;, \u0026#39;love\u0026#39;, \u0026#39;coding\u0026#39;, \u0026#39;and\u0026#39;, \u0026#39;free\u0026#39;] for i in range(len(a)): print(i, a[i]) break Usage  The break statement allows you to jump out of the for and while loop bodies. If you terminate from a for or while loop, any corresponding else block of the loop will not be executed.\nExample\nfor letter in \u0026#39;ityouknow\u0026#39;: # First instance if letter == \u0026#39;n\u0026#39;: # Break when letter is n break print (\u0026#39;Current letter :\u0026#39;, letter) continue Usage  The continue statement is used to skip the remaining statements in the current loop block and then continue to the next round of loops.\nExample\nfor letter in \u0026#39;ityouknow\u0026#39;: # First instance if letter == \u0026#39;n\u0026#39;: # Skip output when letter is n continue print (\u0026#39;Current letter :\u0026#39;, letter) pass statement  Python pass is an empty statement, designed to preserve the structural integrity of the program. It is used when something is syntactically necessary, but the program doesn\u0026rsquo;t do anything.\nExample\nwhile True: pass # Busy-wait for keyboard interrupt (Ctrl+C) # This is usually used to create minimally structured classes: class MyEmptyClass: pass Summary  This section gives you an introduction to the flow control-related syntax of Python, which facilitates conditional control in code logic later on.\n Reference\nhttp://www.pythondoc.com/pythontutorial3 https://www.runoob.com/python3/python3-tutorial.html https://github.com/JustDoPython/python-100-day/tree/master/day-004\n","date":"02 Jul, 2021","image":"images/blog/python.png","permalink":"https://codelink.ai/blog/python/python101-4-flow-control/","tags":["learning","python101"],"title":"Python101: 4. Flow Control"},{"categories":["python"],"contents":" In this article we will learn about Python variables and data types.\nVariables  Variables come from mathematics, and are abstract concepts in computer languages that can store the results of calculations or represent values, and can be accessed by variable names. In Python, variable names must be a combination of upper and lower case English, numbers, and underscores (_), and cannot begin with a number.\nVariable naming rules:\n Variable names can only be any combination of letters, numbers and underscores The first character of the variable name cannot be a number Variable names are case-sensitive, upper and lower case letters are considered to be two different characters Special keywords cannot be named as variable names  Declare variables\nVariables in Python do not need to be declared; each variable must be assigned a value before it can be used, and the variable is not created until it is assigned a value. In Python, a variable is a variable; it has no type, and what we mean by \u0026ldquo;type\u0026rdquo; is the type of the object in memory to which the variable refers.\nname = \u0026#34;neo\u0026#34; The above code declares a variable named: name, with the value of \u0026ldquo;neo\u0026rdquo;.\nVariable assignment\nIn Python, the equal sign = is an assignment statement that allows you to assign any data type to a variable, and the same variable can be assigned repeatedly, and can be of different types.\na = 123 # a is an integer a = \u0026#39;abc\u0026#39; # a is a string Such languages where the variables themselves are not of a fixed type are called dynamic languages, and their counterparts are static languages. Static languages must specify the type of the variable when defining the variable, and if the type does not match when assigning the value, an error will be reported. For example, if Java is a static language, the assignment will result in the following error.\nMultiple variable assignment\nPython allows you to assign values to multiple variables at the same time. For example.\na = b = c = 1 In the above example, an integer object is created with a value of 1. Assigning the value from back to front, the three variables are given the same value.\nYou can also specify multiple variables for multiple objects. For example.\na, b, c = 1, 2, \u0026#34;neo\u0026#34; In the above example, the two integer objects 1 and 2 are assigned to variables a and b, and the string object \u0026ldquo;neo\u0026rdquo; is assigned to variable c.\nConstant\nA constant is a variable that cannot change, such as the common mathematical constant œÄ, which is a constant. In Python, constants are usually represented by all-caps variable names.\nBI = 3.14 But the fact is that BI is still a variable, and Python can\u0026rsquo;t guarantee that BI won\u0026rsquo;t be changed at all, so using all-caps variable names for constants is just a convention, and the syntax won\u0026rsquo;t report an error if you have to change it.\nData Type  There are six standard data types in Python3: Number, String, List, Tuple, Sets, and Dictionary.\nOf Python3\u0026rsquo;s six standard data types:\n Immutable data (3): Number (number), String (string), Tuple (tuple). Variable data (3): List (list), Dictionary (dictionary), Set (collection).  We describe the use of each of these data types below.\nNumber Python3 supports int, float, bool, and complex (plural).\nThe numeric type is, as the name implies, used to store numeric values, and it is important to remember that, somewhat similar to Java\u0026rsquo;s string flavor, if the value of a numeric data type is changed, memory space will be reallocated.\nPython supports three different types of values.\n Integer (int) - commonly referred to as an integer or integer, a positive or negative integer without a decimal point. python3 integers are not limited in size and can be used as Long types, so Python3 does not have the Python2 Long type. Float (float) - a floating-point type consists of an integer part and a fractional part; floats can also be expressed in scientific notation (2.5e2 = 2.5 x 102 = 250) Complex (complex) - complex numbers consist of a real part and an imaginary part, and can be represented as a + bj, or complex(a,b), where both the real part a and the imaginary part b of the complex number are floating point.  Example.\n#! /usr/bin/python3 counter = 100 # Integer variable miles = 1000.0 # Floating-point variable name = \u0026#34;test\u0026#34; # String print (counter) print (miles) print (name) Numeric Type Conversion\n int(x) Converts x to an integer. float(x) converts x to a floating point number. complex(x) converts x to a complex number, with the real part being x and the imaginary part being 0. complex(x, y) converts x and y to a complex number, with the real part being x and the imaginary part being y. x and y are numeric expressions. Additional notes  Like other languages, numeric types support a variety of common operations, but Python\u0026rsquo;s operations are richer than those of most other common languages, and there are a large number of rich methods that provide more efficient development.\nExamples of numerical operations.\nprint(5 + 4) # add Output 9 print(4.3 - 2) # Subtract Output 2.3 print(3 * 7) # Multiply Output 21 print(2 / 4) # Divide to get a floating point number Output 0.5 print(2 // 4) # Divide to get an integer Output 0 print(17 % 3) # Divide and output 2 print(2 ** 5) # Multiply by the square Output 32 String Creating strings can use single quotes, double quotes, triple single quotes, and triple double quotes, where triple quotes can define strings on multiple lines. Python does not support single character types, and single characters are also used as a string in Python as well.\nWe define an s=\u0026lsquo;python\u0026rsquo; statement, which is executed in the computer by first creating a string Python in memory, creating a variable s in the program stack register, and finally assigning the address of Python to s.\nTo look at some more common operations on strings.\ns = \u0026#39;Learn Python\u0026#39; # slice s[0], s[-1], s[3:], s[::-1] # \u0026#39;Yu\u0026#39;, \u0026#39;n\u0026#39;, \u0026#39;Python\u0026#39;, \u0026#39;nohtyP\u0026#39;s YaYu\u0026#39; # replace, you can also use regular expressions to replace s.replace(\u0026#39;Python\u0026#39;, \u0026#39;Java\u0026#39;) # \u0026#39;Learn Java\u0026#39; # find, find(), index(), rfind(), rindex() s.find(\u0026#39;P\u0026#39;) # 3, returns the subscript of the first occurrence of the substring s.find(\u0026#39;h\u0026#39;, 2) # 6, set the subscript 2 to start the search s.find(\u0026#39;23333\u0026#39;) # -1, return -1 if not found s.index(\u0026#39;y\u0026#39;) # 4, return the subscript of the first occurrence of the substring s.index(\u0026#39;P\u0026#39;) # different from find(), throws exception if not found # case-sensitive, upper(), lower(), swapcase(), capitalize(), istitle(), isupper(), islower() s.upper() # \u0026#39;learn PYTHON\u0026#39; s.swapcase() # \u0026#39;learn pYTHON\u0026#39;, case swapping s.istitle() # True s.islower() # False # remove spaces, strip(), lstrip(), rstrip() # Formatting s1 = \u0026#39;%s%s\u0026#39; % (\u0026#39;Windrivder\u0026#39;, 21) # \u0026#39;Windrivder 21\u0026#39; s2 = \u0026#39;{}, {}\u0026#39;.format(21, \u0026#39;Windridver\u0026#39;) # recommended formatting string s3 = \u0026#39;{0}, {1}, {0}\u0026#39;.format(\u0026#39;Windrivder\u0026#39;, 21) s4 = \u0026#39;{name}: {age}\u0026#39;.format(age=21, name=\u0026#39;Windrivder\u0026#39;) # joins and splits, using + to join strings, each operation will recalculate, open and free memory, which is inefficient, so it is recommended to use joins l = [\u0026#39;2017\u0026#39;, \u0026#39;03\u0026#39;, \u0026#39;29\u0026#39;, \u0026#39;22:00\u0026#39;] s5 = \u0026#39;-\u0026#39;.join(l) # \u0026#39;2017-03-29-22:00\u0026#39; s6 = s5.split(\u0026#39;-\u0026#39;) # [\u0026#39;2017\u0026#39;, \u0026#39;03\u0026#39;, \u0026#39;29\u0026#39;, \u0026#39;22:00\u0026#39;] These are some common operations.\nAnother thing to keep in mind is string encoding. All Python strings are Unicode strings, so when you need to save a file to a peripheral or transfer it over the network, you need to perform an encoding conversion, converting characters to bytes for efficiency.\n# encode Converts characters to bytes str = \u0026#39;Learn Python\u0026#39; print (str.encode()) # The default encoding is UTF-8 Output: b\u0026#39;\\xe5\\xad\\xa6\\xe4\\xb9\\xa0Python\u0026#39; print (str.encode(\u0026#39;gbk\u0026#39;)) # output b\u0026#39;\\xd1\\xa7\\xcf\\xb0Python\u0026#39; # decode converts bytes to characters print (str.encode().decode(\u0026#39;utf8\u0026#39;)) # output \u0026#39;Learn Python\u0026#39; print (str.encode(\u0026#39;gbk\u0026#39;).decode(\u0026#39;gbk\u0026#39;)) # output \u0026#39;Learn Python\u0026#39; List  Java List-like collection interface\n Lists are lists of elements written between square brackets [], separated by commas, and can be implemented as data structures for most collection classes. The elements of a list can be of different types, it supports numbers, strings and even contains lists (so-called nesting), and the elements of a list are changeable.\nExample.\nWeekday = [\u0026#39;Monday\u0026#39;,\u0026#39;Tuesday\u0026#39;,\u0026#39;Wednesday\u0026#39;,\u0026#39;Thursday\u0026#39;,\u0026#39;Friday\u0026#39;] print(Weekday[0]) # Output Monday #list Search print(Weekday.index(\u0026#34;Wednesday\u0026#34;)) #list add elements Weekday.append(\u0026#34;new\u0026#34;) print(Weekday) # list Delete Weekday.remove(\u0026#34;Thursday\u0026#34;) print(Weekday) Tuple (tuple) A tuple is similar to a list, except that the elements of a tuple cannot be modified. The tuple is written in parentheses (), the elements are separated by commas, and the elements in the group can be of different types.\nExample.\nletters = (\u0026#39;a\u0026#39;,\u0026#39;b\u0026#39;,\u0026#39;c\u0026#39;,\u0026#39;d\u0026#39;,\u0026#39;e\u0026#39;,\u0026#39;f\u0026#39;,\u0026#39;g\u0026#39;) print(letters[0]) # Output \u0026#39;a\u0026#39; print(letters[0:3]) # Output a set (\u0026#39;a\u0026#39;, \u0026#39;b\u0026#39;, \u0026#39;c\u0026#39;) Sets (collections)  Java Set-like collection interface\n A set is an unordered sequence of unduplicated elements, created using curly braces {} or the set() function.\nSets cannot be sliced or indexed, except for set operations, and set elements can be added and deleted.\nExample.\na_set = {1,2,3,4} # Add a_set.add(5) print(a_set) # output {1, 2, 3, 4, 5} # Delete a_set.discard(5) print(a_set) # output {1, 2, 3, 4} Dictionary  Java Map-like collection interface\n A dictionary is a mapping type whose elements are key-value pairs, and the keywords of a dictionary must be immutable types and cannot be duplicated. To create an empty dictionary use {} .\nExample.\nLogo_code = { \u0026#39;BIDU\u0026#39;:\u0026#39;Baidu\u0026#39;, \u0026#39;SINA\u0026#39;:\u0026#39;Sina\u0026#39;, \u0026#39;YOKU\u0026#39;:\u0026#39;Youku\u0026#39; } print(Logo_code) # Output {\u0026#39;BIDU\u0026#39;: \u0026#39;Baidu\u0026#39;, \u0026#39;YOKU\u0026#39;: \u0026#39;Youku\u0026#39;, \u0026#39;SINA\u0026#39;: \u0026#39;Sina\u0026#39; } print (Logo_code[\u0026#39;SINA\u0026#39;]) # Output the value of the key \u0026#39;one\u0026#39; print (Logo_code.keys()) # Output all keys print (Logo_code.values()) # Output all values print (len(Logo_code)) # Output the length of the field Summary  This section introduces you to Python variables and the six standard data types, showing you the use of variables and the common operations of the six standard data types.\n Reference:\nhttps://www.cnblogs.com/wang-yc/articles/6423951.html https://segmentfault.com/a/1190000014511963 https://www.runoob.com/python3/python3-data-type.html https://zhuanlan.zhihu.com/p/26079855 https://github.com/JustDoPython/python-100-day/tree/master/day-003\n","date":"01 Jul, 2021","image":"images/blog/python.png","permalink":"https://codelink.ai/blog/python/python101-3-variables-and-data-types/","tags":["learning","python101"],"title":"Python101: 3. Variables and Data Types"},{"categories":["python"],"contents":" Python is a scripting language.\nA scripting language is a special language between HTML and programming languages such as Java, Visual Basic, C++, etc. Although it is closer to the latter, it does not have the complex and rigorous syntax and rules of programming languages. Some scripting languages have evolved, such as Python, and perl can be compiled into intermediate code and then executed, so that they can be called compiled scripting languages.\nThe \u0026ldquo;advantage\u0026rdquo; of scripting languages is that they don\u0026rsquo;t need to be \u0026ldquo;compiled\u0026rdquo; beforehand. So instead of having to compile and then run the language like Java or C++, a scripting language can just read a text file and execute it as it is interpreted.\nPython is a unique scripting language, and a quick overview of its main points are.\n Object-Oriented: Every variable is a class, with its own attribute and method. Syntax blocks: indentation (four spaces) rather than semicolons, brackets, and other symbols are used to mark them. Therefore, spaces at the beginning of lines cannot be written arbitrarily. Comments: in-line \u0026ldquo;#\u0026rdquo; signs are used, and inter-line comments are written between two consecutive sets of three single quotes: ''' Continuation: enter a backslash plus a space ('\\ \u0026lsquo;) at the end of the line, then a line break. If the syntax at the end of the line is obviously unfinished (for example, ending with a comma), you can just continue the line. print and input: functions print() and input(), note the sep and end arguments to print(). Variables: No need to specify variable types or declare variables in advance. Delete variable: del() Copy variable: Assign variable a to b directly, sometimes just copying a \u0026ldquo;reference\u0026rdquo;. Changes to b and a will still affect each other afterwards. Use a is b to determine if it is the same address if necessary. Module: Load the module by import pandas (or import pandas as pd) and call the methods in the module with something like pandas.DataFrame (or pd.DataFrame). You can also use from pandas import DataFrame so that you can use DataFrame directly as the call name in the following. help: Use the dir() and help() commands together; the former outputs all members of a variable.  Python Identifiers  An identifier is a collection of valid strings that are allowed as names in a computer language. Some of these are keywords, which form the identifiers of the language. Such identifiers cannot be used as identifiers for other purposes, or they will cause syntax errors (SyntaxError exceptions).\nA legal Python identifier needs to adhere to the following rules.\n The first character must be a letter or an underscore (_) The remaining characters can be letters and numbers or underscores Case-sensitive They cannot be Python keywords, such as def, class, or any other identifier  Identifiers that begin with an underscore have a special meaning. A single underscore _foo represents a class attribute that cannot be accessed directly, but must be accessed through the interface provided by the class, and cannot be imported using from xxx import *.\n__foo starting with a double underscore represents a private member of a class, and __foo__ starting and ending with a double underscore represents a special method-specific identifier in Python, such as __init__() for a class constructor.\nPython can display multiple statements on the same line by separating them with a semicolon ;, e.g.\nprint(\u0026#34;hello\u0026#34;);print(\u0026#34;world\u0026#34;) # hello # world Python keywords  The following list shows the reserved words in Python. These reserved words cannot be used as constants or variables, or any other identifier names.\nAll Python keywords contain only lowercase letters.\n   and exec not     assert finally or   break for pass   class from print   continue global raise   def if return   del import try   elif in while   else is with   except lambda yield    Indentation  Python is known for its \u0026lsquo;elegance and simplicity\u0026rsquo;, and one of the most important reasons for this is its \u0026lsquo;indentation\u0026rsquo;.\nWhile most programming languages use \u0026ldquo;{}\u0026rdquo; to represent a block of statements or code segments, Python uses an indentation hierarchy to organize blocks of code, and the convention is that an indent is represented by \u0026lsquo;4 spaces\u0026rsquo;, so be sure to follow the convention of Be sure to stick to the convention of using 4-space indentation.\nIf you are using a text editor or IDE, you can automatically convert Tab to 4 spaces and then use the tab key to use indentation, making sure you don\u0026rsquo;t mix Tab and spaces.\nThe amount of indented whitespace is variable, but all block statements must contain the same amount of indented whitespace, and this must be strictly enforced. This is shown below.\nif True: print(\u0026#34;neo\u0026#34;) else: print(\u0026#34;smile\u0026#34;) The following code will execute with an error.\nif True: print(\u0026#34;neo\u0026#34;) else: print(\u0026#34;smile\u0026#34;) print(\u0026#34;it\u0026#34;) Therefore, you must use the same number of indented spaces at the beginning of a line in a Python block of code.\nMulti-line statements  Python statements are generally terminated by a new line.\nBut we can use a slash () to split a one-line statement into multiple lines, as follows.\ntotal = item_one + \\ item_two + \\ item_three Statements containing [], {} or () brackets do not need to use multi-line concatenation. The following example.\ndays = [\u0026#39;Monday\u0026#39;, \u0026#39;Tuesday\u0026#39;, \u0026#39;Wednesday\u0026#39;, \u0026#39;Thursday\u0026#39;, \u0026#39;Friday\u0026#39;] Python quotation marks  Python accepts single quotes (\u0026rsquo; ), double quotes (\u0026quot; ), and triple quotes (''' \u0026ldquo;\u0026quot;\u0026quot;) to represent strings, and the quotes must start and end with the same type.\nWhere triple quotes can be composed of multiple lines, a shortcut syntax for writing multi-line text, commonly used document strings, in specific locations in the file, is used as a comment.\nword = \u0026#39;word\u0026#39; sentence = \u0026#34;This is a sentence.\u0026#34; paragraph = \u0026#34;\u0026#34;\u0026#34;This is a paragraph. It is made up of multiple lines and sentences.\u0026#34;\u0026#34;\u0026#34; Python comments  Statements that begin with \u0026lsquo;#\u0026rsquo; are comments, and they don\u0026rsquo;t have to appear at the beginning of a line; you can also add comments after certain statements; they are for human eyes and can be anything you want; the interpreter will ignore them, but be careful not to use meaningless comments.\nPython has single-line comments starting with #, and Python doesn\u0026rsquo;t have block comments, so the recommended multi-line comments now use # as well, for example.\n#! /usr/bin/python # First comment print(\u0026#34;Hello, Python!\u0026#34;); # second comment Output results.\nHello, Python! Comments can be placed at the end of a statement or expression line.\nname = \u0026#34;Madisetti\u0026#34; # This is again comment` Multiple comments.\n# This is a comment. # This is a comment, too. # This is a comment, too. # I said that already. Python spaces and blank lines  In Python, spaces and blank lines are sometimes too guiltily placed in code to make it look clearer and more readable. Spaces or blank lines, unlike code indentation, are not part of the Python syntax.\nThe Python interpreter will run without errors if you don\u0026rsquo;t insert spaces or blank lines when writing. But the purpose of spaces or blank lines is to separate two pieces of code that have different functions or meanings, so that the code can be maintained or refactored later.\n Spaces and blank lines are used to increase the readability of the code.\n For example, adding spaces when variables are copied.\nhello = \u0026#34;world\u0026#34; such as a blank line between class member functions and two lines between module-level functions and class definitions.\nclass A: def __init__(self): pass def hello(self): pass def main(): pass Print output  print() defaults to newline output, if you want to implement no newline you need to add the end parameter.\nx=\u0026#34;a\u0026#34; y=\u0026#34;b\u0026#34; print(x, end=\u0026#39; \u0026#39;) print(y, end=\u0026#39; \u0026#39;) Summary  This article has taught you about Python\u0026rsquo;s syntax and how Python is a concise scripting language, and how using indentation, spaces, line breaks, and other prescribed syntax can keep your program running properly and make it more readable.\n Reference.\nhttps://www.xjimmy.com/python-4-code.html\nhttps://wizardforcel.gitbooks.io/w3school-python/content/3.html https://github.com/JustDoPython/python-100-day/tree/master/day-002\n","date":"30 Jun, 2021","image":"images/blog/python.png","permalink":"https://codelink.ai/blog/python/python101-2-basic-syntax/","tags":["learning","python101"],"title":"Python101: 2. Basic Syntax"},{"categories":["devops"],"contents":" 1. Operating system  Microsoft WindowsÔºöAssembly -\u0026gt; C -\u0026gt; C++\nNote: Once in the smartphone operating system (Windows Mobile) to consider mixing the program written in C#, such as soft keyboard, the results are too slow to write out the program, it is impossible to merge with other modules, and finally back to C++ rewrite.\nI believe many friends know Windows Vista, the system development early Bill Gates wanted to write all in C#, but finally because of the slow implementation and give up, the results of the previous countless software engineers work day and night results overnight was declared null and void.\nLinux: C\nApple MacOS: mainly C, partly C++.\nNote: The language used before is rather mixed, the earliest is assembly and Pascal.\nSun Solaris: C\nHP-UX: C\nSymbian OS: Assembly, mainly C++ (Nokia phones)\nGoogle Android: launched in 2008: C (there are rumors that the operating system is developed in Java, but just recently launched a native C SDK)\nRIM BlackBerry OS 4.x: BlackBerry C++\n2. GUI layer  Microsoft Windows UI: C++\nApple MacOS UI (Aqua): C++\nGnome (one of the Linux GUIs, Bigfoot): C and C++, but mainly C\nKDE (Linux GUI): C++\n3. Desktop search tools  Google Desktop Search: C++\nMicrosoft Windows Desktop Search: C++\nBeagle (under Linux/Windows/UNIX): C# (based on open source .net: Mono)\n4. Office software  Microsoft Office: in Assembly -\u0026gt; C -\u0026gt; stable in C++\nSun Open Office: part of JAVA (external interface), mainly for C (open source, can download its source code)\nCorel Office/WordPerfect Office: tried Java in 1996, abandoned the following year, back to C/C\nAdobe Systems Acrobat Reader/Distiller: C++\n5. Relational database  Oracle: assembly, C, C, Java. mainly for C\nMySQL: C++\nIBM DB2: Assembly, C, C++, but mainly C\nMicrosoft SQL Server: Assembly -\u0026gt; C-\u0026gt;C++\nIBM Informix: Assembly, C, C++, but mainly C\nSAP DB/MaxDB: C++\n6. Web Browsers/Browsers  Microsoft Internet Explorer: C++\nMozilla Firefox: C++\nNetscape Navigator: The code of Netscape browser was written in C, and Netscape engineers, all bought to Java (see M. Cusumano book and article) It was too slow and abandoned. Mozilla, the next version, was later developed using C++.\nSafari: (released in January 2003) C++\nGoogle Chrome: (2008 release) C++\nSun HotJava: Java (died in 1999)\nOpera: C++ (more popular on cell phones)\nOpera Mini: Opera Mini (2007) has a very funny architecture, and is indeed using both C++ and Java. The browser is split in two parts, an ultra thin (less than The first uses Java and receives the page under the OBML format, the latter reuses The first uses Java and receives the page under the OBML format, the latter reuses classical Opera (C++) rendering engine plus Opera\u0026rsquo;s Small Screen Rendering, on the server. This allows Opera to penetrate various J2ME-enabled portable devices, such as phones, while preserving excellent response time. execution.\nMosaic: The originator (dead) C language\n7. Email client  Microsoft Outlook: C++\nIBM Lotus Notes: Java\nFoxmail: Delphi\n8. Integrated software development environment/IDE  Microsoft Visual Studio: C++\nEclipse: Java (its graphical interface SWT based on C/C++)\nCode::Blocks: C++\nVolcano Chinese: C++\nVolcano Mobile: C++\n9. Virtual Machine  Net CLR (virtual machine for .NET): C++\nJava Virtual Machine (JVM): Java Virtual Machine : C++\n10. ERP software (enterprise applications)  SAP mySAP ERP: C, after the main \u0026ldquo;ABAP/4\u0026rdquo; language\nOracle Peoplesoft: C++ -\u0026gt; Java\nOracle E-Business Suite: Java\n11. Business Intelligence (Business Intelligence)  Business Objects: C++\n12. Graphics Processing  Adobe Photoshop: C++\nThe GIMP: C\n13. Search engine  Google: assembly and C++, but mainly for C++\n14. Famous website  eBay: C++ in 2002, after the main move to Java\nfacebook: C++ and PHP\nThis line is only about facebook, not its plugins. Plugins can be developed in many different technologies, thanks to facebook\u0026rsquo;s ORB/application server Thrift contains a compiler coded in C++. facebook people write about Thrift: \u0026ldquo;The multi-language code generation is well suited for search because it allows for application development in an The multi-language code generation is well suited for search because it allows for application development in an efficient server side language (C++) and allows the Facebook PHP-based web application to make calls to the search service using Thrift PHP libraries.\u0026rdquo; Aside the use of C++, facebook has adopted a LAMP architecture.\nAlibaba and Taobao: php-\u0026gt;C++/Java (mainly used)\n15. Games  Assembly, C, C++ Starcraft, Warcraft, CS, Age of Empires, Karting, Legend, World of Warcraft \u0026hellip;. Too many to count, count them yourself!\nThe C++ language is close to the bottom of the system and has the fastest execution speed. For example, your two friends and you respectively play with VB, Java, and C++ written \u0026ldquo;run kart\u0026rdquo;, you play the game written in C++ has been running and playing the end, found that your two friends have not started to run it, that is quite a card ah.\n16. Compiler  Microsoft Visual C++ compiler: C++\nMicrosoft Visual Basic interpretation, compiler: C++\nMicrosoft Visual C#: compiler: C++\ngcc (GNU C compiler): C\njavac (Sun Java compiler): Java\nPerl: C++\nPHP: C\n17. 3D engine  Microsoft DirectX: C++\nOpenGLÔºö C\nOGRE 3DÔºö C++\n18. Web Servers (web services)  Apache: C and C++, but mainly C\nMicrosoft IIS: C++\nTomcat: Java\nJboss: Java\n19. Mail service  **Microsoft Exchange Server**: C-C++ Postfix: C\nhMailServer: C++\nApache James: Java\n20. CD/DVD burning  Nero Burning ROM: C++\nK3B: C++\n21. Media Player  Nullsoft Winamp: C++\nMicrosoft Windows Media PlayerÔºö C++\n22. Peer to Peer (P2P software)  eMule: C++\nŒºtorrent: C++\nAzureus: Java (GUI using C/C++ based SWT, Eclipse-like)\n23. Global Positioning System (GPS)  TomTom: C++\nHertz NeverLost: C++\nGarmin: C++\nMotorola VIAMOTO: June 2007, out of service, Java\n24. 3D engine  Microsoft DirectX: C++ (I believe the game students know this, now the highest version is DX11)\nOpenGL: C\nOGRE 3D: C++\n25. Server software  Apache: C\nNginx: C\nIIS: C\n26. Other  OpenStack: Python\nSource\n","date":"04 Jun, 2021","image":"images/blog/coding-language.jpeg","permalink":"https://codelink.ai/blog/devops/what-programming-languages-are-some-famous-softwares-written-in/","tags":["knowledge"],"title":"What programming languages are some famous softwares written in?"}]